{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46358ffa-ac47-48c6-917e-54d7918483d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os. chdir('/home/users/gmenon/workspace/songsLyricsGenerator/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852a9e9-9f11-40e7-be68-d372a242db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning import LightningModule\n",
    "import pytorch_lightning as pl\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Model\n",
    "from constants.mir_constants import TrainingArgs, WAV2VEC2_ARGS\n",
    "from training import lyrics_finetune\n",
    "from dataclasses import dataclass, asdict\n",
    "import json\n",
    "import argparse\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23a1124d-49d5-4576-b8f2-f775c7239d84",
   "metadata": {},
   "source": [
    "from flash.audio import SpeechRecognitionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b62468-9929-43e3-8aeb-7daaeb74b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(asdict(WAV2VEC2_ARGS), indent = 4))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "690c412e-6b90-431e-98d9-1dfac1e94f98",
   "metadata": {},
   "source": [
    "datamodule = SpeechRecognitionData.from_csv(\"consolidated_file_path\",\n",
    "                                                         \"transcription_capitalized\",\n",
    "                                                         train_file=WAV2VEC2_ARGS.TRAIN_FILE_PATH,\n",
    "                                                         test_file=WAV2VEC2_ARGS.TEST_FILE_PATH,\n",
    "                                                         batch_size=WAV2VEC2_ARGS.BATCH_SIZE\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0809f82-32b0-4995-bdb0-08779a8c0211",
   "metadata": {},
   "source": [
    "datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d6096-d0e4-4d39-8828-57e3a4a208cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flash\n",
    "import torchaudio\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# class SpeechDataModule(pl.LightningDataModule):\n",
    "#     def __init__(self, args: WAV2VEC2_ARGS):\n",
    "#         super().__init__()\n",
    "#         self.batch_size = 2\n",
    "\n",
    "#     def prepare_data(self):\n",
    "#         # Download and extract the audio files and transcripts, if necessary.\n",
    "#         pass\n",
    "\n",
    "#     def setup(self, stage=None):\n",
    "#         # Create the dataset\n",
    "#         # datamodule = \n",
    "#         self.dataset = SpeechRecognitionData.from_csv(\"consolidated_file_path\",\n",
    "#                                                          \"transcription_capitalized\",\n",
    "#                                                          train_file=WAV2VEC2_ARGS.TRAIN_FILE_PATH,\n",
    "#                                                          test_file=WAV2VEC2_ARGS.TEST_FILE_PATH,\n",
    "#                                                          batch_size=2\n",
    "#                                                          )\n",
    "\n",
    "#         # Create the dataloader\n",
    "#         self.train_dataloader = self.dataset.train_dataloader\n",
    "#         # torch.utils.data.DataLoader(\n",
    "#         #     self.dataset,\n",
    "#         #     batch_size=self.batch_size,\n",
    "#         #     shuffle=True,\n",
    "#         #     num_workers=4,\n",
    "#         # )\n",
    "#         self.val_dataloader = self.dataset.val_dataloader\n",
    "#         # torch.utils.data.DataLoader(\n",
    "#         #     self.dataset,\n",
    "#         #     batch_size=self.batch_size,\n",
    "#         #     shuffle=False,\n",
    "#         #     num_workers=4,\n",
    "#         # )\n",
    "\n",
    "#     def train_dataloader(self):\n",
    "#         return self.train_dataloader\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         return self.val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3354031-3fb6-46ee-9fed-c3c06d23348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DALIDataset(pl.LightningDataModule):\n",
    "#     def __init__(self, batch_size: int = 4,\n",
    "#                   train_path :Optional[str] = None,\n",
    "#                     validation_path: Optional[str] = None,\n",
    "#                       model_backbone: pl.LightningModule = None,\n",
    "#                       args: TrainingArgs = WAV2VEC2_ARGS\n",
    "#                       ):\n",
    "        \n",
    "#         super().__init__()\n",
    "#         self.train_path = train_path if train_path is not None else args.TRAIN_FILE_PATH\n",
    "#         self.validation_path = validation_path if validation_path is not None else args.TEST_FILE_PATH\n",
    "#         self.model_backbone = model_backbone if model_backbone is not None else args.MODEL_BACKBONE\n",
    "\n",
    "#         def prepare_data(self):\n",
    "#             pass\n",
    "        \n",
    "#         def setup(self):\n",
    "#             train_df = pd.read_csv(WAV2VEC2_ARGS.TRAIN_FILE_PATH) \n",
    "#             validation_df = pd.read_csv(WAV2VEC2_ARGS.TEST_FILE_PATH)\n",
    "#             songs_metadata = pd.concat([train_df,validation_df], ignore_index = True)\n",
    "#             audio_dataset = Dataset.from_dict(\n",
    "#                 {\"audio\": list(songs_metadata[\"file_name\"]),\n",
    "#                  \"transcription\": list(songs_metadata[\"transcription\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "#             audio_dataset[\"transcription\"] = audio_dataset[\"transcription\"] = re.sub(WAV2VEC2_ARGS.CHARS_TO_REMOVE_FROM_TRANSCRIPTS, '', audio_dataset[\"transcription\"]).upper()\n",
    "#             audio_dataset = audio_dataset.train_test_split(test_size=0.2, shuffle=True)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a239b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor\n",
    "from datasets import load_dataset,Dataset,Audio\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# class SpeechRecognitionDataset(Dataset):\n",
    "#     def __init__(self, dataset,args:TrainingArgs,processor):\n",
    "#         self.model_backbone = args.MODEL_BACKBONE\n",
    "#         self.dataset = dataset\n",
    "#         self.processor = processor\n",
    "#         self.tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(self.model_backbone)\n",
    "#         self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(self.model_backbone)\n",
    "#         self.processor = Wav2Vec2Processor(feature_extractor=self.feature_extractor, tokenizer=self.tokenizer)\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         audio = self.dataset[index][\"audio\"][0]\n",
    "#         transcription = self.dataset[index][\"transcription\"][0]\n",
    "\n",
    "#         input_values = self.processor(audio[\"array\"], sampling_rate=16_000).input_values[0]\n",
    "#         with self.processor.as_target_processor():\n",
    "#             print(\"Entering the label encoder\")\n",
    "#             labels = self.processor(transcription,return_tensors = 'pt').input_ids\n",
    "#        # attention_mask = inputs.attention_mask.squeeze()\n",
    "#         return input_values, labels\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8e8b187-08b6-4e27-b3ec-7e1da0ad5ead",
   "metadata": {},
   "source": [
    "class SpeechRecognitionDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, WAV2VEC2_ARGS: WAV2VEC2_ARGS, num_workers):\n",
    "        super().__init__()\n",
    "        self.batch_size = WAV2VEC2_ARGS.BATCH_SIZE\n",
    "        self.num_workers = num_workers\n",
    "        self.tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(WAV2VEC2_ARGS.MODEL_BACKBONE)\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(WAV2VEC2_ARGS.MODEL_BACKBONE)\n",
    "        self.processor = Wav2Vec2Processor(feature_extractor=self.feature_extractor, tokenizer=self.tokenizer)\n",
    "        self.cpu_count = 1\n",
    "        print(f\"CPU Count = {self.cpu_count}\")\n",
    "        self.padding: Union[bool, str] = True\n",
    "        self.max_length: Optional[int] = None\n",
    "        self.max_length_labels: Optional[int] = None\n",
    "        self.pad_to_multiple_of: Optional[int] = None\n",
    "        self.pad_to_multiple_of_labels: Optional[int] = None\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        train_df = pd.read_csv(WAV2VEC2_ARGS.TRAIN_FILE_PATH).head(10)\n",
    "        validation_df = pd.read_csv(WAV2VEC2_ARGS.TEST_FILE_PATH).head(10)\n",
    "        #songs_metadata = pd.concat([train_df,validation_df], ignore_index = True)\n",
    "        if stage == 'fit' or stage is None:\n",
    "            print(\"In Stage = Fit\")\n",
    "            train_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(train_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(train_df[\"transcription_capitalized\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "\n",
    "            \n",
    "            val_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(validation_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(validation_df[\"transcription_capitalized\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "\n",
    "            \n",
    "            train_dataset = train_dataset.map(self.transform_huggingface_dataset, num_proc = self.cpu_count)\n",
    "            train_dataset =train_dataset.remove_columns(['audio','transcription','input_length'])\n",
    "            self.train_dataset = train_dataset.map(self.data_collate, num_proc = self.cpu_count)\n",
    "\n",
    "            \n",
    "            val_dataset = val_dataset.map(self.transform_huggingface_dataset, num_proc = self.cpu_count,)\n",
    "            val_dataset =val_dataset.remove_columns(['audio','transcription','input_length'])\n",
    "            self.val_dataset = val_dataset.map(self.data_collate, num_proc = self.cpu_count)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            print(\"In Stage = Test\")\n",
    "            val_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(validation_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(validation_df[\"transcription_capitalized\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "          #  val_dataset[\"transcription\"] = val_dataset[\"transcription\"] = re.sub(WAV2VEC2_ARGS.CHARS_TO_REMOVE_FROM_TRANSCRIPTS, '', val_dataset[\"transcription\"]).upper()\n",
    "            val_dataset = val_dataset.map(self.transform_huggingface_dataset, num_proc = self.cpu_count)\n",
    "            #self.test_dataset = SpeechRecognitionDataset(val_dataset,WAV2VEC2_ARGS,self.processor)\n",
    "            self.test_dataset = val_dataset\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        print(\"entering train data loader\")\n",
    "        return DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        print(\"entering val data loader\")\n",
    "        return DataLoader(\n",
    "            self.val_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        print(\"entering test data loader\")\n",
    "        return DataLoader(\n",
    "            self.test_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "    \n",
    "    def transform_huggingface_dataset(self, batch: Dataset) -> Dataset:\n",
    "        audio = batch[\"audio\"]\n",
    "        batch[\"input_values\"] = self.processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "        batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "        with self.processor.as_target_processor():\n",
    "            batch[\"labels\"] = self.processor(batch[\"transcription\"]).input_ids\n",
    "        return batch\n",
    "\n",
    "    def data_collate(self, batch: Dataset) :\n",
    "        input_features = [{\"input_values\": batch[\"input_values\"]}]\n",
    "        label_features = [{\"input_ids\": batch[\"labels\"]}]\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )      \n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ed33833-367d-48be-a594-389fa4aef1d8",
   "metadata": {},
   "source": [
    "data = SpeechRecognitionDataModule(WAV2VEC2_ARGS, num_workers = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d7bd241-6c23-48c0-a557-fd3cd663add3",
   "metadata": {},
   "source": [
    "data.setup()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64526ed0-9e12-4065-b4d3-4e484d573e92",
   "metadata": {},
   "source": [
    "next(iter(data.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc4a02-0e0b-4462-bb7b-79e70cbec785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96306ffe-8df9-4e84-a994-d7d92f614a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Union, List, Dict\n",
    "# import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "# from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "\n",
    "# class DataCollatorCTCWithPadding:\n",
    "#     \"\"\"\n",
    "#     Data collator that will dynamically pad the inputs received.\n",
    "#     Args:\n",
    "#         processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "#             The processor used for proccessing the data.\n",
    "#         padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "#             Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "#             among:\n",
    "#             * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "#               sequence if provided).\n",
    "#             * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "#               maximum acceptable input length for the model if that argument is not provided.\n",
    "#             * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "#               different lengths).\n",
    "#         max_length (:obj:`int`, `optional`):\n",
    "#             Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "#         max_length_labels (:obj:`int`, `optional`):\n",
    "#             Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "#         pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "#             If set will pad the sequence to a multiple of the provided value.\n",
    "#             This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "#             7.5 (Volta).\n",
    "#     \"\"\"\n",
    "\n",
    "#     processor: Wav2Vec2Processor\n",
    "#     padding: Union[bool, str] = True\n",
    "#     max_length: Optional[int] = None\n",
    "#     max_length_labels: Optional[int] = None\n",
    "#     pad_to_multiple_of: Optional[int] = None\n",
    "#     pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "#     def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "#         # split inputs and labels since they have to be of different lengths and need\n",
    "#         # different padding methods\n",
    "#         input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "#         label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "#         batch = self.processor.pad(\n",
    "#             input_features,\n",
    "#             padding=self.padding,\n",
    "#             max_length=self.max_length,\n",
    "#             pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "#             return_tensors=\"pt\",\n",
    "#         )\n",
    "#         with self.processor.as_target_processor():\n",
    "#             labels_batch = self.processor.pad(\n",
    "#                 label_features,\n",
    "#                 padding=self.padding,\n",
    "#                 max_length=self.max_length_labels,\n",
    "#                 pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "#                 return_tensors=\"pt\",\n",
    "#             )\n",
    "\n",
    "#         # replace padding with -100 to ignore loss correctly\n",
    "#         labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "#         batch[\"labels\"] = labels\n",
    "\n",
    "#         return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cdad31-2268-4085-a6d4-6f86eb7558c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "# text = \"Replace me by any text you'd like.\"\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c217f6c-0f28-48c6-92b0-0ca5755253b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Dict, List\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        label_attention_features =[{\"input_ids\": feature[\"label_attention_mask\"]} for feature in features]\n",
    "        attention_features =[{\"input_values\": feature[\"attention_mask\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\")\n",
    "\n",
    "        batch_attention = self.processor.pad(\n",
    "            attention_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\")\n",
    "    \n",
    "            \n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        with self.processor.as_target_processor():\n",
    "            label_attention_batch = self.processor.pad(\n",
    "                label_attention_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "                \n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels_attention = label_attention_batch[\"input_ids\"].masked_fill(labels_batch.input_ids.eq(101), 0).masked_fill(labels_batch.input_ids.eq(102), 0)\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        \n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        batch[\"label_attention_masks\"] = labels_attention\n",
    "        batch[\"attention_mask\"] = batch_attention[\"input_values\"]\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5405a62-6cc2-4291-b105-4f2f9c7aaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor,BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoFeatureExtractor, AutoModelForCTC, AutoModel,AutoProcessor\n",
    "\n",
    "from datasets import load_dataset,Dataset,Audio\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "WAV2VEC2_ARGS.BATCH_SIZE = 2\n",
    "class SpeechRecognitionDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, WAV2VEC2_ARGS: WAV2VEC2_ARGS, num_workers):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.batch_size = WAV2VEC2_ARGS.BATCH_SIZE\n",
    "        self.num_workers = num_workers\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(hparams.wav2vec2_model)\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        #self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(WAV2VEC2_ARGS.MODEL_BACKBONE)\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "        #self.feature_extractor = AutoFeatureExtractor.from_pretrained(hparams.wav2vec2_model)\n",
    "        self.processor = Wav2Vec2Processor(feature_extractor=self.feature_extractor, tokenizer=self.bert_tokenizer)\n",
    "        #self.processor = AutoProcessor(feature_extractor=self.feature_extractor, tokenizer=self.bert_tokenizer)\n",
    "        #self.processor = WhisperProcessor(feature_extractor=self.feature_extractor, tokenizer=self.bert_tokenizer)\n",
    "        self.data_collator = DataCollatorCTCWithPadding(processor=self.processor, padding=True)\n",
    "        self.cpu_count = 4\n",
    "        print(f\"CPU Count = {self.cpu_count}\")\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        train_df = pd.read_csv(WAV2VEC2_ARGS.TRAIN_FILE_PATH).head(10)\n",
    "        validation_df = pd.read_csv(WAV2VEC2_ARGS.TEST_FILE_PATH).head(10)\n",
    "        if stage == 'fit' or stage is None:\n",
    "            print(\"In Stage = Fit\")\n",
    "            train_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(train_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(train_df[\"transcription_capitalized\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "            self.train_dataset = train_dataset.map(self.prepare_dataset,remove_columns = train_dataset.column_names)\n",
    "            \n",
    "            val_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(validation_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(validation_df[\"transcription_capitalized\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "            self.val_dataset = val_dataset.map(self.prepare_dataset,remove_columns = val_dataset.column_names)\n",
    "\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            print(\"In Stage = Test\")\n",
    "            test_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(validation_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(validation_df[\"transcription_capitalized\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "            test_dataset = val_dataset.map(self.prepare_dataset,remove_columns = val_dataset.column_names)\n",
    "            self.test_dataset = test_dataset\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        print(\"entering train data loader\")\n",
    "        return DataLoader(\n",
    "            self.train_dataset.with_format(\"torch\"), \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn = self.data_collator\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        print(\"entering val data loader\")\n",
    "        return DataLoader(\n",
    "            self.val_dataset.with_format(\"torch\"), \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn = self.data_collator\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        print(\"entering test data loader\")\n",
    "        return DataLoader(\n",
    "            self.test_dataset.with_format(\"torch\"), \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn = self.data_collator\n",
    "        )\n",
    "\n",
    "    def prepare_dataset(self,batch):\n",
    "        audio = batch[\"audio\"]\n",
    "        # batched output is \"un-batched\" to ensure mapping is correct\n",
    "        batch[\"input_values\"] = self.processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "        batch[\"attention_mask\"] = self.processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).attention_mask[0]\n",
    "        batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "        with self.processor.as_target_processor():\n",
    "            batch[\"labels\"] = self.processor(batch[\"transcription\"]).input_ids\n",
    "            batch[\"label_attention_mask\"] = self.processor(batch[\"transcription\"]).attention_mask\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75fe7b63-806e-46e7-8007-6223196529a5",
   "metadata": {},
   "source": [
    "data = SpeechRecognitionDataModule(WAV2VEC2_ARGS, num_workers = 0)\n",
    "data.setup()\n",
    "data.val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44155934-62d0-4943-afb7-9891bbd11a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.val_dataset[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d90ec0e4-4a82-4f5b-a545-14a2be55dd00",
   "metadata": {},
   "source": [
    "print(next(iter(data.val_dataloader())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d9597-6db9-48ff-b8db-4fe73bef6ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Model, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, AutoFeatureExtractor, AutoModelForCTC, AutoModel\n",
    "\n",
    "class Wav2SeqModel(LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.batch_size = hparams.batch_size\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.wav2vec2 = AutoModelForCTC.from_pretrained(hparams.wav2vec2_model,ctc_zero_infinity=True,ctc_loss_reduction=\"mean\")\n",
    "        self.wav2vec2.eval()\n",
    "        #self.wav2vec2 = AutoModel.from_pretrained(hparams.wav2vec2_model)\n",
    "        #self.wav2vec2.eval()\n",
    "        print(self.wav2vec2.config)\n",
    "        self.seq2seq = AutoModelForCausalLM.from_pretrained(hparams.lm_model)\n",
    "        self.seq2seq.config.is_decoder = True\n",
    "        self.seq2seq.add_cross_attention = True\n",
    "        print(self.seq2seq.config)\n",
    "\n",
    "    def forward(self, audio, attention_mask, labels, label_attention_mask):\n",
    "        #print(\"entering forward step\")\n",
    "        encoder_outputs = self.wav2vec2(audio[0],\n",
    "                                        attention_mask=attention_mask, #Made a change here by adding a [0]\n",
    "                                        output_hidden_states=True,\n",
    "                                        output_attentions=True)\n",
    "        encoder_hidden_states = encoder_outputs[0]  \n",
    "        print(f\"encoder_hidden_states={encoder_hidden_states}\")\n",
    "        encoder_attention_mask = self.wav2vec2._get_feature_vector_attention_mask(\n",
    "                encoder_hidden_states.shape[1], attention_mask\n",
    "            )\n",
    "        print(f\"[PRIOR]decoder_input_ids={labels}\")\n",
    "        print(f\"[PRIOR]decoder_attention_masks={label_attention_mask}\")\n",
    "        decoder_input_ids = self.shift_tokens_right(labels, 0, 101)\n",
    "        decoder_attention_masks = self.shift_tokens_right_mask(label_attention_mask)\n",
    "        print(f\"[AFTER]decoder_input_ids={decoder_input_ids}\")\n",
    "        print(f\"[AFTER]decoder_attention_masks={decoder_attention_masks}\")\n",
    "        decoder_outputs = self.seq2seq(input_ids=decoder_input_ids,\n",
    "                                       attention_mask = decoder_attention_masks,\n",
    "                                       encoder_hidden_states=encoder_hidden_states,\n",
    "                                      encoder_attention_mask=encoder_attention_mask) #,attention_mask = x.attentions, decoder_input_ids=predicted_ids\n",
    "        return decoder_outputs\n",
    "\n",
    "    def generate(self, audio):\n",
    "        encoder_outputs = self.wav2vec2(audio[0],output_hidden_states=True,output_attentions=True)\n",
    "        encoder_hidden_states = encoder_outputs[0]\n",
    "        bos_ids = (\n",
    "            torch.ones(\n",
    "                (encoder_hidden_states.size()[0], 1),\n",
    "                dtype=torch.long,\n",
    "                device=self.seq2seq.device,\n",
    "            )\n",
    "            * self.seq2seq.config.pad_token_id\n",
    "        )\n",
    "        return self.seq2seq.generate(\n",
    "            input_ids=bos_ids,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #print(\"entering training step\")\n",
    "        audio = batch[\"input_values\"].unsqueeze(0)\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        label_attention_mask = batch[\"label_attention_masks\"].unsqueeze(0)\n",
    "        #print(f\"audio={audio}, attention_mask = {attention_mask}, label_attention_mask = {label_attention_mask}\")\n",
    "        labels = batch[\"labels\"]\n",
    "        labels = labels.reshape(self.batch_size,-1)\n",
    "        logits = self(audio,attention_mask,labels,label_attention_mask).logits\n",
    "        logits = logits.reshape(-1, self.batch_size, self.seq2seq.config.vocab_size)\n",
    "        input_lengths = torch.full(size=(self.batch_size,), fill_value=logits.shape[0], dtype=torch.long)\n",
    "        target_lengths = torch.full(size=(self.batch_size,), fill_value=labels.shape[0], dtype=torch.long)\n",
    "        # ctc_loss =  nn.CTCLoss(blank=0)\n",
    "        # loss = ctc_loss(logits,labels,input_lengths,target_lengths)\n",
    "        ce_loss = nn.CrossEntropyLoss()\n",
    "        loss = ce_loss(logits, labels)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch,batch_idx):\n",
    "        #print(\"entering validation step\")\n",
    "        audio = batch[\"input_values\"].unsqueeze(0)\n",
    "        labels = batch[\"labels\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        label_attention_mask = batch[\"label_attention_masks\"].unsqueeze(0)\n",
    "        #print(f\"audio={audio}, attention_mask = {attention_mask}, label_attention_mask = {label_attention_mask}\")\n",
    "        labels = labels.reshape(self.batch_size,-1)\n",
    "        logits = self(audio,attention_mask,labels,label_attention_mask).logits\n",
    "        logits = logits.reshape(-1, self.batch_size, self.seq2seq.config.vocab_size)\n",
    "        input_lengths = torch.full(size=(self.batch_size,), fill_value=logits.shape[0], dtype=torch.long)\n",
    "        target_lengths = torch.full(size=(self.batch_size,), fill_value=labels.shape[0], dtype=torch.long)\n",
    "        # ctc_loss =  nn.CTCLoss(blank=0)\n",
    "        # loss = ctc_loss(logits,labels,input_lengths,target_lengths)\n",
    "        ce_loss = nn.CrossEntropyLoss()\n",
    "        loss = ce_loss(logits, labels)\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        label_decoded = labels.type(torch.int64).tolist()\n",
    "        #print(f\"labels = {labels}\")\n",
    "        #print(f\"predicted ids = {predicted_ids}\")\n",
    "        print(f\"original text = {self.bert_tokenizer.decode(label_decoded[0])},{self.bert_tokenizer.decode(label_decoded[1])}\")\n",
    "        predicted_text = predicted_ids.type(torch.int64)\n",
    "        print(f\"Predicted text = {self.bert_tokenizer.decode(predicted_text[:,0].flatten().tolist())},{self.bert_tokenizer.decode(predicted_text[:,-1].flatten().tolist())}\")\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=hparams.learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n",
    "        \"\"\"\n",
    "        Shift input ids one token to the right.\n",
    "        \"\"\"\n",
    "        shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "        shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
    "        if decoder_start_token_id is None:\n",
    "            raise ValueError(\"Make sure to set the decoder_start_token_id attribute of the model's configuration.\")\n",
    "        shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "    \n",
    "        if pad_token_id is None:\n",
    "            raise ValueError(\"Make sure to set the pad_token_id attribute of the model's configuration.\")\n",
    "        # replace possible -100 values in labels by `pad_token_id`\n",
    "        shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "    \n",
    "        return shifted_input_ids\n",
    "\n",
    "    @staticmethod\n",
    "    def shift_tokens_right_mask(input_ids: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Shift input ids one token to the right.\n",
    "        \"\"\"\n",
    "        shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "        shifted_input_ids[:,:, 1:] = input_ids[:,:, :-1].clone()\n",
    "        shifted_input_ids[:,:, 0] = 0\n",
    "        return shifted_input_ids.squeeze()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1365d597-7bd4-420e-8077-b021455357df",
   "metadata": {},
   "source": [
    "test_data = SpeechRecognitionDataModule(WAV2VEC2_ARGS, num_workers = 0)\n",
    "test_data.setup()\n",
    "print(next(iter(test_data.val_dataloader())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93bcca1-79eb-4f51-9dd3-368e192fcfcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "hparams = argparse.Namespace()\n",
    "hparams.wav2vec2_model = 'facebook/wav2vec2-large-960h-lv60-self' #'openai/whisper-base'# #'openai/whisper-base'\n",
    "hparams.lm_model = 'bert-base-uncased' #'facebook/bart-large'\n",
    "hparams.vocab_size = 30000\n",
    "hparams.learning_rate = 0.00001\n",
    "hparams.batch_size = WAV2VEC2_ARGS.BATCH_SIZE\n",
    "\n",
    "model = Wav2SeqModel(hparams)\n",
    "trainer = Trainer(max_epochs=10,devices=1, accelerator=\"gpu\")\n",
    "trainer.fit(model,SpeechRecognitionDataModule(WAV2VEC2_ARGS,num_workers=4))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3fa8d2a-177c-40b8-b166-108a04b7c4ae",
   "metadata": {},
   "source": [
    "import librosa \n",
    "def create_audio_tensor(audio_path):\n",
    "    audio, sample_rate = librosa.load(audio_path)\n",
    "    audio_tensor = torch.from_numpy(audio).float()\n",
    "    audio_tensor = audio_tensor.unsqueeze(0)\n",
    "    return audio_tensor\n",
    "audio_tensor = create_audio_tensor(\"notebooks/separated/mdx_extra/test_clip/vocals.wav\")\n",
    "print(audio_tensor.unsqueeze(0).shape)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = model.generate(audio_tensor.unsqueeze(0))\n",
    "torch.argmax(y_hat, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5538f-c4f3-4c19-a729-26f38aff7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f92b482-a046-4c0f-bcd3-2ca40b2fc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_tensor = next(iter(test_data.val_dataloader()))[\"input_values\"]\n",
    "audio_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9938cd6-0d0e-4914-89cd-9772ac41a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = model.generate(audio_tensor.unsqueeze(0))\n",
    "torch.argmax(y_hat, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3838261-9da4-46a1-8a35-543a359e81cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import torch\n",
    "# from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "# def create_audio_tensor(audio_path):\n",
    "#     audio, sample_rate = librosa.load(audio_path)\n",
    "#     audio_tensor = torch.from_numpy(audio).float()\n",
    "#     audio_tensor = audio_tensor.unsqueeze(0)\n",
    "#     return audio_tensor\n",
    "\n",
    "# model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "# audio_tensor = create_audio_tensor(\"notebooks/separated/mdx_extra/test_clip/vocals.wav\")\n",
    "logits = model(audio_tensor.unsqueeze(0),torch.Tensor(18, 11,  0,  0,  0,  0,  0,  7,  0,  0,  0,  0,  6,  0,  0,  0,  4,  4,\n",
    "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  5,  0,  0,  0,\n",
    "          0, 15, 15,  0,  0,  0,  0,  0,  0, 12,  0,  0,  0,  4,  4,  0,  0,  0,\n",
    "         14,  0,  0,  0,  0, 10,  0,  0, 12, 12,  0,  0,  0,  0,  0, 19,  0,  0,\n",
    "          0,  0,  0,  0,  0,  0,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6, 11,\n",
    "          0,  0,  5,  0,  0,  0,  4,  4,  0,  0,  0, 24,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0,  5,  0,  0,  0,  0,  0,  9,  0,  0,  0,  0,  4,  4,  4,  0,\n",
    "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0))\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "print(audio_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c2fb4-ab29-433a-ab4f-5e895a1aaf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e40856-59d1-4d5e-84c3-ab64b528f23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96624e0-53a7-47c0-bb31-07da5ad31208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4686fb-f6f8-4b08-af94-a9d18762a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa479c4-9660-4ee0-b8f1-7cabac8d3480",
   "metadata": {},
   "outputs": [],
   "source": [
    "input,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b60aad4-07ca-422c-a376-fab2cd8cbdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor,BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoFeatureExtractor, AutoModelForCTC, AutoModel,AutoProcessor\n",
    "\n",
    "from datasets import load_dataset,Dataset,Audio\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "class SpeechRecognitionDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, WAV2VEC2_ARGS: WAV2VEC2_ARGS, num_workers):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.batch_size = WAV2VEC2_ARGS.BATCH_SIZE\n",
    "        self.num_workers = num_workers\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(hparams.wav2vec2_model)\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        #self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(WAV2VEC2_ARGS.MODEL_BACKBONE)\n",
    "        #self.feature_extractor = AutoFeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "        self.feature_extractor = AutoFeatureExtractor.from_pretrained(hparams.wav2vec2_model)\n",
    "        #self.processor = Wav2Vec2Processor(feature_extractor=self.feature_extractor, tokenizer=self.tokenizer)\n",
    "        #self.processor = AutoProcessor(feature_extractor=self.feature_extractor, tokenizer=self.bert_tokenizer)\n",
    "        self.processor = WhisperProcessor(feature_extractor=self.feature_extractor, tokenizer=self.bert_tokenizer)\n",
    "        self.data_collator = DataCollatorCTCWithPadding(processor=self.processor, padding=True)\n",
    "        self.cpu_count = 4\n",
    "        print(f\"CPU Count = {self.cpu_count}\")\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        train_df = pd.read_csv(WAV2VEC2_ARGS.TRAIN_FILE_PATH).head(10)\n",
    "        validation_df = pd.read_csv(WAV2VEC2_ARGS.TEST_FILE_PATH).head(10)\n",
    "        if stage == 'fit' or stage is None:\n",
    "            print(\"In Stage = Fit\")\n",
    "            train_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(train_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(train_df[\"transcription_capitalized\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "            self.train_dataset = train_dataset.map(self.prepare_dataset,remove_columns = train_dataset.column_names)\n",
    "            \n",
    "            val_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(validation_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(validation_df[\"transcription_capitalized\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "            self.val_dataset = val_dataset.map(self.prepare_dataset,remove_columns = val_dataset.column_names)\n",
    "\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            print(\"In Stage = Test\")\n",
    "            test_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(validation_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(validation_df[\"transcription_capitalized\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "            test_dataset = val_dataset.map(self.prepare_dataset,remove_columns = val_dataset.column_names)\n",
    "            self.test_dataset = test_dataset\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        print(\"entering train data loader\")\n",
    "        return DataLoader(\n",
    "            self.train_dataset.with_format(\"torch\"), \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn = self.data_collator\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        print(\"entering val data loader\")\n",
    "        return DataLoader(\n",
    "            self.val_dataset.with_format(\"torch\"), \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn = self.data_collator\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        print(\"entering test data loader\")\n",
    "        return DataLoader(\n",
    "            self.test_dataset.with_format(\"torch\"), \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn = self.data_collator\n",
    "        )\n",
    "\n",
    "    def prepare_dataset(self,batch):\n",
    "        audio = batch[\"audio\"]\n",
    "        # batched output is \"un-batched\" to ensure mapping is correct\n",
    "        batch[\"input_values\"] = self.processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "        batch[\"attention_mask\"] = self.processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).attention_mask[0]\n",
    "        batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "        with self.processor.as_target_processor():\n",
    "            batch[\"labels\"] = self.processor(batch[\"transcription\"]).input_ids\n",
    "            batch[\"label_attention_mask\"] = self.processor(batch[\"transcription\"]).attention_mask\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a286c7f4-b4f8-4849-a121-7b7337b701c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Model, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, AutoFeatureExtractor, AutoModelForCTC, AutoModel\n",
    "\n",
    "class Wav2SeqModel(LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.batch_size = hparams.batch_size\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        #self.wav2vec2 = AutoModelForCTC.from_pretrained(hparams.wav2vec2_model,ctc_zero_infinity=True,ctc_loss_reduction=\"mean\")\n",
    "        #self.wav2vec2.freeze_feature_encoder()\n",
    "        self.wav2vec2 = AutoModel.from_pretrained(hparams.wav2vec2_model)\n",
    "        self.wav2vec2.eval()\n",
    "        print(self.wav2vec2.config)\n",
    "        self.seq2seq = AutoModelForCausalLM.from_pretrained(hparams.lm_model)\n",
    "        self.seq2seq.config.is_decoder = True\n",
    "        self.seq2seq.add_cross_attention = True\n",
    "        print(self.seq2seq.config)\n",
    "\n",
    "    def forward(self, audio, attention_mask, labels, label_attention_mask):\n",
    "        #print(\"entering forward step\")\n",
    "        encoder_outputs = self.wav2vec2(audio[0],\n",
    "                                        attention_mask=attention_mask, #Made a change here by adding a [0]\n",
    "                                        output_hidden_states=True,\n",
    "                                        output_attentions=True)\n",
    "        encoder_hidden_states = encoder_outputs[0]  \n",
    "        print(f\"encoder_hidden_states={encoder_hidden_states}\")\n",
    "        encoder_attention_mask = self.wav2vec2._get_feature_vector_attention_mask(\n",
    "                encoder_hidden_states.shape[1], attention_mask\n",
    "            )\n",
    "        #print(f\"[PRIOR]decoder_input_ids={labels}\")\n",
    "        #print(f\"[PRIOR]decoder_attention_masks={label_attention_mask}\")\n",
    "        decoder_input_ids = self.shift_tokens_right(labels, 0, 101)\n",
    "        decoder_attention_masks = self.shift_tokens_right_mask(label_attention_mask)\n",
    "        #print(f\"[AFTER]decoder_input_ids={decoder_input_ids}\")\n",
    "        #print(f\"[AFTER]decoder_attention_masks={decoder_attention_masks}\")\n",
    "        decoder_outputs = self.seq2seq(input_ids=decoder_input_ids,\n",
    "                                       attention_mask = decoder_attention_masks,\n",
    "                                       encoder_hidden_states=encoder_hidden_states,\n",
    "                                      encoder_attention_mask=encoder_attention_mask) #,attention_mask = x.attentions, decoder_input_ids=predicted_ids\n",
    "        return decoder_outputs\n",
    "\n",
    "    def generate(self, audio):\n",
    "        encoder_outputs = self.wav2vec2(audio[0],output_hidden_states=True,output_attentions=True)\n",
    "        encoder_hidden_states = encoder_outputs[0]\n",
    "        bos_ids = (\n",
    "            torch.ones(\n",
    "                (encoder_hidden_states.size()[0], 1),\n",
    "                dtype=torch.long,\n",
    "                device=self.seq2seq.device,\n",
    "            )\n",
    "            * self.seq2seq.config.pad_token_id\n",
    "        )\n",
    "        return self.seq2seq.generate(\n",
    "            input_ids=bos_ids,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #print(\"entering training step\")\n",
    "        audio = batch[\"input_values\"].unsqueeze(0)\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        label_attention_mask = batch[\"label_attention_masks\"].unsqueeze(0)\n",
    "        #print(f\"audio={audio}, attention_mask = {attention_mask}, label_attention_mask = {label_attention_mask}\")\n",
    "        labels = batch[\"labels\"]\n",
    "        labels = labels.reshape(self.batch_size,-1)\n",
    "        logits = self(audio,attention_mask,labels,label_attention_mask).logits\n",
    "        logits = logits.reshape(-1, self.batch_size, self.seq2seq.config.vocab_size)\n",
    "        input_lengths = torch.full(size=(self.batch_size,), fill_value=logits.shape[0], dtype=torch.long)\n",
    "        target_lengths = torch.full(size=(self.batch_size,), fill_value=labels.shape[0], dtype=torch.long)\n",
    "        ctc_loss =  nn.CTCLoss(blank=0)\n",
    "        loss = ctc_loss(logits,labels,input_lengths,target_lengths)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch,batch_idx):\n",
    "        #print(\"entering validation step\")\n",
    "        audio = batch[\"input_values\"].unsqueeze(0)\n",
    "        labels = batch[\"labels\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        label_attention_mask = batch[\"label_attention_masks\"].unsqueeze(0)\n",
    "        #print(f\"audio={audio}, attention_mask = {attention_mask}, label_attention_mask = {label_attention_mask}\")\n",
    "        labels = labels.reshape(self.batch_size,-1)\n",
    "        logits = self(audio,attention_mask,labels,label_attention_mask).logits\n",
    "        logits = logits.reshape(-1, self.batch_size, self.seq2seq.config.vocab_size)\n",
    "        input_lengths = torch.full(size=(self.batch_size,), fill_value=logits.shape[0], dtype=torch.long)\n",
    "        target_lengths = torch.full(size=(self.batch_size,), fill_value=labels.shape[0], dtype=torch.long)\n",
    "        ctc_loss =  nn.CTCLoss(blank=0)\n",
    "        loss = ctc_loss(logits,labels,input_lengths,target_lengths)\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        label_decoded = labels.type(torch.int64).tolist()\n",
    "        #print(f\"labels = {labels}\")\n",
    "        #print(f\"predicted ids = {predicted_ids}\")\n",
    "        print(f\"original text = {self.bert_tokenizer.decode(label_decoded[0])},{self.bert_tokenizer.decode(label_decoded[1])}\")\n",
    "        predicted_text = predicted_ids.type(torch.int64)\n",
    "        print(f\"Predicted text = {self.bert_tokenizer.decode(predicted_text[:,0].flatten().tolist())},{self.bert_tokenizer.decode(predicted_text[:,-1].flatten().tolist())}\")\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=hparams.learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n",
    "        \"\"\"\n",
    "        Shift input ids one token to the right.\n",
    "        \"\"\"\n",
    "        shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "        shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
    "        if decoder_start_token_id is None:\n",
    "            raise ValueError(\"Make sure to set the decoder_start_token_id attribute of the model's configuration.\")\n",
    "        shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "    \n",
    "        if pad_token_id is None:\n",
    "            raise ValueError(\"Make sure to set the pad_token_id attribute of the model's configuration.\")\n",
    "        # replace possible -100 values in labels by `pad_token_id`\n",
    "        shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "    \n",
    "        return shifted_input_ids\n",
    "\n",
    "    @staticmethod\n",
    "    def shift_tokens_right_mask(input_ids: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Shift input ids one token to the right.\n",
    "        \"\"\"\n",
    "        shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "        shifted_input_ids[:,:, 1:] = input_ids[:,:, :-1].clone()\n",
    "        shifted_input_ids[:,:, 0] = 0\n",
    "        return shifted_input_ids.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41800a8c-b400-4f13-acc7-af7a56bbfa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(WAV2VEC2_ARGS.TRAIN_FILE_PATH)\n",
    "validation_df = pd.read_csv(WAV2VEC2_ARGS.TEST_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b1e3a-6e1a-4d93-9f48-a970bf08eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df.transcription_capitalized.str.len()>200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806eb51a-1af0-4b4b-a02d-f26c16beed6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93f879b6-a836-4798-86ed-6bf40d44fc81",
   "metadata": {},
   "source": [
    "# Readying the codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa9d25-0b49-480f-87fd-a7a1439cea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgreeshmasmenon\u001b[0m (\u001b[33msongslyricstranscription\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230822_071229-1yo3wk2q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/songslyricstranscription/SLG%20-%20wav2vec2%20transfer%20learning/runs/1yo3wk2q' target=\"_blank\">deep-darkness-169</a></strong> to <a href='https://wandb.ai/songslyricstranscription/SLG%20-%20wav2vec2%20transfer%20learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/songslyricstranscription/SLG%20-%20wav2vec2%20transfer%20learning' target=\"_blank\">https://wandb.ai/songslyricstranscription/SLG%20-%20wav2vec2%20transfer%20learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/songslyricstranscription/SLG%20-%20wav2vec2%20transfer%20learning/runs/1yo3wk2q' target=\"_blank\">https://wandb.ai/songslyricstranscription/SLG%20-%20wav2vec2%20transfer%20learning/runs/1yo3wk2q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"TRAIN_FILE_PATH\": \"/scratch/users/gmenon/train_song_metadata_en_demucs_cleaned_filtered_095.csv\",\n",
      "    \"TEST_FILE_PATH\": \"/scratch/users/gmenon/validation_song_metadata_en_demucs_cleaned_filtered_005.csv\",\n",
      "    \"MODEL_BACKBONE\": \"facebook/wav2vec2-large-960h-lv60-self\",\n",
      "    \"BATCH_SIZE\": 1,\n",
      "    \"NUM_EPOCHS\": 15,\n",
      "    \"MODEL_SAVE_PATH\": \"/scratch/users/gmenon//model_artefacts/wav2vec2_demucs_en_large-960h-lv60-self_freeze_unfreeze_15epochs_adamw.pt\",\n",
      "    \"FINETUNE_STRATEGY\": [\n",
      "        \"freeze_unfreeze\",\n",
      "        10\n",
      "    ],\n",
      "    \"LR_SCHEDULER\": \"reduce_on_plateau_schedule\"\n",
      "}\n",
      "Namespace(batch_size=1, learning_rate=1e-06, lm_model='bert-base-uncased', vocab_size=20000, wav2vec2_model='facebook/wav2vec2-large-960h-lv60-self')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/irisgpfs/users/gmenon/workspace/songsLyricsGenerator/slg_finetuned/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "Using 'facebook/wav2vec2-large-960h-lv60-self' provided by Hugging Face/transformers (https://github.com/huggingface/transformers).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using 'facebook/wav2vec2-large-960h-lv60-self' provided by Hugging Face/transformers (https://github.com/huggingface/transformers).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Count = 4\n",
      "In Stage = Fit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed244b9016ce4bd39a0665793d499071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2228e1fc1b444bb3c813c1e47f74d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type            | Params\n",
      "---------------------------------------------\n",
      "0 | wav2vec2 | Wav2Vec2ForCTC  | 315 M \n",
      "1 | seq2seq  | BertLMHeadModel | 109 M \n",
      "---------------------------------------------\n",
      "424 M     Trainable params\n",
      "0         Non-trainable params\n",
      "424 M     Total params\n",
      "1,699.943 Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Optimization Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering val data loader\n",
      "original text = so learn from your mistakes, labels = tensor([ 2061,  4553,  2013,  2115, 12051], device='cuda:0')\n",
      "Predicted text = and and and your and, predicted ids = tensor([1998, 1998, 1998, 2115, 1998], device='cuda:0')\n",
      "original text = i've been connected to the right line, labels = tensor([1045, 1005, 2310, 2042, 4198, 2000, 1996, 2157, 2240], device='cuda:0')\n",
      "Predicted text = -'' been to to the right line, predicted ids = tensor([1011, 1005, 1005, 2042, 2000, 2000, 1996, 2157, 2240], device='cuda:0')\n",
      "entering train data loader\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291fec64877a41f3b5b9aea93faf6e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text = so learn from your mistakes, labels = tensor([ 2061,  4553,  2013,  2115, 12051], device='cuda:0')\n",
      "Predicted text = so learn from your mistakes, predicted ids = tensor([ 2061,  4553,  2013,  2115, 12051], device='cuda:0')\n",
      "original text = i've been connected to the right line, labels = tensor([1045, 1005, 2310, 2042, 4198, 2000, 1996, 2157, 2240], device='cuda:0')\n",
      "Predicted text = i've been connected to the right line, predicted ids = tensor([1045, 1005, 2310, 2042, 4198, 2000, 1996, 2157, 2240], device='cuda:0')\n",
      "original text = the truth to be found, labels = tensor([1996, 3606, 2000, 2022, 2179], device='cuda:0')\n",
      "Predicted text = and truth to be found, predicted ids = tensor([1998, 3606, 2000, 2022, 2179], device='cuda:0')\n",
      "original text = he said the way myblue eyes shined, labels = tensor([ 2002,  2056,  1996,  2126,  2026, 16558,  5657,  2159, 12342,  2094],\n",
      "       device='cuda:0')\n",
      "Predicted text = i said the way myblue eyes shined, predicted ids = tensor([ 1045,  2056,  1996,  2126,  2026, 16558,  5657,  2159, 12342,  2094],\n",
      "       device='cuda:0')\n",
      "original text = you leave me once again home alone, labels = tensor([2017, 2681, 2033, 2320, 2153, 2188, 2894], device='cuda:0')\n",
      "Predicted text = you leave me once again home alone, predicted ids = tensor([2017, 2681, 2033, 2320, 2153, 2188, 2894], device='cuda:0')\n",
      "original text = while they are in commend, labels = tensor([2096, 2027, 2024, 1999, 4012, 3549, 2094], device='cuda:0')\n",
      "Predicted text = and they are in commend, predicted ids = tensor([1998, 2027, 2024, 1999, 4012, 3549, 2094], device='cuda:0')\n",
      "original text = a life all mine, labels = tensor([1037, 2166, 2035, 3067], device='cuda:0')\n",
      "Predicted text = and life all mine, predicted ids = tensor([1998, 2166, 2035, 3067], device='cuda:0')\n",
      "original text = so i never went back, labels = tensor([2061, 1045, 2196, 2253, 2067], device='cuda:0')\n",
      "Predicted text = so i never went back, predicted ids = tensor([2061, 1045, 2196, 2253, 2067], device='cuda:0')\n",
      "original text = in you i taste god, labels = tensor([1999, 2017, 1045, 5510, 2643], device='cuda:0')\n",
      "Predicted text = when you i taste god, predicted ids = tensor([2043, 2017, 1045, 5510, 2643], device='cuda:0')\n",
      "original text = could stay a while, labels = tensor([2071, 2994, 1037, 2096], device='cuda:0')\n",
      "Predicted text = can stay a while, predicted ids = tensor([2064, 2994, 1037, 2096], device='cuda:0')\n",
      "original text = my love my life, labels = tensor([2026, 2293, 2026, 2166], device='cuda:0')\n",
      "Predicted text = i love my life, predicted ids = tensor([1045, 2293, 2026, 2166], device='cuda:0')\n",
      "original text = one two one two three arghh, labels = tensor([ 2028,  2048,  2028,  2048,  2093, 12098,  5603,  2232],\n",
      "       device='cuda:0')\n",
      "Predicted text = that two one two three arghh, predicted ids = tensor([ 2008,  2048,  2028,  2048,  2093, 12098,  5603,  2232],\n",
      "       device='cuda:0')\n",
      "original text = how can you treat me like a child, labels = tensor([2129, 2064, 2017, 7438, 2033, 2066, 1037, 2775], device='cuda:0')\n",
      "Predicted text = why can you treat me like a child, predicted ids = tensor([2339, 2064, 2017, 7438, 2033, 2066, 1037, 2775], device='cuda:0')\n",
      "original text = it's hard to put the fire out, labels = tensor([2009, 1005, 1055, 2524, 2000, 2404, 1996, 2543, 2041], device='cuda:0')\n",
      "Predicted text = it's hard to put the fire out, predicted ids = tensor([2009, 1005, 1055, 2524, 2000, 2404, 1996, 2543, 2041], device='cuda:0')\n",
      "original text = and walked out of my life, labels = tensor([1998, 2939, 2041, 1997, 2026, 2166], device='cuda:0')\n",
      "Predicted text = and walked out of my life, predicted ids = tensor([1998, 2939, 2041, 1997, 2026, 2166], device='cuda:0')\n",
      "original text = open your wings evil angel, labels = tensor([2330, 2115, 4777, 4763, 4850], device='cuda:0')\n",
      "Predicted text = open your wings evil angel, predicted ids = tensor([2330, 2115, 4777, 4763, 4850], device='cuda:0')\n",
      "original text = oh it's what you do to me, labels = tensor([2821, 2009, 1005, 1055, 2054, 2017, 2079, 2000, 2033], device='cuda:0')\n",
      "Predicted text = oh it's what you do to me, predicted ids = tensor([2821, 2009, 1005, 1055, 2054, 2017, 2079, 2000, 2033], device='cuda:0')\n",
      "original text = ah look at all the lonely people, labels = tensor([6289, 2298, 2012, 2035, 1996, 9479, 2111], device='cuda:0')\n",
      "Predicted text = oh look at all the lonely people, predicted ids = tensor([2821, 2298, 2012, 2035, 1996, 9479, 2111], device='cuda:0')\n",
      "original text = that's where she lies broken inside, labels = tensor([2008, 1005, 1055, 2073, 2016, 3658, 3714, 2503], device='cuda:0')\n",
      "Predicted text = and's where she lies broken inside, predicted ids = tensor([1998, 1005, 1055, 2073, 2016, 3658, 3714, 2503], device='cuda:0')\n",
      "original text = closing time open all the doors, labels = tensor([5494, 2051, 2330, 2035, 1996, 4303], device='cuda:0')\n",
      "Predicted text = closing time open all the doors, predicted ids = tensor([5494, 2051, 2330, 2035, 1996, 4303], device='cuda:0')\n",
      "original text = many places i have been, labels = tensor([2116, 3182, 1045, 2031, 2042], device='cuda:0')\n",
      "Predicted text = all places i have been, predicted ids = tensor([2035, 3182, 1045, 2031, 2042], device='cuda:0')\n",
      "original text = we used to know, labels = tensor([2057, 2109, 2000, 2113], device='cuda:0')\n",
      "Predicted text = we used to know, predicted ids = tensor([2057, 2109, 2000, 2113], device='cuda:0')\n",
      "original text = i don't want to be a hero, labels = tensor([1045, 2123, 1005, 1056, 2215, 2000, 2022, 1037, 5394], device='cuda:0')\n",
      "Predicted text = i don't want to be a hero, predicted ids = tensor([1045, 2123, 1005, 1056, 2215, 2000, 2022, 1037, 5394], device='cuda:0')\n",
      "original text = i've seen your face i feel your love, labels = tensor([1045, 1005, 2310, 2464, 2115, 2227, 1045, 2514, 2115, 2293],\n",
      "       device='cuda:0')\n",
      "Predicted text = i've seen your face i feel your love, predicted ids = tensor([1045, 1005, 2310, 2464, 2115, 2227, 1045, 2514, 2115, 2293],\n",
      "       device='cuda:0')\n",
      "original text = you can make the most of the distance, labels = tensor([2017, 2064, 2191, 1996, 2087, 1997, 1996, 3292], device='cuda:0')\n",
      "Predicted text = you can make the most of the distance, predicted ids = tensor([2017, 2064, 2191, 1996, 2087, 1997, 1996, 3292], device='cuda:0')\n",
      "original text = it's the song about love between, labels = tensor([2009, 1005, 1055, 1996, 2299, 2055, 2293, 2090], device='cuda:0')\n",
      "Predicted text = it's the song about love between, predicted ids = tensor([2009, 1005, 1055, 1996, 2299, 2055, 2293, 2090], device='cuda:0')\n",
      "original text = in the beginning we, labels = tensor([1999, 1996, 2927, 2057], device='cuda:0')\n",
      "Predicted text = when the beginning we, predicted ids = tensor([2043, 1996, 2927, 2057], device='cuda:0')\n",
      "original text = because you livegirl, labels = tensor([ 2138,  2017,  2444, 15239], device='cuda:0')\n",
      "Predicted text = and you livegirl, predicted ids = tensor([ 1998,  2017,  2444, 15239], device='cuda:0')\n",
      "original text = i can feel her on my skin, labels = tensor([1045, 2064, 2514, 2014, 2006, 2026, 3096], device='cuda:0')\n",
      "Predicted text = i can feel her on my skin, predicted ids = tensor([1045, 2064, 2514, 2014, 2006, 2026, 3096], device='cuda:0')\n",
      "original text = with arms wide open, labels = tensor([2007, 2608, 2898, 2330], device='cuda:0')\n",
      "Predicted text = i arms wide open, predicted ids = tensor([1045, 2608, 2898, 2330], device='cuda:0')\n",
      "original text = they make me feel so good, labels = tensor([2027, 2191, 2033, 2514, 2061, 2204], device='cuda:0')\n",
      "Predicted text = they make me feel so good, predicted ids = tensor([2027, 2191, 2033, 2514, 2061, 2204], device='cuda:0')\n",
      "original text = be wrong or right, labels = tensor([2022, 3308, 2030, 2157], device='cuda:0')\n",
      "Predicted text = you wrong or right, predicted ids = tensor([2017, 3308, 2030, 2157], device='cuda:0')\n",
      "original text = though your friends try to tell me, labels = tensor([2295, 2115, 2814, 3046, 2000, 2425, 2033], device='cuda:0')\n",
      "Predicted text = and your friends try to tell me, predicted ids = tensor([1998, 2115, 2814, 3046, 2000, 2425, 2033], device='cuda:0')\n",
      "original text = you still can touch my heart, labels = tensor([2017, 2145, 2064, 3543, 2026, 2540], device='cuda:0')\n",
      "Predicted text = you still can touch my heart, predicted ids = tensor([2017, 2145, 2064, 3543, 2026, 2540], device='cuda:0')\n",
      "original text = and both of us must try, labels = tensor([1998, 2119, 1997, 2149, 2442, 3046], device='cuda:0')\n",
      "Predicted text = and both of us must try, predicted ids = tensor([1998, 2119, 1997, 2149, 2442, 3046], device='cuda:0')\n",
      "original text = when i thought that i fought without a cause, labels = tensor([2043, 1045, 2245, 2008, 1045, 4061, 2302, 1037, 3426], device='cuda:0')\n",
      "Predicted text = and i thought that i fought without a cause, predicted ids = tensor([1998, 1045, 2245, 2008, 1045, 4061, 2302, 1037, 3426], device='cuda:0')\n",
      "original text = but you thought i would look the other way, labels = tensor([2021, 2017, 2245, 1045, 2052, 2298, 1996, 2060, 2126], device='cuda:0')\n",
      "Predicted text = and you thought i would look the other way, predicted ids = tensor([1998, 2017, 2245, 1045, 2052, 2298, 1996, 2060, 2126], device='cuda:0')\n",
      "original text = i'm just trying to say, labels = tensor([1045, 1005, 1049, 2074, 2667, 2000, 2360], device='cuda:0')\n",
      "Predicted text = i'm just trying to say, predicted ids = tensor([1045, 1005, 1049, 2074, 2667, 2000, 2360], device='cuda:0')\n",
      "original text = i wish that i could be there for you, labels = tensor([1045, 4299, 2008, 1045, 2071, 2022, 2045, 2005, 2017], device='cuda:0')\n",
      "Predicted text = i wish that i could be there for you, predicted ids = tensor([1045, 4299, 2008, 1045, 2071, 2022, 2045, 2005, 2017], device='cuda:0')\n",
      "original text = and you don't need tricks, labels = tensor([ 1998,  2017,  2123,  1005,  1056,  2342, 12225], device='cuda:0')\n",
      "Predicted text = and you don't need tricks, predicted ids = tensor([ 1998,  2017,  2123,  1005,  1056,  2342, 12225], device='cuda:0')\n",
      "original text = dub dub dududududub dudu, labels = tensor([12931, 12931,  4241,  8566,  8566,  8566,  8566,  2497,  4241,  8566],\n",
      "       device='cuda:0')\n",
      "Predicted text = dub dub dubdududududududu, predicted ids = tensor([12931, 12931, 12931,  8566,  8566,  8566,  8566,  8566,  8566,  8566],\n",
      "       device='cuda:0')\n",
      "original text = we're only just beginning and it's over, labels = tensor([2057, 1005, 2128, 2069, 2074, 2927, 1998, 2009, 1005, 1055, 2058],\n",
      "       device='cuda:0')\n",
      "Predicted text = we're only just beginning and it's over, predicted ids = tensor([2057, 1005, 2128, 2069, 2074, 2927, 1998, 2009, 1005, 1055, 2058],\n",
      "       device='cuda:0')\n",
      "original text = when words get broken, labels = tensor([2043, 2616, 2131, 3714], device='cuda:0')\n",
      "Predicted text = and words get broken, predicted ids = tensor([1998, 2616, 2131, 3714], device='cuda:0')\n",
      "original text = i cannot blame you for a thing, labels = tensor([1045, 3685, 7499, 2017, 2005, 1037, 2518], device='cuda:0')\n",
      "Predicted text = i cannot blame you for a thing, predicted ids = tensor([1045, 3685, 7499, 2017, 2005, 1037, 2518], device='cuda:0')\n",
      "original text = through the monsoon, labels = tensor([ 2083,  1996, 19183], device='cuda:0')\n",
      "Predicted text = and the monsoon, predicted ids = tensor([ 1998,  1996, 19183], device='cuda:0')\n",
      "original text = down on the corner out in the street, labels = tensor([2091, 2006, 1996, 3420, 2041, 1999, 1996, 2395], device='cuda:0')\n",
      "Predicted text = like on the corner out in the street, predicted ids = tensor([2066, 2006, 1996, 3420, 2041, 1999, 1996, 2395], device='cuda:0')\n",
      "original text = there's no life on earth, labels = tensor([2045, 1005, 1055, 2053, 2166, 2006, 3011], device='cuda:0')\n",
      "Predicted text = there's no life on earth, predicted ids = tensor([2045, 1005, 1055, 2053, 2166, 2006, 3011], device='cuda:0')\n",
      "original text = girl ain't no kindness in the face of strangers, labels = tensor([ 2611,  7110,  1005,  1056,  2053, 16056,  1999,  1996,  2227,  1997,\n",
      "        12358], device='cuda:0')\n",
      "Predicted text = girl ain't no kindness in the face of strangers, predicted ids = tensor([ 2611,  7110,  1005,  1056,  2053, 16056,  1999,  1996,  2227,  1997,\n",
      "        12358], device='cuda:0')\n",
      "original text = nothing have i gained but my own true love i've lost, labels = tensor([2498, 2031, 1045, 4227, 2021, 2026, 2219, 2995, 2293, 1045, 1005, 2310,\n",
      "        2439], device='cuda:0')\n",
      "Predicted text = nothing have i gained but my own true love i've lost, predicted ids = tensor([2498, 2031, 1045, 4227, 2021, 2026, 2219, 2995, 2293, 1045, 1005, 2310,\n",
      "        2439], device='cuda:0')\n",
      "original text = worship his holy name, labels = tensor([7425, 2010, 4151, 2171], device='cuda:0')\n",
      "Predicted text = everyday his holy name, predicted ids = tensor([10126,  2010,  4151,  2171], device='cuda:0')\n",
      "original text = from living high for so long, labels = tensor([2013, 2542, 2152, 2005, 2061, 2146], device='cuda:0')\n",
      "Predicted text = in living high for so long, predicted ids = tensor([1999, 2542, 2152, 2005, 2061, 2146], device='cuda:0')\n",
      "original text = when darkness turns to light, labels = tensor([2043, 4768, 4332, 2000, 2422], device='cuda:0')\n",
      "Predicted text = and darkness turns to light, predicted ids = tensor([1998, 4768, 4332, 2000, 2422], device='cuda:0')\n",
      "original text = old school hollywood washed up hollywood, labels = tensor([2214, 2082, 5365, 8871, 2039, 5365], device='cuda:0')\n",
      "Predicted text = old school hollywood washed up hollywood, predicted ids = tensor([2214, 2082, 5365, 8871, 2039, 5365], device='cuda:0')\n",
      "original text = i won't sleep, labels = tensor([1045, 2180, 1005, 1056, 3637], device='cuda:0')\n",
      "Predicted text = i won't sleep, predicted ids = tensor([1045, 2180, 1005, 1056, 3637], device='cuda:0')\n",
      "original text = and should we crush his sweet hands, labels = tensor([ 1998,  2323,  2057, 10188,  2010,  4086,  2398], device='cuda:0')\n",
      "Predicted text = and should we crush his sweet hands, predicted ids = tensor([ 1998,  2323,  2057, 10188,  2010,  4086,  2398], device='cuda:0')\n",
      "original text = every rose has its thorn, labels = tensor([ 2296,  3123,  2038,  2049, 16337], device='cuda:0')\n",
      "Predicted text = and rose has its thorn, predicted ids = tensor([ 1998,  3123,  2038,  2049, 16337], device='cuda:0')\n",
      "original text = that someone so handsome, labels = tensor([2008, 2619, 2061, 8502], device='cuda:0')\n",
      "Predicted text = and someone so handsome, predicted ids = tensor([1998, 2619, 2061, 8502], device='cuda:0')\n",
      "original text = that we're allowed to stay, labels = tensor([2008, 2057, 1005, 2128, 3039, 2000, 2994], device='cuda:0')\n",
      "Predicted text = and we're allowed to stay, predicted ids = tensor([1998, 2057, 1005, 2128, 3039, 2000, 2994], device='cuda:0')\n",
      "original text = ilive without love, labels = tensor([6335, 3512, 2302, 2293], device='cuda:0')\n",
      "Predicted text = iive without love, predicted ids = tensor([1045, 3512, 2302, 2293], device='cuda:0')\n",
      "original text = i'mall alone, labels = tensor([1045, 1005, 6670, 2894], device='cuda:0')\n",
      "Predicted text = i'mall alone, predicted ids = tensor([1045, 1005, 6670, 2894], device='cuda:0')\n",
      "original text = offers coming over the phone, labels = tensor([4107, 2746, 2058, 1996, 3042], device='cuda:0')\n",
      "Predicted text = you coming over the phone, predicted ids = tensor([2017, 2746, 2058, 1996, 3042], device='cuda:0')\n",
      "original text = what do you say, labels = tensor([2054, 2079, 2017, 2360], device='cuda:0')\n",
      "Predicted text = what do you say, predicted ids = tensor([2054, 2079, 2017, 2360], device='cuda:0')\n",
      "original text = me and you and you and me, labels = tensor([2033, 1998, 2017, 1998, 2017, 1998, 2033], device='cuda:0')\n",
      "Predicted text = i and you and you and me, predicted ids = tensor([1045, 1998, 2017, 1998, 2017, 1998, 2033], device='cuda:0')\n",
      "original text = of a twosided mirror, labels = tensor([1997, 1037, 2048, 7363, 2094, 5259], device='cuda:0')\n",
      "Predicted text = and a twosided mirror, predicted ids = tensor([1998, 1037, 2048, 7363, 2094, 5259], device='cuda:0')\n",
      "original text = i must think of a new life, labels = tensor([1045, 2442, 2228, 1997, 1037, 2047, 2166], device='cuda:0')\n",
      "Predicted text = i must think of a new life, predicted ids = tensor([1045, 2442, 2228, 1997, 1037, 2047, 2166], device='cuda:0')\n",
      "original text = i got it all, labels = tensor([1045, 2288, 2009, 2035], device='cuda:0')\n",
      "Predicted text = i got it all, predicted ids = tensor([1045, 2288, 2009, 2035], device='cuda:0')\n",
      "original text = time can never mend, labels = tensor([2051, 2064, 2196, 2273, 2094], device='cuda:0')\n",
      "Predicted text = you can never mend, predicted ids = tensor([2017, 2064, 2196, 2273, 2094], device='cuda:0')\n",
      "original text = phones but can i still call, labels = tensor([11640,  2021,  2064,  1045,  2145,  2655], device='cuda:0')\n",
      "Predicted text = you but can i still call, predicted ids = tensor([2017, 2021, 2064, 1045, 2145, 2655], device='cuda:0')\n",
      "original text = under her spell i can't break, labels = tensor([2104, 2014, 6297, 1045, 2064, 1005, 1056, 3338], device='cuda:0')\n",
      "Predicted text = and her spell i can't break, predicted ids = tensor([1998, 2014, 6297, 1045, 2064, 1005, 1056, 3338], device='cuda:0')\n",
      "original text = what's going on, labels = tensor([2054, 1005, 1055, 2183, 2006], device='cuda:0')\n",
      "Predicted text = what's going on, predicted ids = tensor([2054, 1005, 1055, 2183, 2006], device='cuda:0')\n",
      "original text = there ain't no easy way out, labels = tensor([2045, 7110, 1005, 1056, 2053, 3733, 2126, 2041], device='cuda:0')\n",
      "Predicted text = there ain't no easy way out, predicted ids = tensor([2045, 7110, 1005, 1056, 2053, 3733, 2126, 2041], device='cuda:0')\n",
      "original text = when your love shines down on me, labels = tensor([ 2043,  2115,  2293, 12342,  2015,  2091,  2006,  2033],\n",
      "       device='cuda:0')\n",
      "Predicted text = and your love shines down on me, predicted ids = tensor([ 1998,  2115,  2293, 12342,  2015,  2091,  2006,  2033],\n",
      "       device='cuda:0')\n",
      "original text = and if you think that i'm wrong, labels = tensor([1998, 2065, 2017, 2228, 2008, 1045, 1005, 1049, 3308], device='cuda:0')\n",
      "Predicted text = and if you think that i'm wrong, predicted ids = tensor([1998, 2065, 2017, 2228, 2008, 1045, 1005, 1049, 3308], device='cuda:0')\n",
      "original text = you need love, labels = tensor([2017, 2342, 2293], device='cuda:0')\n",
      "Predicted text = you need love, predicted ids = tensor([2017, 2342, 2293], device='cuda:0')\n",
      "original text = in my time, labels = tensor([1999, 2026, 2051], device='cuda:0')\n",
      "Predicted text = when my time, predicted ids = tensor([2043, 2026, 2051], device='cuda:0')\n",
      "original text = it's cold and loveless, labels = tensor([2009, 1005, 1055, 3147, 1998, 2293, 3238], device='cuda:0')\n",
      "Predicted text = it's cold and loveless, predicted ids = tensor([2009, 1005, 1055, 3147, 1998, 2293, 3238], device='cuda:0')\n",
      "original text = and we tumble down like jack and jill, labels = tensor([ 1998,  2057, 28388,  2091,  2066,  2990,  1998, 10454],\n",
      "       device='cuda:0')\n",
      "Predicted text = and we tumble down like jack and jill, predicted ids = tensor([ 1998,  2057, 28388,  2091,  2066,  2990,  1998, 10454],\n",
      "       device='cuda:0')\n",
      "original text = you're head was in the clouds, labels = tensor([2017, 1005, 2128, 2132, 2001, 1999, 1996, 8044], device='cuda:0')\n",
      "Predicted text = you're head was in the clouds, predicted ids = tensor([2017, 1005, 2128, 2132, 2001, 1999, 1996, 8044], device='cuda:0')\n",
      "original text = don't waste my time, labels = tensor([2123, 1005, 1056, 5949, 2026, 2051], device='cuda:0')\n",
      "Predicted text = don't waste my time, predicted ids = tensor([2123, 1005, 1056, 5949, 2026, 2051], device='cuda:0')\n",
      "original text = her soul rises in the evening, labels = tensor([2014, 3969, 9466, 1999, 1996, 3944], device='cuda:0')\n",
      "Predicted text = you soul rises in the evening, predicted ids = tensor([2017, 3969, 9466, 1999, 1996, 3944], device='cuda:0')\n",
      "original text = chemicals all rushin'in my bloodstream, labels = tensor([12141,  2035,  5481,  2378,  1005,  1999,  2026,  2668, 21422],\n",
      "       device='cuda:0')\n",
      "Predicted text = can all rushin'in my bloodstream, predicted ids = tensor([ 2064,  2035,  5481,  2378,  1005,  1999,  2026,  2668, 21422],\n",
      "       device='cuda:0')\n",
      "original text = hope there's a reason, labels = tensor([3246, 2045, 1005, 1055, 1037, 3114], device='cuda:0')\n",
      "Predicted text = love there's a reason, predicted ids = tensor([2293, 2045, 1005, 1055, 1037, 3114], device='cuda:0')\n",
      "original text = this is a happy end, labels = tensor([2023, 2003, 1037, 3407, 2203], device='cuda:0')\n",
      "Predicted text = this is a happy end, predicted ids = tensor([2023, 2003, 1037, 3407, 2203], device='cuda:0')\n",
      "original text = talk to me so you can see, labels = tensor([2831, 2000, 2033, 2061, 2017, 2064, 2156], device='cuda:0')\n",
      "Predicted text = talk to me so you can see, predicted ids = tensor([2831, 2000, 2033, 2061, 2017, 2064, 2156], device='cuda:0')\n",
      "original text = reason for the world, labels = tensor([3114, 2005, 1996, 2088], device='cuda:0')\n",
      "Predicted text = can for the world, predicted ids = tensor([2064, 2005, 1996, 2088], device='cuda:0')\n",
      "original text = i will carry us home, labels = tensor([1045, 2097, 4287, 2149, 2188], device='cuda:0')\n",
      "Predicted text = i will carry us home, predicted ids = tensor([1045, 2097, 4287, 2149, 2188], device='cuda:0')\n",
      "original text = i have been so good this year, labels = tensor([1045, 2031, 2042, 2061, 2204, 2023, 2095], device='cuda:0')\n",
      "Predicted text = i have been so good this year, predicted ids = tensor([1045, 2031, 2042, 2061, 2204, 2023, 2095], device='cuda:0')\n",
      "original text = rain falls like elvistears, labels = tensor([ 4542,  4212,  2066, 12280, 27058,  2869], device='cuda:0')\n",
      "Predicted text = rain falls like elvistears, predicted ids = tensor([ 4542,  4212,  2066, 12280, 27058,  2869], device='cuda:0')\n",
      "original text = you know i love you but i just can't take this, labels = tensor([2017, 2113, 1045, 2293, 2017, 2021, 1045, 2074, 2064, 1005, 1056, 2202,\n",
      "        2023], device='cuda:0')\n",
      "Predicted text = you know i love you but i just can't take this, predicted ids = tensor([2017, 2113, 1045, 2293, 2017, 2021, 1045, 2074, 2064, 1005, 1056, 2202,\n",
      "        2023], device='cuda:0')\n",
      "original text = i'm a victim, labels = tensor([1045, 1005, 1049, 1037, 6778], device='cuda:0')\n",
      "Predicted text = i'm a victim, predicted ids = tensor([1045, 1005, 1049, 1037, 6778], device='cuda:0')\n",
      "original text = for you i'm open wide, labels = tensor([2005, 2017, 1045, 1005, 1049, 2330, 2898], device='cuda:0')\n",
      "Predicted text = and you i'm open wide, predicted ids = tensor([1998, 2017, 1045, 1005, 1049, 2330, 2898], device='cuda:0')\n",
      "original text = learning how to love, labels = tensor([4083, 2129, 2000, 2293], device='cuda:0')\n",
      "Predicted text = learning how to love, predicted ids = tensor([4083, 2129, 2000, 2293], device='cuda:0')\n",
      "original text = tell me goodbye tell me goodbye, labels = tensor([2425, 2033, 9119, 2425, 2033, 9119], device='cuda:0')\n",
      "Predicted text = tell me goodbye tell me goodbye, predicted ids = tensor([2425, 2033, 9119, 2425, 2033, 9119], device='cuda:0')\n",
      "original text = undo this hurt youcaused, labels = tensor([25672,  2023,  3480,  2017,  3540, 13901], device='cuda:0')\n",
      "Predicted text = undo this hurt youcaused, predicted ids = tensor([25672,  2023,  3480,  2017,  3540, 13901], device='cuda:0')\n",
      "original text = we didn't respect it, labels = tensor([2057, 2134, 1005, 1056, 4847, 2009], device='cuda:0')\n",
      "Predicted text = we didn't respect it, predicted ids = tensor([2057, 2134, 1005, 1056, 4847, 2009], device='cuda:0')\n",
      "original text = gonna take this all in, labels = tensor([6069, 2202, 2023, 2035, 1999], device='cuda:0')\n",
      "Predicted text = gonna take this all in, predicted ids = tensor([6069, 2202, 2023, 2035, 1999], device='cuda:0')\n",
      "original text = and i'm glad that i gave it to him, labels = tensor([1998, 1045, 1005, 1049, 5580, 2008, 1045, 2435, 2009, 2000, 2032],\n",
      "       device='cuda:0')\n",
      "Predicted text = and i'm glad that i gave it to him, predicted ids = tensor([1998, 1045, 1005, 1049, 5580, 2008, 1045, 2435, 2009, 2000, 2032],\n",
      "       device='cuda:0')\n",
      "original text = oh frank zappa and the mothers, labels = tensor([ 2821,  3581, 23564, 13944,  1998,  1996, 10756], device='cuda:0')\n",
      "Predicted text = oh frank zappa and the mothers, predicted ids = tensor([ 2821,  3581, 23564, 13944,  1998,  1996, 10756], device='cuda:0')\n",
      "original text = and darling that's when i, labels = tensor([1998, 9548, 2008, 1005, 1055, 2043, 1045], device='cuda:0')\n",
      "Predicted text = and darling that's when i, predicted ids = tensor([1998, 9548, 2008, 1005, 1055, 2043, 1045], device='cuda:0')\n",
      "original text = you reach out for the guiding light, labels = tensor([ 2017,  3362,  2041,  2005,  1996, 14669,  2422], device='cuda:0')\n",
      "Predicted text = you reach out for the guiding light, predicted ids = tensor([ 2017,  3362,  2041,  2005,  1996, 14669,  2422], device='cuda:0')\n",
      "original text = and they're only, labels = tensor([1998, 2027, 1005, 2128, 2069], device='cuda:0')\n",
      "Predicted text = and they're only, predicted ids = tensor([1998, 2027, 1005, 2128, 2069], device='cuda:0')\n",
      "original text = will you love me, labels = tensor([2097, 2017, 2293, 2033], device='cuda:0')\n",
      "Predicted text = will you love me, predicted ids = tensor([2097, 2017, 2293, 2033], device='cuda:0')\n",
      "original text = i'm the one with no soul, labels = tensor([1045, 1005, 1049, 1996, 2028, 2007, 2053, 3969], device='cuda:0')\n",
      "Predicted text = i'm the one with no soul, predicted ids = tensor([1045, 1005, 1049, 1996, 2028, 2007, 2053, 3969], device='cuda:0')\n",
      "original text = understand, labels = tensor([3305], device='cuda:0')\n",
      "Predicted text = change, predicted ids = tensor([2689], device='cuda:0')\n",
      "original text = sweet sensations, labels = tensor([ 4086, 21378], device='cuda:0')\n",
      "Predicted text = sweet sensations, predicted ids = tensor([ 4086, 21378], device='cuda:0')\n",
      "original text = hot like to burn my lips, labels = tensor([2980, 2066, 2000, 6402, 2026, 2970], device='cuda:0')\n",
      "Predicted text = hot like to burn my lips, predicted ids = tensor([2980, 2066, 2000, 6402, 2026, 2970], device='cuda:0')\n",
      "original text = but i wont give you up, labels = tensor([2021, 1045, 2180, 2102, 2507, 2017, 2039], device='cuda:0')\n",
      "Predicted text = and i wont give you up, predicted ids = tensor([1998, 1045, 2180, 2102, 2507, 2017, 2039], device='cuda:0')\n",
      "original text = pray for me cause i have lost, labels = tensor([11839,  2005,  2033,  3426,  1045,  2031,  2439], device='cuda:0')\n",
      "Predicted text = pray for me cause cause have lost, predicted ids = tensor([11839,  2005,  2033,  3426,  3426,  2031,  2439], device='cuda:0')\n",
      "original text = that's what i intend to do, labels = tensor([ 2008,  1005,  1055,  2054,  1045, 13566,  2000,  2079],\n",
      "       device='cuda:0')\n",
      "Predicted text = and's what i intend to do, predicted ids = tensor([ 1998,  1005,  1055,  2054,  1045, 13566,  2000,  2079],\n",
      "       device='cuda:0')\n",
      "original text = you know me, labels = tensor([2017, 2113, 2033], device='cuda:0')\n",
      "Predicted text = you know me, predicted ids = tensor([2017, 2113, 2033], device='cuda:0')\n",
      "original text = went into a place even darker, labels = tensor([2253, 2046, 1037, 2173, 2130, 9904], device='cuda:0')\n",
      "Predicted text = you into a place even darker, predicted ids = tensor([2017, 2046, 1037, 2173, 2130, 9904], device='cuda:0')\n",
      "original text = iya na koto bakkari demo, labels = tensor([ 1045,  3148,  6583, 12849,  3406,  8670, 15714,  3089,  9703],\n",
      "       device='cuda:0')\n",
      "Predicted text = iya na koto bakkari demo, predicted ids = tensor([ 1045,  3148,  6583, 12849,  3406,  8670, 15714,  3089,  9703],\n",
      "       device='cuda:0')\n",
      "original text = burning here, labels = tensor([5255, 2182], device='cuda:0')\n",
      "Predicted text = burning here, predicted ids = tensor([5255, 2182], device='cuda:0')\n",
      "original text = while on the road to sweet athy, labels = tensor([ 2096,  2006,  1996,  2346,  2000,  4086,  2012, 10536],\n",
      "       device='cuda:0')\n",
      "Predicted text = and on the road to sweet athy, predicted ids = tensor([ 1998,  2006,  1996,  2346,  2000,  4086,  2012, 10536],\n",
      "       device='cuda:0')\n",
      "original text = we can stop the world, labels = tensor([2057, 2064, 2644, 1996, 2088], device='cuda:0')\n",
      "Predicted text = we can stop the world, predicted ids = tensor([2057, 2064, 2644, 1996, 2088], device='cuda:0')\n",
      "original text = a naked light a fire to keep me warm, labels = tensor([1037, 6248, 2422, 1037, 2543, 2000, 2562, 2033, 4010], device='cuda:0')\n",
      "Predicted text = and naked light a fire to keep me warm, predicted ids = tensor([1998, 6248, 2422, 1037, 2543, 2000, 2562, 2033, 4010], device='cuda:0')\n",
      "original text = aim so high above, labels = tensor([6614, 2061, 2152, 2682], device='cuda:0')\n",
      "Predicted text = aim so high above, predicted ids = tensor([6614, 2061, 2152, 2682], device='cuda:0')\n",
      "original text = live for each second without hesitation, labels = tensor([ 2444,  2005,  2169,  2117,  2302, 13431], device='cuda:0')\n",
      "Predicted text = live for each second without hesitation, predicted ids = tensor([ 2444,  2005,  2169,  2117,  2302, 13431], device='cuda:0')\n",
      "original text = feet don't fail me now, labels = tensor([2519, 2123, 1005, 1056, 8246, 2033, 2085], device='cuda:0')\n",
      "Predicted text = land don't fail me now, predicted ids = tensor([2455, 2123, 1005, 1056, 8246, 2033, 2085], device='cuda:0')\n",
      "original text = when we all ignore each other going under, labels = tensor([2043, 2057, 2035, 8568, 2169, 2060, 2183, 2104], device='cuda:0')\n",
      "Predicted text = and we all ignore each other going under, predicted ids = tensor([1998, 2057, 2035, 8568, 2169, 2060, 2183, 2104], device='cuda:0')\n",
      "original text = just do as i say don't do as i do, labels = tensor([2074, 2079, 2004, 1045, 2360, 2123, 1005, 1056, 2079, 2004, 1045, 2079],\n",
      "       device='cuda:0')\n",
      "Predicted text = just do as i say don't do as i do, predicted ids = tensor([2074, 2079, 2004, 1045, 2360, 2123, 1005, 1056, 2079, 2004, 1045, 2079],\n",
      "       device='cuda:0')\n",
      "original text = give me some rope i'm coming loose, labels = tensor([2507, 2033, 2070, 8164, 1045, 1005, 1049, 2746, 6065], device='cuda:0')\n",
      "Predicted text = give me some rope i'm coming loose, predicted ids = tensor([2507, 2033, 2070, 8164, 1045, 1005, 1049, 2746, 6065], device='cuda:0')\n",
      "original text = and i won't get left behind, labels = tensor([1998, 1045, 2180, 1005, 1056, 2131, 2187, 2369], device='cuda:0')\n",
      "Predicted text = and i won't get left behind, predicted ids = tensor([1998, 1045, 2180, 1005, 1056, 2131, 2187, 2369], device='cuda:0')\n",
      "original text = he'll begin his life again, labels = tensor([2002, 1005, 2222, 4088, 2010, 2166, 2153], device='cuda:0')\n",
      "Predicted text = i'll begin his life again, predicted ids = tensor([1045, 1005, 2222, 4088, 2010, 2166, 2153], device='cuda:0')\n",
      "original text = in the summertime, labels = tensor([1999, 1996, 2621, 7292], device='cuda:0')\n",
      "Predicted text = when the summertime, predicted ids = tensor([2043, 1996, 2621, 7292], device='cuda:0')\n",
      "original text = forever we are changed, labels = tensor([5091, 2057, 2024, 2904], device='cuda:0')\n",
      "Predicted text = forever we are changed, predicted ids = tensor([5091, 2057, 2024, 2904], device='cuda:0')\n",
      "original text = you're gonna be mine, labels = tensor([2017, 1005, 2128, 6069, 2022, 3067], device='cuda:0')\n",
      "Predicted text = you're gonna be mine, predicted ids = tensor([2017, 1005, 2128, 6069, 2022, 3067], device='cuda:0')\n",
      "original text = of what's around me, labels = tensor([1997, 2054, 1005, 1055, 2105, 2033], device='cuda:0')\n",
      "Predicted text = and what's around me, predicted ids = tensor([1998, 2054, 1005, 1055, 2105, 2033], device='cuda:0')\n",
      "original text = youdon'tknownothingyet, labels = tensor([ 2017,  5280,  1005,  1056,  2243, 19779, 17048, 12053,  6672,  2102],\n",
      "       device='cuda:0')\n",
      "Predicted text = youdon'tknownothingyet, predicted ids = tensor([ 2017,  5280,  1005,  1056,  2243, 19779, 17048, 12053,  6672,  2102],\n",
      "       device='cuda:0')\n",
      "original text = and the story ends, labels = tensor([1998, 1996, 2466, 4515], device='cuda:0')\n",
      "Predicted text = and the story ends, predicted ids = tensor([1998, 1996, 2466, 4515], device='cuda:0')\n",
      "original text = back to better days, labels = tensor([2067, 2000, 2488, 2420], device='cuda:0')\n",
      "Predicted text = like to better days, predicted ids = tensor([2066, 2000, 2488, 2420], device='cuda:0')\n",
      "original text = i don't wanna hide us away, labels = tensor([ 1045,  2123,  1005,  1056, 10587,  5342,  2149,  2185],\n",
      "       device='cuda:0')\n",
      "Predicted text = i don't wanna hide us away, predicted ids = tensor([ 1045,  2123,  1005,  1056, 10587,  5342,  2149,  2185],\n",
      "       device='cuda:0')\n",
      "original text = my face among them, labels = tensor([2026, 2227, 2426, 2068], device='cuda:0')\n",
      "Predicted text = i face among them, predicted ids = tensor([1045, 2227, 2426, 2068], device='cuda:0')\n",
      "original text = don't let them throw me away, labels = tensor([2123, 1005, 1056, 2292, 2068, 5466, 2033, 2185], device='cuda:0')\n",
      "Predicted text = don't let them throw me away, predicted ids = tensor([2123, 1005, 1056, 2292, 2068, 5466, 2033, 2185], device='cuda:0')\n",
      "original text = southern man will you pay them back, labels = tensor([2670, 2158, 2097, 2017, 3477, 2068, 2067], device='cuda:0')\n",
      "Predicted text = good man will you pay them back, predicted ids = tensor([2204, 2158, 2097, 2017, 3477, 2068, 2067], device='cuda:0')\n",
      "original text = he took me to meet his old granny, labels = tensor([ 2002,  2165,  2033,  2000,  3113,  2010,  2214, 19794],\n",
      "       device='cuda:0')\n",
      "Predicted text = i took me to meet his old granny, predicted ids = tensor([ 1045,  2165,  2033,  2000,  3113,  2010,  2214, 19794],\n",
      "       device='cuda:0')\n",
      "original text = out from beneath your feet, labels = tensor([2041, 2013, 4218, 2115, 2519], device='cuda:0')\n",
      "Predicted text = just from beneath your feet, predicted ids = tensor([2074, 2013, 4218, 2115, 2519], device='cuda:0')\n",
      "original text = we could cry an ocean, labels = tensor([2057, 2071, 5390, 2019, 4153], device='cuda:0')\n",
      "Predicted text = we could cry an ocean, predicted ids = tensor([2057, 2071, 5390, 2019, 4153], device='cuda:0')\n",
      "original text = shpalmatooh restera ', labels = tensor([14021, 12952, 18900,  9541,  2232,  2717,  6906,  1005],\n",
      "       device='cuda:0')\n",
      "Predicted text = ohpalmatooh restera ', predicted ids = tensor([ 2821, 12952, 18900,  9541,  2232,  2717,  6906,  1005],\n",
      "       device='cuda:0')\n",
      "original text = and when i'm dreamin'i know that it's all right, labels = tensor([1998, 2043, 1045, 1005, 1049, 3959, 2378, 1005, 1045, 2113, 2008, 2009,\n",
      "        1005, 1055, 2035, 2157], device='cuda:0')\n",
      "Predicted text = and when i'm dreamin'i know that it's all right, predicted ids = tensor([1998, 2043, 1045, 1005, 1049, 3959, 2378, 1005, 1045, 2113, 2008, 2009,\n",
      "        1005, 1055, 2035, 2157], device='cuda:0')\n",
      "original text = let the music take your mind, labels = tensor([2292, 1996, 2189, 2202, 2115, 2568], device='cuda:0')\n",
      "Predicted text = let the music take your mind, predicted ids = tensor([2292, 1996, 2189, 2202, 2115, 2568], device='cuda:0')\n",
      "original text = and feel it now babylon, labels = tensor([ 1998,  2514,  2009,  2085, 17690], device='cuda:0')\n",
      "Predicted text = and feel it now babylon, predicted ids = tensor([ 1998,  2514,  2009,  2085, 17690], device='cuda:0')\n",
      "original text = all these drugs all these women, labels = tensor([2035, 2122, 5850, 2035, 2122, 2308], device='cuda:0')\n",
      "Predicted text = all these drugs all these women, predicted ids = tensor([2035, 2122, 5850, 2035, 2122, 2308], device='cuda:0')\n",
      "original text = last man standing, labels = tensor([2197, 2158, 3061], device='cuda:0')\n",
      "Predicted text = will man standing, predicted ids = tensor([2097, 2158, 3061], device='cuda:0')\n",
      "original text = you cannot be saved, labels = tensor([2017, 3685, 2022, 5552], device='cuda:0')\n",
      "Predicted text = you cannot be saved, predicted ids = tensor([2017, 3685, 2022, 5552], device='cuda:0')\n",
      "original text = maybe the rain will stop following me, labels = tensor([2672, 1996, 4542, 2097, 2644, 2206, 2033], device='cuda:0')\n",
      "Predicted text = maybe the rain will stop following me, predicted ids = tensor([2672, 1996, 4542, 2097, 2644, 2206, 2033], device='cuda:0')\n",
      "original text = and told me you loved me, labels = tensor([1998, 2409, 2033, 2017, 3866, 2033], device='cuda:0')\n",
      "Predicted text = and told me you loved me, predicted ids = tensor([1998, 2409, 2033, 2017, 3866, 2033], device='cuda:0')\n",
      "original text = quietly fading away, labels = tensor([ 5168, 14059,  2185], device='cuda:0')\n",
      "Predicted text = do fading away, predicted ids = tensor([ 2079, 14059,  2185], device='cuda:0')\n",
      "original text = beauty in all she is, labels = tensor([5053, 1999, 2035, 2016, 2003], device='cuda:0')\n",
      "Predicted text = beauty in all she is, predicted ids = tensor([5053, 1999, 2035, 2016, 2003], device='cuda:0')\n",
      "original text = nebudu vkoute stat, labels = tensor([11265,  8569,  8566,  1058, 24861,  2618, 28093], device='cuda:0')\n",
      "Predicted text = youbudu vkoute stat, predicted ids = tensor([ 2017,  8569,  8566,  1058, 24861,  2618, 28093], device='cuda:0')\n",
      "original text = and i could write it down, labels = tensor([1998, 1045, 2071, 4339, 2009, 2091], device='cuda:0')\n",
      "Predicted text = and i could write it down, predicted ids = tensor([1998, 1045, 2071, 4339, 2009, 2091], device='cuda:0')\n",
      "original text = soon i'll be leaving you, labels = tensor([2574, 1045, 1005, 2222, 2022, 2975, 2017], device='cuda:0')\n",
      "Predicted text = soon i'll be leaving you, predicted ids = tensor([2574, 1045, 1005, 2222, 2022, 2975, 2017], device='cuda:0')\n",
      "original text = i'm so fed up with people telling me to bee, labels = tensor([ 1045,  1005,  1049,  2061,  7349,  2039,  2007,  2111,  4129,  2033,\n",
      "         2000, 10506], device='cuda:0')\n",
      "Predicted text = i'm so fed up with people telling me to bee, predicted ids = tensor([ 1045,  1005,  1049,  2061,  7349,  2039,  2007,  2111,  4129,  2033,\n",
      "         2000, 10506], device='cuda:0')\n",
      "original text = there's no way the band can lose, labels = tensor([2045, 1005, 1055, 2053, 2126, 1996, 2316, 2064, 4558], device='cuda:0')\n",
      "Predicted text = there's no way the band can lose, predicted ids = tensor([2045, 1005, 1055, 2053, 2126, 1996, 2316, 2064, 4558], device='cuda:0')\n",
      "original text = it's a pretty good crowd for a saturday, labels = tensor([2009, 1005, 1055, 1037, 3492, 2204, 4306, 2005, 1037, 5095],\n",
      "       device='cuda:0')\n",
      "Predicted text = it's a pretty good crowd for a saturday, predicted ids = tensor([2009, 1005, 1055, 1037, 3492, 2204, 4306, 2005, 1037, 5095],\n",
      "       device='cuda:0')\n",
      "original text = i'm the one you need, labels = tensor([1045, 1005, 1049, 1996, 2028, 2017, 2342], device='cuda:0')\n",
      "Predicted text = i'm the one you need, predicted ids = tensor([1045, 1005, 1049, 1996, 2028, 2017, 2342], device='cuda:0')\n",
      "original text = here's the watch that my grandpa gave me, labels = tensor([ 2182,  1005,  1055,  1996,  3422,  2008,  2026, 15310,  2435,  2033],\n",
      "       device='cuda:0')\n",
      "Predicted text = here's the watch that my grandpa gave me, predicted ids = tensor([ 2182,  1005,  1055,  1996,  3422,  2008,  2026, 15310,  2435,  2033],\n",
      "       device='cuda:0')\n",
      "original text = tonight anything is possible, labels = tensor([3892, 2505, 2003, 2825], device='cuda:0')\n",
      "Predicted text = new anything is possible, predicted ids = tensor([2047, 2505, 2003, 2825], device='cuda:0')\n",
      "original text = to relearn how to smile, labels = tensor([ 2000,  2128, 19738,  6826,  2129,  2000,  2868], device='cuda:0')\n",
      "Predicted text = and relearn how to smile, predicted ids = tensor([ 1998,  2128, 19738,  6826,  2129,  2000,  2868], device='cuda:0')\n",
      "original text = open my eyes let me find you, labels = tensor([2330, 2026, 2159, 2292, 2033, 2424, 2017], device='cuda:0')\n",
      "Predicted text = open my eyes let me find you, predicted ids = tensor([2330, 2026, 2159, 2292, 2033, 2424, 2017], device='cuda:0')\n",
      "original text = now it's time to blow this fucker down, labels = tensor([2085, 2009, 1005, 1055, 2051, 2000, 6271, 2023, 6616, 2121, 2091],\n",
      "       device='cuda:0')\n",
      "Predicted text = now it's time to blow this fucker down, predicted ids = tensor([2085, 2009, 1005, 1055, 2051, 2000, 6271, 2023, 6616, 2121, 2091],\n",
      "       device='cuda:0')\n",
      "original text = and i can't stop pretending, labels = tensor([ 1998,  1045,  2064,  1005,  1056,  2644, 12097], device='cuda:0')\n",
      "Predicted text = and i can't stop pretending, predicted ids = tensor([ 1998,  1045,  2064,  1005,  1056,  2644, 12097], device='cuda:0')\n",
      "original text = all in all is all we all are, labels = tensor([2035, 1999, 2035, 2003, 2035, 2057, 2035, 2024], device='cuda:0')\n",
      "Predicted text = all in all is all we all are, predicted ids = tensor([2035, 1999, 2035, 2003, 2035, 2057, 2035, 2024], device='cuda:0')\n",
      "original text = no more mister clean, labels = tensor([ 2053,  2062, 12525,  4550], device='cuda:0')\n",
      "Predicted text = \" more mister clean, predicted ids = tensor([ 1000,  2062, 12525,  4550], device='cuda:0')\n",
      "original text = and here in our hollow we fuse like a family, labels = tensor([ 1998,  2182,  1999,  2256,  8892,  2057, 19976,  2066,  1037,  2155],\n",
      "       device='cuda:0')\n",
      "Predicted text = and here in our hollow we fuse like a family, predicted ids = tensor([ 1998,  2182,  1999,  2256,  8892,  2057, 19976,  2066,  1037,  2155],\n",
      "       device='cuda:0')\n",
      "original text = and the taste of the kissing, labels = tensor([1998, 1996, 5510, 1997, 1996, 7618], device='cuda:0')\n",
      "Predicted text = and the taste of the kissing, predicted ids = tensor([1998, 1996, 5510, 1997, 1996, 7618], device='cuda:0')\n",
      "original text = i'm gonna start all over, labels = tensor([1045, 1005, 1049, 6069, 2707, 2035, 2058], device='cuda:0')\n",
      "Predicted text = i'm gonna start all over, predicted ids = tensor([1045, 1005, 1049, 6069, 2707, 2035, 2058], device='cuda:0')\n",
      "original text = i'm walking to the light, labels = tensor([1045, 1005, 1049, 3788, 2000, 1996, 2422], device='cuda:0')\n",
      "Predicted text = i'm walking to the light, predicted ids = tensor([1045, 1005, 1049, 3788, 2000, 1996, 2422], device='cuda:0')\n",
      "original text = tonight my head is spinning, labels = tensor([3892, 2026, 2132, 2003, 9419], device='cuda:0')\n",
      "Predicted text = new my head is spinning, predicted ids = tensor([2047, 2026, 2132, 2003, 9419], device='cuda:0')\n",
      "original text = take a walk on the wild side of life life, labels = tensor([2202, 1037, 3328, 2006, 1996, 3748, 2217, 1997, 2166, 2166],\n",
      "       device='cuda:0')\n",
      "Predicted text = take a walk on the wild side of life life, predicted ids = tensor([2202, 1037, 3328, 2006, 1996, 3748, 2217, 1997, 2166, 2166],\n",
      "       device='cuda:0')\n",
      "original text = don't don't don't, labels = tensor([2123, 1005, 1056, 2123, 1005, 1056, 2123, 1005, 1056], device='cuda:0')\n",
      "Predicted text = don't don don t don don t, predicted ids = tensor([2123, 1005, 1056, 2123, 2123, 1056, 2123, 2123, 1056], device='cuda:0')\n",
      "original text = of a dying world, labels = tensor([1997, 1037, 5996, 2088], device='cuda:0')\n",
      "Predicted text = and a dying world, predicted ids = tensor([1998, 1037, 5996, 2088], device='cuda:0')\n",
      "original text = rain's falling down from the horizon, labels = tensor([4542, 1005, 1055, 4634, 2091, 2013, 1996, 9154], device='cuda:0')\n",
      "Predicted text = rain's falling down from the horizon, predicted ids = tensor([4542, 1005, 1055, 4634, 2091, 2013, 1996, 9154], device='cuda:0')\n",
      "original text = she was always like a feather in my life, labels = tensor([ 2016,  2001,  2467,  2066,  1037, 15550,  1999,  2026,  2166],\n",
      "       device='cuda:0')\n",
      "Predicted text = i was always like a feather in my life, predicted ids = tensor([ 1045,  2001,  2467,  2066,  1037, 15550,  1999,  2026,  2166],\n",
      "       device='cuda:0')\n",
      "original text = i don't want your remedy, labels = tensor([ 1045,  2123,  1005,  1056,  2215,  2115, 19519], device='cuda:0')\n",
      "Predicted text = i don't want your remedy, predicted ids = tensor([ 1045,  2123,  1005,  1056,  2215,  2115, 19519], device='cuda:0')\n",
      "original text = where i'm going will you follow, labels = tensor([2073, 1045, 1005, 1049, 2183, 2097, 2017, 3582], device='cuda:0')\n",
      "Predicted text = and i'm going will you follow, predicted ids = tensor([1998, 1045, 1005, 1049, 2183, 2097, 2017, 3582], device='cuda:0')\n",
      "original text = if you feel what i feel, labels = tensor([2065, 2017, 2514, 2054, 1045, 2514], device='cuda:0')\n",
      "Predicted text = if you feel what i feel, predicted ids = tensor([2065, 2017, 2514, 2054, 1045, 2514], device='cuda:0')\n",
      "original text = fingers crossed there will be love, labels = tensor([3093, 4625, 2045, 2097, 2022, 2293], device='cuda:0')\n",
      "Predicted text = can crossed there will be love, predicted ids = tensor([2064, 4625, 2045, 2097, 2022, 2293], device='cuda:0')\n",
      "original text = we got a thing, labels = tensor([2057, 2288, 1037, 2518], device='cuda:0')\n",
      "Predicted text = we got a thing, predicted ids = tensor([2057, 2288, 1037, 2518], device='cuda:0')\n",
      "original text = i'll come back begging you, labels = tensor([ 1045,  1005,  2222,  2272,  2067, 12858,  2017], device='cuda:0')\n",
      "Predicted text = i'll come back begging you, predicted ids = tensor([ 1045,  1005,  2222,  2272,  2067, 12858,  2017], device='cuda:0')\n",
      "original text = it's in the wa ter baby, labels = tensor([ 2009,  1005,  1055,  1999,  1996, 11333, 28774,  3336],\n",
      "       device='cuda:0')\n",
      "Predicted text = it's in the wa ter baby, predicted ids = tensor([ 2009,  1005,  1055,  1999,  1996, 11333, 28774,  3336],\n",
      "       device='cuda:0')\n",
      "original text = they say that the world was built for two, labels = tensor([2027, 2360, 2008, 1996, 2088, 2001, 2328, 2005, 2048], device='cuda:0')\n",
      "Predicted text = they say that the world was built for two, predicted ids = tensor([2027, 2360, 2008, 1996, 2088, 2001, 2328, 2005, 2048], device='cuda:0')\n",
      "original text = ' cause i think i'm coming for you, labels = tensor([1005, 3426, 1045, 2228, 1045, 1005, 1049, 2746, 2005, 2017],\n",
      "       device='cuda:0')\n",
      "Predicted text = ' cause i think i'm coming for you, predicted ids = tensor([1005, 3426, 1045, 2228, 1045, 1005, 1049, 2746, 2005, 2017],\n",
      "       device='cuda:0')\n",
      "original text = for all my life, labels = tensor([2005, 2035, 2026, 2166], device='cuda:0')\n",
      "Predicted text = and all my life, predicted ids = tensor([1998, 2035, 2026, 2166], device='cuda:0')\n",
      "original text = and if i wish to comfort the fall, labels = tensor([1998, 2065, 1045, 4299, 2000, 7216, 1996, 2991], device='cuda:0')\n",
      "Predicted text = and if i wish to comfort the fall, predicted ids = tensor([1998, 2065, 1045, 4299, 2000, 7216, 1996, 2991], device='cuda:0')\n",
      "original text = to fix it up make it up somehow, labels = tensor([2000, 8081, 2009, 2039, 2191, 2009, 2039, 5064], device='cuda:0')\n",
      "Predicted text = and fix it up make it up somehow, predicted ids = tensor([1998, 8081, 2009, 2039, 2191, 2009, 2039, 5064], device='cuda:0')\n",
      "original text = that we're allowed to stay, labels = tensor([2008, 2057, 1005, 2128, 3039, 2000, 2994], device='cuda:0')\n",
      "Predicted text = and we're allowed to stay, predicted ids = tensor([1998, 2057, 1005, 2128, 3039, 2000, 2994], device='cuda:0')\n",
      "original text = the whole world could fall away, labels = tensor([1996, 2878, 2088, 2071, 2991, 2185], device='cuda:0')\n",
      "Predicted text = and whole world could fall away, predicted ids = tensor([1998, 2878, 2088, 2071, 2991, 2185], device='cuda:0')\n",
      "original text = my daddy worked all night inthe vanleer coal mine, labels = tensor([ 2026,  8600,  2499,  2035,  2305, 20014,  5369,  3158, 10559,  2099,\n",
      "         5317,  3067], device='cuda:0')\n",
      "Predicted text = i daddy worked all night inthe vanleer coal mine, predicted ids = tensor([ 1045,  8600,  2499,  2035,  2305, 20014,  5369,  3158, 10559,  2099,\n",
      "         5317,  3067], device='cuda:0')\n",
      "original text = i'm coming alive, labels = tensor([1045, 1005, 1049, 2746, 4142], device='cuda:0')\n",
      "Predicted text = i'm coming alive, predicted ids = tensor([1045, 1005, 1049, 2746, 4142], device='cuda:0')\n",
      "original text = in the beginning was a world, labels = tensor([1999, 1996, 2927, 2001, 1037, 2088], device='cuda:0')\n",
      "Predicted text = when the beginning was a world, predicted ids = tensor([2043, 1996, 2927, 2001, 1037, 2088], device='cuda:0')\n",
      "original text = february of last year, labels = tensor([2337, 1997, 2197, 2095], device='cuda:0')\n",
      "Predicted text = may of last year, predicted ids = tensor([2089, 1997, 2197, 2095], device='cuda:0')\n",
      "original text = yes anyone tell me is this, labels = tensor([2748, 3087, 2425, 2033, 2003, 2023], device='cuda:0')\n",
      "Predicted text = yes anyone tell me is this, predicted ids = tensor([2748, 3087, 2425, 2033, 2003, 2023], device='cuda:0')\n",
      "original text = liar killer demon, labels = tensor([16374,  6359,  5698], device='cuda:0')\n",
      "Predicted text = liar killer demon, predicted ids = tensor([16374,  6359,  5698], device='cuda:0')\n",
      "original text = won't you cure my tragedy, labels = tensor([ 2180,  1005,  1056,  2017,  9526,  2026, 10576], device='cuda:0')\n",
      "Predicted text = won't you cure my tragedy, predicted ids = tensor([ 2180,  1005,  1056,  2017,  9526,  2026, 10576], device='cuda:0')\n",
      "original text = but out of line, labels = tensor([2021, 2041, 1997, 2240], device='cuda:0')\n",
      "Predicted text = and out of line, predicted ids = tensor([1998, 2041, 1997, 2240], device='cuda:0')\n",
      "original text = she got her own thing, labels = tensor([2016, 2288, 2014, 2219, 2518], device='cuda:0')\n",
      "Predicted text = i got her own thing, predicted ids = tensor([1045, 2288, 2014, 2219, 2518], device='cuda:0')\n",
      "original text = cause you said this was right, labels = tensor([3426, 2017, 2056, 2023, 2001, 2157], device='cuda:0')\n",
      "Predicted text = cause you said this was right, predicted ids = tensor([3426, 2017, 2056, 2023, 2001, 2157], device='cuda:0')\n",
      "original text = i see you down on your knees, labels = tensor([1045, 2156, 2017, 2091, 2006, 2115, 5042], device='cuda:0')\n",
      "Predicted text = i see you down on your knees, predicted ids = tensor([1045, 2156, 2017, 2091, 2006, 2115, 5042], device='cuda:0')\n",
      "original text = a love like ours will never end, labels = tensor([ 1037,  2293,  2066, 14635,  2097,  2196,  2203], device='cuda:0')\n",
      "Predicted text = and love like ours will never end, predicted ids = tensor([ 1998,  2293,  2066, 14635,  2097,  2196,  2203], device='cuda:0')\n",
      "original text = but i still believe, labels = tensor([2021, 1045, 2145, 2903], device='cuda:0')\n",
      "Predicted text = and i still believe, predicted ids = tensor([1998, 1045, 2145, 2903], device='cuda:0')\n",
      "original text = boy you better do it soon, labels = tensor([2879, 2017, 2488, 2079, 2009, 2574], device='cuda:0')\n",
      "Predicted text = new you better do it soon, predicted ids = tensor([2047, 2017, 2488, 2079, 2009, 2574], device='cuda:0')\n",
      "original text = shattered by rain, labels = tensor([10909,  2011,  4542], device='cuda:0')\n",
      "Predicted text = bang by rain, predicted ids = tensor([9748, 2011, 4542], device='cuda:0')\n",
      "original text = this year to save me from tears, labels = tensor([2023, 2095, 2000, 3828, 2033, 2013, 4000], device='cuda:0')\n",
      "Predicted text = this year to save me from tears, predicted ids = tensor([2023, 2095, 2000, 3828, 2033, 2013, 4000], device='cuda:0')\n",
      "original text = i'm free from your spell, labels = tensor([1045, 1005, 1049, 2489, 2013, 2115, 6297], device='cuda:0')\n",
      "Predicted text = i'm free from your spell, predicted ids = tensor([1045, 1005, 1049, 2489, 2013, 2115, 6297], device='cuda:0')\n",
      "original text = oh and my girlfriend loves me, labels = tensor([2821, 1998, 2026, 6513, 7459, 2033], device='cuda:0')\n",
      "Predicted text = oh and my girlfriend loves me, predicted ids = tensor([2821, 1998, 2026, 6513, 7459, 2033], device='cuda:0')\n",
      "original text = the truth is harder than the pain inside, labels = tensor([1996, 3606, 2003, 6211, 2084, 1996, 3255, 2503], device='cuda:0')\n",
      "Predicted text = and truth is harder than the pain inside, predicted ids = tensor([1998, 3606, 2003, 6211, 2084, 1996, 3255, 2503], device='cuda:0')\n",
      "original text = i try to do the best i can, labels = tensor([1045, 3046, 2000, 2079, 1996, 2190, 1045, 2064], device='cuda:0')\n",
      "Predicted text = i try to do the best i can, predicted ids = tensor([1045, 3046, 2000, 2079, 1996, 2190, 1045, 2064], device='cuda:0')\n",
      "original text = i am here to stay, labels = tensor([1045, 2572, 2182, 2000, 2994], device='cuda:0')\n",
      "Predicted text = i am here to stay, predicted ids = tensor([1045, 2572, 2182, 2000, 2994], device='cuda:0')\n",
      "original text = mitsumeteta, labels = tensor([10210, 23545, 22513,  2050], device='cuda:0')\n",
      "Predicted text = mitsumeteta, predicted ids = tensor([10210, 23545, 22513,  2050], device='cuda:0')\n",
      "original text = it's still you and the moment you met me, labels = tensor([2009, 1005, 1055, 2145, 2017, 1998, 1996, 2617, 2017, 2777, 2033],\n",
      "       device='cuda:0')\n",
      "Predicted text = it's still you and the moment you met me, predicted ids = tensor([2009, 1005, 1055, 2145, 2017, 1998, 1996, 2617, 2017, 2777, 2033],\n",
      "       device='cuda:0')\n",
      "original text = all upon the gods, labels = tensor([2035, 2588, 1996, 5932], device='cuda:0')\n",
      "Predicted text = all upon the gods, predicted ids = tensor([2035, 2588, 1996, 5932], device='cuda:0')\n",
      "original text = somebody tell me why i'm on my own, labels = tensor([8307, 2425, 2033, 2339, 1045, 1005, 1049, 2006, 2026, 2219],\n",
      "       device='cuda:0')\n",
      "Predicted text = somebody tell me why i'm on my own, predicted ids = tensor([8307, 2425, 2033, 2339, 1045, 1005, 1049, 2006, 2026, 2219],\n",
      "       device='cuda:0')\n",
      "original text = that you're one of the lonely, labels = tensor([2008, 2017, 1005, 2128, 2028, 1997, 1996, 9479], device='cuda:0')\n",
      "Predicted text = and you're one of the lonely, predicted ids = tensor([1998, 2017, 1005, 2128, 2028, 1997, 1996, 9479], device='cuda:0')\n",
      "original text = love suicide, labels = tensor([2293, 5920], device='cuda:0')\n",
      "Predicted text = love suicide, predicted ids = tensor([2293, 5920], device='cuda:0')\n",
      "original text = and then you appeared, labels = tensor([1998, 2059, 2017, 2596], device='cuda:0')\n",
      "Predicted text = and then you appeared, predicted ids = tensor([1998, 2059, 2017, 2596], device='cuda:0')\n",
      "original text = her dog days just begun, labels = tensor([2014, 3899, 2420, 2074, 5625], device='cuda:0')\n",
      "Predicted text = you dog days just begun, predicted ids = tensor([2017, 3899, 2420, 2074, 5625], device='cuda:0')\n",
      "original text = now i've swung back down again, labels = tensor([2085, 1045, 1005, 2310, 7671, 2067, 2091, 2153], device='cuda:0')\n",
      "Predicted text = now i've swung back down again, predicted ids = tensor([2085, 1045, 1005, 2310, 7671, 2067, 2091, 2153], device='cuda:0')\n",
      "original text = but tomorrow will bring, labels = tensor([2021, 4826, 2097, 3288], device='cuda:0')\n",
      "Predicted text = and tomorrow will bring, predicted ids = tensor([1998, 4826, 2097, 3288], device='cuda:0')\n",
      "original text = could see it clearly once when you, labels = tensor([2071, 2156, 2009, 4415, 2320, 2043, 2017], device='cuda:0')\n",
      "Predicted text = can see it clearly once when you, predicted ids = tensor([2064, 2156, 2009, 4415, 2320, 2043, 2017], device='cuda:0')\n",
      "original text = born to make mistakes, labels = tensor([ 2141,  2000,  2191, 12051], device='cuda:0')\n",
      "Predicted text = fun to make mistakes, predicted ids = tensor([ 4569,  2000,  2191, 12051], device='cuda:0')\n",
      "original text = discord i'm howlin'at the moon, labels = tensor([12532,  4103,  1045,  1005,  1049, 22912,  2378,  1005,  2012,  1996,\n",
      "         4231], device='cuda:0')\n",
      "Predicted text = discord i'm howlin'at the moon, predicted ids = tensor([12532,  4103,  1045,  1005,  1049, 22912,  2378,  1005,  2012,  1996,\n",
      "         4231], device='cuda:0')\n",
      "original text = a friend who'll tease is better, labels = tensor([ 1037,  2767,  2040,  1005,  2222, 18381,  2003,  2488],\n",
      "       device='cuda:0')\n",
      "Predicted text = and friend who'll tease is better, predicted ids = tensor([ 1998,  2767,  2040,  1005,  2222, 18381,  2003,  2488],\n",
      "       device='cuda:0')\n",
      "original text = how can i be lost, labels = tensor([2129, 2064, 1045, 2022, 2439], device='cuda:0')\n",
      "Predicted text = why can i be lost, predicted ids = tensor([2339, 2064, 1045, 2022, 2439], device='cuda:0')\n",
      "original text = with what you wanna say, labels = tensor([ 2007,  2054,  2017, 10587,  2360], device='cuda:0')\n",
      "Predicted text = i what you wanna say, predicted ids = tensor([ 1045,  2054,  2017, 10587,  2360], device='cuda:0')\n",
      "original text = know my heart, labels = tensor([2113, 2026, 2540], device='cuda:0')\n",
      "Predicted text = can my heart, predicted ids = tensor([2064, 2026, 2540], device='cuda:0')\n",
      "original text = crying forever, labels = tensor([6933, 5091], device='cuda:0')\n",
      "Predicted text = crying forever, predicted ids = tensor([6933, 5091], device='cuda:0')\n",
      "original text = all i know for sure, labels = tensor([2035, 1045, 2113, 2005, 2469], device='cuda:0')\n",
      "Predicted text = all i know for sure, predicted ids = tensor([2035, 1045, 2113, 2005, 2469], device='cuda:0')\n",
      "original text = don't hide behind your false pride, labels = tensor([2123, 1005, 1056, 5342, 2369, 2115, 6270, 6620], device='cuda:0')\n",
      "Predicted text = don't hide behind your false pride, predicted ids = tensor([2123, 1005, 1056, 5342, 2369, 2115, 6270, 6620], device='cuda:0')\n",
      "original text = ' cause the dead can't testify, labels = tensor([ 1005,  3426,  1996,  2757,  2064,  1005,  1056, 19919],\n",
      "       device='cuda:0')\n",
      "Predicted text = ' cause the dead can't testify, predicted ids = tensor([ 1005,  3426,  1996,  2757,  2064,  1005,  1056, 19919],\n",
      "       device='cuda:0')\n",
      "original text = gives me all and nothing, labels = tensor([3957, 2033, 2035, 1998, 2498], device='cuda:0')\n",
      "Predicted text = give me all and nothing, predicted ids = tensor([2507, 2033, 2035, 1998, 2498], device='cuda:0')\n",
      "original text = she's fly effortlessly, labels = tensor([ 2016,  1005,  1055,  4875, 29483], device='cuda:0')\n",
      "Predicted text = i's fly effortlessly, predicted ids = tensor([ 1045,  1005,  1055,  4875, 29483], device='cuda:0')\n",
      "original text = making love to you, labels = tensor([2437, 2293, 2000, 2017], device='cuda:0')\n",
      "Predicted text = i love to you, predicted ids = tensor([1045, 2293, 2000, 2017], device='cuda:0')\n",
      "original text = we both go down together, labels = tensor([2057, 2119, 2175, 2091, 2362], device='cuda:0')\n",
      "Predicted text = we both go down together, predicted ids = tensor([2057, 2119, 2175, 2091, 2362], device='cuda:0')\n",
      "original text = feel the pain of you needles, labels = tensor([ 2514,  1996,  3255,  1997,  2017, 17044], device='cuda:0')\n",
      "Predicted text = feel the pain of you needles, predicted ids = tensor([ 2514,  1996,  3255,  1997,  2017, 17044], device='cuda:0')\n",
      "original text = i wanna let go of the pain i've felt so long, labels = tensor([ 1045, 10587,  2292,  2175,  1997,  1996,  3255,  1045,  1005,  2310,\n",
      "         2371,  2061,  2146], device='cuda:0')\n",
      "Predicted text = i wanna let go of the pain i've felt so long, predicted ids = tensor([ 1045, 10587,  2292,  2175,  1997,  1996,  3255,  1045,  1005,  2310,\n",
      "         2371,  2061,  2146], device='cuda:0')\n",
      "original text = every friday night, labels = tensor([2296, 5958, 2305], device='cuda:0')\n",
      "Predicted text = and friday night, predicted ids = tensor([1998, 5958, 2305], device='cuda:0')\n",
      "original text = our clocks don't chime what a surprise, labels = tensor([ 2256, 20940,  2123,  1005,  1056,  9610,  4168,  2054,  1037,  4474],\n",
      "       device='cuda:0')\n",
      "Predicted text = our clocks don't chime what a surprise, predicted ids = tensor([ 2256, 20940,  2123,  1005,  1056,  9610,  4168,  2054,  1037,  4474],\n",
      "       device='cuda:0')\n",
      "original text = it's my name that's on that jag, labels = tensor([ 2009,  1005,  1055,  2026,  2171,  2008,  1005,  1055,  2006,  2008,\n",
      "        14855,  2290], device='cuda:0')\n",
      "Predicted text = it's my name that's on that jag, predicted ids = tensor([ 2009,  1005,  1055,  2026,  2171,  2008,  1005,  1055,  2006,  2008,\n",
      "        14855,  2290], device='cuda:0')\n",
      "original text = he was a leader of a small gang, labels = tensor([2002, 2001, 1037, 3003, 1997, 1037, 2235, 6080], device='cuda:0')\n",
      "Predicted text = i was a leader of a small gang, predicted ids = tensor([1045, 2001, 1037, 3003, 1997, 1037, 2235, 6080], device='cuda:0')\n",
      "original text = and wasting away with time, labels = tensor([ 1998, 18313,  2185,  2007,  2051], device='cuda:0')\n",
      "Predicted text = and wasting away with time, predicted ids = tensor([ 1998, 18313,  2185,  2007,  2051], device='cuda:0')\n",
      "original text = oo oo oo oo hh hh, labels = tensor([1051, 2080, 1051, 2080, 1051, 2080, 1051, 2080, 1044, 2232, 1044, 2232],\n",
      "       device='cuda:0')\n",
      "Predicted text = o o o o o o o o hh hh, predicted ids = tensor([1051, 1051, 1051, 1051, 1051, 1051, 1051, 1051, 1044, 2232, 1044, 2232],\n",
      "       device='cuda:0')\n",
      "original text = gonna see, labels = tensor([6069, 2156], device='cuda:0')\n",
      "Predicted text = gonna see, predicted ids = tensor([6069, 2156], device='cuda:0')\n",
      "original text = and lay the blanket on the ground, labels = tensor([1998, 3913, 1996, 8768, 2006, 1996, 2598], device='cuda:0')\n",
      "Predicted text = and lay the blanket on the ground, predicted ids = tensor([1998, 3913, 1996, 8768, 2006, 1996, 2598], device='cuda:0')\n",
      "original text = and then i ran like hell, labels = tensor([1998, 2059, 1045, 2743, 2066, 3109], device='cuda:0')\n",
      "Predicted text = and then i ran like hell, predicted ids = tensor([1998, 2059, 1045, 2743, 2066, 3109], device='cuda:0')\n",
      "original text = karma police, labels = tensor([19902,  2610], device='cuda:0')\n",
      "Predicted text = change police, predicted ids = tensor([2689, 2610], device='cuda:0')\n",
      "original text = so long since i can even remember, labels = tensor([2061, 2146, 2144, 1045, 2064, 2130, 3342], device='cuda:0')\n",
      "Predicted text = so long since i can even remember, predicted ids = tensor([2061, 2146, 2144, 1045, 2064, 2130, 3342], device='cuda:0')\n",
      "original text = dreams are made winding, labels = tensor([ 5544,  2024,  2081, 12788], device='cuda:0')\n",
      "Predicted text = dreams are made winding, predicted ids = tensor([ 5544,  2024,  2081, 12788], device='cuda:0')\n",
      "original text = disappointed and passed over, labels = tensor([9364, 1998, 2979, 2058], device='cuda:0')\n",
      "Predicted text = good and passed over, predicted ids = tensor([2204, 1998, 2979, 2058], device='cuda:0')\n",
      "original text = you make me want to forget, labels = tensor([2017, 2191, 2033, 2215, 2000, 5293], device='cuda:0')\n",
      "Predicted text = you make me want to forget, predicted ids = tensor([2017, 2191, 2033, 2215, 2000, 5293], device='cuda:0')\n",
      "original text = i live through your love, labels = tensor([1045, 2444, 2083, 2115, 2293], device='cuda:0')\n",
      "Predicted text = i live through your love, predicted ids = tensor([1045, 2444, 2083, 2115, 2293], device='cuda:0')\n",
      "original text = yeah i would slay yeah i would maim, labels = tensor([ 3398,  1045,  2052, 22889,  4710,  3398,  1045,  2052, 14736,  2213],\n",
      "       device='cuda:0')\n",
      "Predicted text = yeah i would slay yeah i would maim, predicted ids = tensor([ 3398,  1045,  2052, 22889,  4710,  3398,  1045,  2052, 14736,  2213],\n",
      "       device='cuda:0')\n",
      "original text = i'll give it to someone special, labels = tensor([1045, 1005, 2222, 2507, 2009, 2000, 2619, 2569], device='cuda:0')\n",
      "Predicted text = i'll give it to someone special, predicted ids = tensor([1045, 1005, 2222, 2507, 2009, 2000, 2619, 2569], device='cuda:0')\n",
      "original text = sanctified by oppression, labels = tensor([ 2624,  6593,  7810,  2011, 20489], device='cuda:0')\n",
      "Predicted text = newctified by oppression, predicted ids = tensor([ 2047,  6593,  7810,  2011, 20489], device='cuda:0')\n",
      "original text = and many were wakened, labels = tensor([1998, 2116, 2020, 5256, 7228], device='cuda:0')\n",
      "Predicted text = and many were wakened, predicted ids = tensor([1998, 2116, 2020, 5256, 7228], device='cuda:0')\n",
      "original text = hard to be sure, labels = tensor([2524, 2000, 2022, 2469], device='cuda:0')\n",
      "Predicted text = can to be sure, predicted ids = tensor([2064, 2000, 2022, 2469], device='cuda:0')\n",
      "original text = who gave that right to me, labels = tensor([2040, 2435, 2008, 2157, 2000, 2033], device='cuda:0')\n",
      "Predicted text = you gave that right to me, predicted ids = tensor([2017, 2435, 2008, 2157, 2000, 2033], device='cuda:0')\n",
      "original text = as good as new thank god its true, labels = tensor([2004, 2204, 2004, 2047, 4067, 2643, 2049, 2995], device='cuda:0')\n",
      "Predicted text = and good as new thank god its true, predicted ids = tensor([1998, 2204, 2004, 2047, 4067, 2643, 2049, 2995], device='cuda:0')\n",
      "original text = thinkin'bout what we had, labels = tensor([ 2228,  2378,  1005, 10094,  2054,  2057,  2018], device='cuda:0')\n",
      "Predicted text = thinkin'bout what we had, predicted ids = tensor([ 2228,  2378,  1005, 10094,  2054,  2057,  2018], device='cuda:0')\n",
      "original text = that anything should happen, labels = tensor([2008, 2505, 2323, 4148], device='cuda:0')\n",
      "Predicted text = and anything should happen, predicted ids = tensor([1998, 2505, 2323, 4148], device='cuda:0')\n",
      "original text = i'm not just another one of your plays, labels = tensor([1045, 1005, 1049, 2025, 2074, 2178, 2028, 1997, 2115, 3248],\n",
      "       device='cuda:0')\n",
      "Predicted text = i'm not just another one of your plays, predicted ids = tensor([1045, 1005, 1049, 2025, 2074, 2178, 2028, 1997, 2115, 3248],\n",
      "       device='cuda:0')\n",
      "original text = when you play catch without arms, labels = tensor([2043, 2017, 2377, 4608, 2302, 2608], device='cuda:0')\n",
      "Predicted text = and you play catch without arms, predicted ids = tensor([1998, 2017, 2377, 4608, 2302, 2608], device='cuda:0')\n",
      "original text = unconditionally, labels = tensor([ 4895,  8663, 27064,  2135], device='cuda:0')\n",
      "Predicted text = iconditionally, predicted ids = tensor([ 1045,  8663, 27064,  2135], device='cuda:0')\n",
      "original text = my arms feel stronger now than ever before, labels = tensor([2026, 2608, 2514, 6428, 2085, 2084, 2412, 2077], device='cuda:0')\n",
      "Predicted text = i arms feel stronger now than ever before, predicted ids = tensor([1045, 2608, 2514, 6428, 2085, 2084, 2412, 2077], device='cuda:0')\n",
      "original text = but i don't give a damn, labels = tensor([2021, 1045, 2123, 1005, 1056, 2507, 1037, 4365], device='cuda:0')\n",
      "Predicted text = and i don't give a damn, predicted ids = tensor([1998, 1045, 2123, 1005, 1056, 2507, 1037, 4365], device='cuda:0')\n",
      "original text = see the light on your face, labels = tensor([2156, 1996, 2422, 2006, 2115, 2227], device='cuda:0')\n",
      "Predicted text = see the light on your face, predicted ids = tensor([2156, 1996, 2422, 2006, 2115, 2227], device='cuda:0')\n",
      "original text = sometimes i don't recognise my own face, labels = tensor([ 2823,  1045,  2123,  1005,  1056, 17614,  2026,  2219,  2227],\n",
      "       device='cuda:0')\n",
      "Predicted text = sometimes i don't recognise my own face, predicted ids = tensor([ 2823,  1045,  2123,  1005,  1056, 17614,  2026,  2219,  2227],\n",
      "       device='cuda:0')\n",
      "original text = some things are sacred baby, labels = tensor([2070, 2477, 2024, 6730, 3336], device='cuda:0')\n",
      "Predicted text = some things are sacred baby, predicted ids = tensor([2070, 2477, 2024, 6730, 3336], device='cuda:0')\n",
      "original text = i think she understood but she never spoke, labels = tensor([1045, 2228, 2016, 5319, 2021, 2016, 2196, 3764], device='cuda:0')\n",
      "Predicted text = i think she understood but she never spoke, predicted ids = tensor([1045, 2228, 2016, 5319, 2021, 2016, 2196, 3764], device='cuda:0')\n",
      "original text = i've got an aching in my bones, labels = tensor([ 1045,  1005,  2310,  2288,  2019, 14750,  1999,  2026,  5944],\n",
      "       device='cuda:0')\n",
      "Predicted text = i've got an aching in my bones, predicted ids = tensor([ 1045,  1005,  2310,  2288,  2019, 14750,  1999,  2026,  5944],\n",
      "       device='cuda:0')\n",
      "original text = hurroo hurroo, labels = tensor([15876, 18933,  2080, 15876, 18933,  2080], device='cuda:0')\n",
      "Predicted text = ifrroo hurroo, predicted ids = tensor([ 2065, 18933,  2080, 15876, 18933,  2080], device='cuda:0')\n",
      "original text = never enough to forget, labels = tensor([2196, 2438, 2000, 5293], device='cuda:0')\n",
      "Predicted text = never enough to forget, predicted ids = tensor([2196, 2438, 2000, 5293], device='cuda:0')\n",
      "original text = not all i'm, labels = tensor([2025, 2035, 1045, 1005, 1049], device='cuda:0')\n",
      "Predicted text = it all i'm, predicted ids = tensor([2009, 2035, 1045, 1005, 1049], device='cuda:0')\n",
      "original text = lived ever after happily, labels = tensor([ 2973,  2412,  2044, 11361], device='cuda:0')\n",
      "Predicted text = will ever after happily, predicted ids = tensor([ 2097,  2412,  2044, 11361], device='cuda:0')\n",
      "original text = play with the fire drunk and denial, labels = tensor([ 2377,  2007,  1996,  2543,  7144,  1998, 14920], device='cuda:0')\n",
      "Predicted text = play with the fire drunk and denial, predicted ids = tensor([ 2377,  2007,  1996,  2543,  7144,  1998, 14920], device='cuda:0')\n",
      "original text = love shack baby, labels = tensor([ 2293, 22200,  3336], device='cuda:0')\n",
      "Predicted text = love shack baby, predicted ids = tensor([ 2293, 22200,  3336], device='cuda:0')\n",
      "original text = over my heart ohoh, labels = tensor([ 2058,  2026,  2540,  2821, 11631], device='cuda:0')\n",
      "Predicted text = now my heart ohoh, predicted ids = tensor([ 2085,  2026,  2540,  2821, 11631], device='cuda:0')\n",
      "original text = someone i am made for, labels = tensor([2619, 1045, 2572, 2081, 2005], device='cuda:0')\n",
      "Predicted text = i i am made for, predicted ids = tensor([1045, 1045, 2572, 2081, 2005], device='cuda:0')\n",
      "original text = gambling the tiny shards of brass, labels = tensor([12219,  1996,  4714, 23327,  1997,  8782], device='cuda:0')\n",
      "Predicted text = if the tiny shards of brass, predicted ids = tensor([ 2065,  1996,  4714, 23327,  1997,  8782], device='cuda:0')\n",
      "original text = as sunrise comes, labels = tensor([ 2004, 13932,  3310], device='cuda:0')\n",
      "Predicted text = and sunrise comes, predicted ids = tensor([ 1998, 13932,  3310], device='cuda:0')\n",
      "original text = in a fairytale of lies, labels = tensor([ 1999,  1037,  8867, 22059,  1997,  3658], device='cuda:0')\n",
      "Predicted text = when a fairytale of lies, predicted ids = tensor([ 2043,  1037,  8867, 22059,  1997,  3658], device='cuda:0')\n",
      "original text = i can't keep my eyes off of you, labels = tensor([1045, 2064, 1005, 1056, 2562, 2026, 2159, 2125, 1997, 2017],\n",
      "       device='cuda:0')\n",
      "Predicted text = i can't keep my eyes off of you, predicted ids = tensor([1045, 2064, 1005, 1056, 2562, 2026, 2159, 2125, 1997, 2017],\n",
      "       device='cuda:0')\n",
      "original text = i try not to hate it so, labels = tensor([1045, 3046, 2025, 2000, 5223, 2009, 2061], device='cuda:0')\n",
      "Predicted text = i try not to hate it so, predicted ids = tensor([1045, 3046, 2025, 2000, 5223, 2009, 2061], device='cuda:0')\n",
      "original text = we walk an endless mile, labels = tensor([ 2057,  3328,  2019, 10866,  3542], device='cuda:0')\n",
      "Predicted text = we walk an endless mile, predicted ids = tensor([ 2057,  3328,  2019, 10866,  3542], device='cuda:0')\n",
      "original text = there goes my baby, labels = tensor([2045, 3632, 2026, 3336], device='cuda:0')\n",
      "Predicted text = there goes my baby, predicted ids = tensor([2045, 3632, 2026, 3336], device='cuda:0')\n",
      "original text = stay forever, labels = tensor([2994, 5091], device='cuda:0')\n",
      "Predicted text = like forever, predicted ids = tensor([2066, 5091], device='cuda:0')\n",
      "original text = and still you feel like the loneliness, labels = tensor([ 1998,  2145,  2017,  2514,  2066,  1996, 20334], device='cuda:0')\n",
      "Predicted text = and still you feel like the loneliness, predicted ids = tensor([ 1998,  2145,  2017,  2514,  2066,  1996, 20334], device='cuda:0')\n",
      "original text = foes are losing ground retreating to the sound, labels = tensor([22277,  2015,  2024,  3974,  2598, 17512,  2000,  1996,  2614],\n",
      "       device='cuda:0')\n",
      "Predicted text = wises are losing ground retreating to the sound, predicted ids = tensor([ 7968,  2015,  2024,  3974,  2598, 17512,  2000,  1996,  2614],\n",
      "       device='cuda:0')\n",
      "original text = we took you in full of sin and pride, labels = tensor([2057, 2165, 2017, 1999, 2440, 1997, 8254, 1998, 6620], device='cuda:0')\n",
      "Predicted text = we took you in full of sin and pride, predicted ids = tensor([2057, 2165, 2017, 1999, 2440, 1997, 8254, 1998, 6620], device='cuda:0')\n",
      "original text = dance with you baby nooo more, labels = tensor([3153, 2007, 2017, 3336, 2053, 9541, 2062], device='cuda:0')\n",
      "Predicted text = dance with you baby nooo more, predicted ids = tensor([3153, 2007, 2017, 3336, 2053, 9541, 2062], device='cuda:0')\n",
      "original text = and we can loveforever, labels = tensor([ 1998,  2057,  2064,  2293, 29278, 22507], device='cuda:0')\n",
      "Predicted text = and we can loveforever, predicted ids = tensor([ 1998,  2057,  2064,  2293, 29278, 22507], device='cuda:0')\n",
      "original text = being a part of you, labels = tensor([2108, 1037, 2112, 1997, 2017], device='cuda:0')\n",
      "Predicted text = that a part of you, predicted ids = tensor([2008, 1037, 2112, 1997, 2017], device='cuda:0')\n",
      "original text = just show me what it takes to, labels = tensor([2074, 2265, 2033, 2054, 2009, 3138, 2000], device='cuda:0')\n",
      "Predicted text = just show me what it takes to, predicted ids = tensor([2074, 2265, 2033, 2054, 2009, 3138, 2000], device='cuda:0')\n",
      "original text = i wonder what you're doing now, labels = tensor([1045, 4687, 2054, 2017, 1005, 2128, 2725, 2085], device='cuda:0')\n",
      "Predicted text = i wonder what you're doing now, predicted ids = tensor([1045, 4687, 2054, 2017, 1005, 2128, 2725, 2085], device='cuda:0')\n",
      "original text = i cried so many nights, labels = tensor([1045, 6639, 2061, 2116, 6385], device='cuda:0')\n",
      "Predicted text = i cried so many nights, predicted ids = tensor([1045, 6639, 2061, 2116, 6385], device='cuda:0')\n",
      "original text = i need you to need me, labels = tensor([1045, 2342, 2017, 2000, 2342, 2033], device='cuda:0')\n",
      "Predicted text = i need you to need me, predicted ids = tensor([1045, 2342, 2017, 2000, 2342, 2033], device='cuda:0')\n",
      "original text = where no one else can see, labels = tensor([2073, 2053, 2028, 2842, 2064, 2156], device='cuda:0')\n",
      "Predicted text = and no one else can see, predicted ids = tensor([1998, 2053, 2028, 2842, 2064, 2156], device='cuda:0')\n",
      "original text = tell me goodbye tell me goodbye, labels = tensor([2425, 2033, 9119, 2425, 2033, 9119], device='cuda:0')\n",
      "Predicted text = tell me goodbye tell me goodbye, predicted ids = tensor([2425, 2033, 9119, 2425, 2033, 9119], device='cuda:0')\n",
      "original text = she said don't let my door hit your ass, labels = tensor([2016, 2056, 2123, 1005, 1056, 2292, 2026, 2341, 2718, 2115, 4632],\n",
      "       device='cuda:0')\n",
      "Predicted text = i said don't let my door hit your ass, predicted ids = tensor([1045, 2056, 2123, 1005, 1056, 2292, 2026, 2341, 2718, 2115, 4632],\n",
      "       device='cuda:0')\n",
      "original text = ' cos i'm a rocker i'm a roller i'm a rockin'man, labels = tensor([ 1005,  2522,  2015,  1045,  1005,  1049,  1037, 24779,  1045,  1005,\n",
      "         1049,  1037, 11220,  1045,  1005,  1049,  1037,  2600,  2378,  1005,\n",
      "         2158], device='cuda:0')\n",
      "Predicted text = ' cos i'm a rocker i'm a roller i'm a rockin'man, predicted ids = tensor([ 1005,  2522,  2015,  1045,  1005,  1049,  1037, 24779,  1045,  1005,\n",
      "         1049,  1037, 11220,  1045,  1005,  1049,  1037,  2600,  2378,  1005,\n",
      "         2158], device='cuda:0')\n",
      "original text = when the joke's on you yeah, labels = tensor([2043, 1996, 8257, 1005, 1055, 2006, 2017, 3398], device='cuda:0')\n",
      "Predicted text = and the joke's on you yeah, predicted ids = tensor([1998, 1996, 8257, 1005, 1055, 2006, 2017, 3398], device='cuda:0')\n",
      "original text = and someday you feed on a tree frog, labels = tensor([ 1998, 13834,  2017,  5438,  2006,  1037,  3392, 10729],\n",
      "       device='cuda:0')\n",
      "Predicted text = and someday you feed on a tree frog, predicted ids = tensor([ 1998, 13834,  2017,  5438,  2006,  1037,  3392, 10729],\n",
      "       device='cuda:0')\n",
      "original text = i wanti want jessie's girl, labels = tensor([ 1045,  2215,  2072,  2215, 10934,  1005,  1055,  2611],\n",
      "       device='cuda:0')\n",
      "Predicted text = i want i want jessie's girl, predicted ids = tensor([ 1045,  2215,  1045,  2215, 10934,  1005,  1055,  2611],\n",
      "       device='cuda:0')\n",
      "original text = what i'm leaving now, labels = tensor([2054, 1045, 1005, 1049, 2975, 2085], device='cuda:0')\n",
      "Predicted text = what i'm leaving now, predicted ids = tensor([2054, 1045, 1005, 1049, 2975, 2085], device='cuda:0')\n",
      "original text = teachers said it's just a phase, labels = tensor([5089, 2056, 2009, 1005, 1055, 2074, 1037, 4403], device='cuda:0')\n",
      "Predicted text = can said it's just a phase, predicted ids = tensor([2064, 2056, 2009, 1005, 1055, 2074, 1037, 4403], device='cuda:0')\n",
      "original text = a plundering desire, labels = tensor([ 1037, 20228, 20824,  2075,  4792], device='cuda:0')\n",
      "Predicted text = and plundering desire, predicted ids = tensor([ 1998, 20228, 20824,  2075,  4792], device='cuda:0')\n",
      "original text = you're my guiding light, labels = tensor([ 2017,  1005,  2128,  2026, 14669,  2422], device='cuda:0')\n",
      "Predicted text = you're my guiding light, predicted ids = tensor([ 2017,  1005,  2128,  2026, 14669,  2422], device='cuda:0')\n",
      "original text = and reach for the end, labels = tensor([1998, 3362, 2005, 1996, 2203], device='cuda:0')\n",
      "Predicted text = and reach for the end, predicted ids = tensor([1998, 3362, 2005, 1996, 2203], device='cuda:0')\n",
      "original text = running in and out of time, labels = tensor([2770, 1999, 1998, 2041, 1997, 2051], device='cuda:0')\n",
      "Predicted text = good in and in of time, predicted ids = tensor([2204, 1999, 1998, 1999, 1997, 2051], device='cuda:0')\n",
      "original text = want to dive into your ocean, labels = tensor([ 2215,  2000, 11529,  2046,  2115,  4153], device='cuda:0')\n",
      "Predicted text = want to dive into your ocean, predicted ids = tensor([ 2215,  2000, 11529,  2046,  2115,  4153], device='cuda:0')\n",
      "original text = mmh gonna dream tonight, labels = tensor([3461, 2232, 6069, 3959, 3892], device='cuda:0')\n",
      "Predicted text = mmh gonna dream tonight, predicted ids = tensor([3461, 2232, 6069, 3959, 3892], device='cuda:0')\n",
      "original text = when they try to blow it away, labels = tensor([2043, 2027, 3046, 2000, 6271, 2009, 2185], device='cuda:0')\n",
      "Predicted text = and they try to blow it away, predicted ids = tensor([1998, 2027, 3046, 2000, 6271, 2009, 2185], device='cuda:0')\n",
      "original text = laph'wafela khona, labels = tensor([ 5001,  2232,  1005, 11333,  7959,  2721,  1047,  8747,  2050],\n",
      "       device='cuda:0')\n",
      "Predicted text = loveh'wafela khona, predicted ids = tensor([ 2293,  2232,  1005, 11333,  7959,  2721,  1047,  8747,  2050],\n",
      "       device='cuda:0')\n",
      "original text = you can't refuse, labels = tensor([ 2017,  2064,  1005,  1056, 10214], device='cuda:0')\n",
      "Predicted text = you can't refuse, predicted ids = tensor([ 2017,  2064,  1005,  1056, 10214], device='cuda:0')\n",
      "original text = give me something to believe in, labels = tensor([2507, 2033, 2242, 2000, 2903, 1999], device='cuda:0')\n",
      "Predicted text = give me something to believe in, predicted ids = tensor([2507, 2033, 2242, 2000, 2903, 1999], device='cuda:0')\n",
      "original text = oh hug him, labels = tensor([2821, 8549, 2032], device='cuda:0')\n",
      "Predicted text = oh hug him, predicted ids = tensor([2821, 8549, 2032], device='cuda:0')\n",
      "original text = still craving your kiss, labels = tensor([ 2145, 26369,  2115,  3610], device='cuda:0')\n",
      "Predicted text = just craving your kiss, predicted ids = tensor([ 2074, 26369,  2115,  3610], device='cuda:0')\n",
      "original text = you know that i protect you, labels = tensor([2017, 2113, 2008, 1045, 4047, 2017], device='cuda:0')\n",
      "Predicted text = you know that i protect you, predicted ids = tensor([2017, 2113, 2008, 1045, 4047, 2017], device='cuda:0')\n",
      "original text = just give me some sweet candy, labels = tensor([2074, 2507, 2033, 2070, 4086, 9485], device='cuda:0')\n",
      "Predicted text = just give me some sweet candy, predicted ids = tensor([2074, 2507, 2033, 2070, 4086, 9485], device='cuda:0')\n",
      "original text = from the top to the bottom bottom to top i stop, labels = tensor([2013, 1996, 2327, 2000, 1996, 3953, 3953, 2000, 2327, 1045, 2644],\n",
      "       device='cuda:0')\n",
      "Predicted text = in the top to the bottom bottom to top i stop, predicted ids = tensor([1999, 1996, 2327, 2000, 1996, 3953, 3953, 2000, 2327, 1045, 2644],\n",
      "       device='cuda:0')\n",
      "original text = it feels like everything, labels = tensor([2009, 5683, 2066, 2673], device='cuda:0')\n",
      "Predicted text = it feels like everything, predicted ids = tensor([2009, 5683, 2066, 2673], device='cuda:0')\n",
      "original text = this is the way i need to wake, labels = tensor([2023, 2003, 1996, 2126, 1045, 2342, 2000, 5256], device='cuda:0')\n",
      "Predicted text = this is the way i need to wake, predicted ids = tensor([2023, 2003, 1996, 2126, 1045, 2342, 2000, 5256], device='cuda:0')\n",
      "original text = give them all back to you, labels = tensor([2507, 2068, 2035, 2067, 2000, 2017], device='cuda:0')\n",
      "Predicted text = give them all back to you, predicted ids = tensor([2507, 2068, 2035, 2067, 2000, 2017], device='cuda:0')\n",
      "original text = if everyour world starts crashing down, labels = tensor([ 2065,  2296,  8162,  2088,  4627, 12894,  2091], device='cuda:0')\n",
      "Predicted text = if everyour world starts crashing down, predicted ids = tensor([ 2065,  2296,  8162,  2088,  4627, 12894,  2091], device='cuda:0')\n",
      "original text = from the sky, labels = tensor([2013, 1996, 3712], device='cuda:0')\n",
      "Predicted text = in the sky, predicted ids = tensor([1999, 1996, 3712], device='cuda:0')\n",
      "original text = no one ever stop believing this the journey of our lives, labels = tensor([2053, 2028, 2412, 2644, 8929, 2023, 1996, 4990, 1997, 2256, 3268],\n",
      "       device='cuda:0')\n",
      "Predicted text = \" one ever stop believing this the journey of our lives, predicted ids = tensor([1000, 2028, 2412, 2644, 8929, 2023, 1996, 4990, 1997, 2256, 3268],\n",
      "       device='cuda:0')\n",
      "original text = creating a love that can not be shared, labels = tensor([4526, 1037, 2293, 2008, 2064, 2025, 2022, 4207], device='cuda:0')\n",
      "Predicted text = hearts a love that can can be shared, predicted ids = tensor([8072, 1037, 2293, 2008, 2064, 2064, 2022, 4207], device='cuda:0')\n",
      "original text = another night another day goes by, labels = tensor([2178, 2305, 2178, 2154, 3632, 2011], device='cuda:0')\n",
      "Predicted text = the night another day goes by, predicted ids = tensor([1996, 2305, 2178, 2154, 3632, 2011], device='cuda:0')\n",
      "original text = don't hurt me with your lies, labels = tensor([2123, 1005, 1056, 3480, 2033, 2007, 2115, 3658], device='cuda:0')\n",
      "Predicted text = don't hurt me with your lies, predicted ids = tensor([2123, 1005, 1056, 3480, 2033, 2007, 2115, 3658], device='cuda:0')\n",
      "original text = don't take the girl, labels = tensor([2123, 1005, 1056, 2202, 1996, 2611], device='cuda:0')\n",
      "Predicted text = don't take the girl, predicted ids = tensor([2123, 1005, 1056, 2202, 1996, 2611], device='cuda:0')\n",
      "original text = why be afraid, labels = tensor([2339, 2022, 4452], device='cuda:0')\n",
      "Predicted text = why be afraid, predicted ids = tensor([2339, 2022, 4452], device='cuda:0')\n",
      "original text = for you and your denial, labels = tensor([ 2005,  2017,  1998,  2115, 14920], device='cuda:0')\n",
      "Predicted text = and you and your denial, predicted ids = tensor([ 1998,  2017,  1998,  2115, 14920], device='cuda:0')\n",
      "original text = yes i want you, labels = tensor([2748, 1045, 2215, 2017], device='cuda:0')\n",
      "Predicted text = yes i want you, predicted ids = tensor([2748, 1045, 2215, 2017], device='cuda:0')\n",
      "original text = and don't go hoping for a miracle, labels = tensor([1998, 2123, 1005, 1056, 2175, 5327, 2005, 1037, 9727], device='cuda:0')\n",
      "Predicted text = and don't go hoping for a miracle, predicted ids = tensor([1998, 2123, 1005, 1056, 2175, 5327, 2005, 1037, 9727], device='cuda:0')\n",
      "original text = is like a pipe, labels = tensor([2003, 2066, 1037, 8667], device='cuda:0')\n",
      "Predicted text = is like a pipe, predicted ids = tensor([2003, 2066, 1037, 8667], device='cuda:0')\n",
      "original text = we are the young so raise your hands, labels = tensor([2057, 2024, 1996, 2402, 2061, 5333, 2115, 2398], device='cuda:0')\n",
      "Predicted text = we are the young so raise your hands, predicted ids = tensor([2057, 2024, 1996, 2402, 2061, 5333, 2115, 2398], device='cuda:0')\n",
      "original text = are of a girl who's lost and broken, labels = tensor([2024, 1997, 1037, 2611, 2040, 1005, 1055, 2439, 1998, 3714],\n",
      "       device='cuda:0')\n",
      "Predicted text = you of a girl who's lost and broken, predicted ids = tensor([2017, 1997, 1037, 2611, 2040, 1005, 1055, 2439, 1998, 3714],\n",
      "       device='cuda:0')\n",
      "original text = if youdon't turn andwalk away, labels = tensor([ 2065,  2017,  5280,  1005,  1056,  2735,  1998, 17122,  2185],\n",
      "       device='cuda:0')\n",
      "Predicted text = if youdon't turn andwalk away, predicted ids = tensor([ 2065,  2017,  5280,  1005,  1056,  2735,  1998, 17122,  2185],\n",
      "       device='cuda:0')\n",
      "original text = to thepulse of the feedback current, labels = tensor([ 2000,  1996, 14289,  4877,  2063,  1997,  1996, 12247,  2783],\n",
      "       device='cuda:0')\n",
      "Predicted text = and thepulse of the feedback current, predicted ids = tensor([ 1998,  1996, 14289,  4877,  2063,  1997,  1996, 12247,  2783],\n",
      "       device='cuda:0')\n",
      "original text = the clock is counting down, labels = tensor([ 1996,  5119,  2003, 10320,  2091], device='cuda:0')\n",
      "Predicted text = and clock is counting down, predicted ids = tensor([ 1998,  5119,  2003, 10320,  2091], device='cuda:0')\n",
      "original text = but you know i like it like it like, labels = tensor([2021, 2017, 2113, 1045, 2066, 2009, 2066, 2009, 2066], device='cuda:0')\n",
      "Predicted text = and you know i like it like it like, predicted ids = tensor([1998, 2017, 2113, 1045, 2066, 2009, 2066, 2009, 2066], device='cuda:0')\n",
      "original text = but we lost it, labels = tensor([2021, 2057, 2439, 2009], device='cuda:0')\n",
      "Predicted text = and we lost it, predicted ids = tensor([1998, 2057, 2439, 2009], device='cuda:0')\n",
      "original text = and we're never coming down down down, labels = tensor([1998, 2057, 1005, 2128, 2196, 2746, 2091, 2091, 2091], device='cuda:0')\n",
      "Predicted text = and we're never coming down down down, predicted ids = tensor([1998, 2057, 1005, 2128, 2196, 2746, 2091, 2091, 2091], device='cuda:0')\n",
      "original text = who wants to live forever, labels = tensor([2040, 4122, 2000, 2444, 5091], device='cuda:0')\n",
      "Predicted text = you wants to live forever, predicted ids = tensor([2017, 4122, 2000, 2444, 5091], device='cuda:0')\n",
      "original text = run around on me i'd sooner die without, labels = tensor([ 2448,  2105,  2006,  2033,  1045,  1005,  1040, 10076,  3280,  2302],\n",
      "       device='cuda:0')\n",
      "Predicted text = run around on me i'd sooner die without, predicted ids = tensor([ 2448,  2105,  2006,  2033,  1045,  1005,  1040, 10076,  3280,  2302],\n",
      "       device='cuda:0')\n",
      "original text = my skin is theirs, labels = tensor([ 2026,  3096,  2003, 17156], device='cuda:0')\n",
      "Predicted text = i skin is theirs, predicted ids = tensor([ 1045,  3096,  2003, 17156], device='cuda:0')\n",
      "original text = endlessly searching for you, labels = tensor([10866,  2135,  6575,  2005,  2017], device='cuda:0')\n",
      "Predicted text = lovely searching for you, predicted ids = tensor([2293, 2135, 6575, 2005, 2017], device='cuda:0')\n",
      "original text = if i turn my back i'm defenseless, labels = tensor([2065, 1045, 2735, 2026, 2067, 1045, 1005, 1049, 3639, 3238],\n",
      "       device='cuda:0')\n",
      "Predicted text = if i turn my back i'm defenseless, predicted ids = tensor([2065, 1045, 2735, 2026, 2067, 1045, 1005, 1049, 3639, 3238],\n",
      "       device='cuda:0')\n",
      "original text = on my knees and out of luck, labels = tensor([2006, 2026, 5042, 1998, 2041, 1997, 6735], device='cuda:0')\n",
      "Predicted text = and my knees and out of luck, predicted ids = tensor([1998, 2026, 5042, 1998, 2041, 1997, 6735], device='cuda:0')\n",
      "original text = i wanna feel you in my arms again, labels = tensor([ 1045, 10587,  2514,  2017,  1999,  2026,  2608,  2153],\n",
      "       device='cuda:0')\n",
      "Predicted text = i wanna feel you in my arms again, predicted ids = tensor([ 1045, 10587,  2514,  2017,  1999,  2026,  2608,  2153],\n",
      "       device='cuda:0')\n",
      "original text = with that look in your eyes, labels = tensor([2007, 2008, 2298, 1999, 2115, 2159], device='cuda:0')\n",
      "Predicted text = i that look in your eyes, predicted ids = tensor([1045, 2008, 2298, 1999, 2115, 2159], device='cuda:0')\n",
      "original text = it doesn't seem right, labels = tensor([2009, 2987, 1005, 1056, 4025, 2157], device='cuda:0')\n",
      "Predicted text = it doesn't seem right, predicted ids = tensor([2009, 2987, 1005, 1056, 4025, 2157], device='cuda:0')\n",
      "original text = hush my darlin'don't feel my darling, labels = tensor([20261,  2026, 18243,  4115,  1005,  2123,  1005,  1056,  2514,  2026,\n",
      "         9548], device='cuda:0')\n",
      "Predicted text = hush my darlin'don't feel my darling, predicted ids = tensor([20261,  2026, 18243,  4115,  1005,  2123,  1005,  1056,  2514,  2026,\n",
      "         9548], device='cuda:0')\n",
      "original text = hold you maybe no one told you, labels = tensor([2907, 2017, 2672, 2053, 2028, 2409, 2017], device='cuda:0')\n",
      "Predicted text = hold you maybe no one told you, predicted ids = tensor([2907, 2017, 2672, 2053, 2028, 2409, 2017], device='cuda:0')\n",
      "original text = eoreumgongju osyeotda, labels = tensor([ 1041,  5686,  2819, 17036,  9103,  9808,  6672,  4140,  2850],\n",
      "       device='cuda:0')\n",
      "Predicted text = eoreumgongju osyeotda, predicted ids = tensor([ 1041,  5686,  2819, 17036,  9103,  9808,  6672,  4140,  2850],\n",
      "       device='cuda:0')\n",
      "original text = of your kingdom, labels = tensor([1997, 2115, 2983], device='cuda:0')\n",
      "Predicted text = and your kingdom, predicted ids = tensor([1998, 2115, 2983], device='cuda:0')\n",
      "original text = some people are born for each other, labels = tensor([2070, 2111, 2024, 2141, 2005, 2169, 2060], device='cuda:0')\n",
      "Predicted text = some people are born for each other, predicted ids = tensor([2070, 2111, 2024, 2141, 2005, 2169, 2060], device='cuda:0')\n",
      "original text = no chance for one more day, labels = tensor([2053, 3382, 2005, 2028, 2062, 2154], device='cuda:0')\n",
      "Predicted text = \" chance for one more day, predicted ids = tensor([1000, 3382, 2005, 2028, 2062, 2154], device='cuda:0')\n",
      "original text = i'm thinkin bout all that still matters is love ever after, labels = tensor([ 1045,  1005,  1049,  2228,  2378, 10094,  2035,  2008,  2145,  5609,\n",
      "         2003,  2293,  2412,  2044], device='cuda:0')\n",
      "Predicted text = i'm thinkin bout all that still matters is love ever after, predicted ids = tensor([ 1045,  1005,  1049,  2228,  2378, 10094,  2035,  2008,  2145,  5609,\n",
      "         2003,  2293,  2412,  2044], device='cuda:0')\n",
      "original text = demons cluttering around, labels = tensor([ 7942, 18856, 26878,  2075,  2105], device='cuda:0')\n",
      "Predicted text = you cluttering around, predicted ids = tensor([ 2017, 18856, 26878,  2075,  2105], device='cuda:0')\n",
      "original text = life is but a dream, labels = tensor([2166, 2003, 2021, 1037, 3959], device='cuda:0')\n",
      "Predicted text = life is but a dream, predicted ids = tensor([2166, 2003, 2021, 1037, 3959], device='cuda:0')\n",
      "original text = i know i'll often stop and think about them, labels = tensor([1045, 2113, 1045, 1005, 2222, 2411, 2644, 1998, 2228, 2055, 2068],\n",
      "       device='cuda:0')\n",
      "Predicted text = i know i'll often stop and think about them, predicted ids = tensor([1045, 2113, 1045, 1005, 2222, 2411, 2644, 1998, 2228, 2055, 2068],\n",
      "       device='cuda:0')\n",
      "original text = i i'm not the only one, labels = tensor([1045, 1045, 1005, 1049, 2025, 1996, 2069, 2028], device='cuda:0')\n",
      "Predicted text = i i'm not the only one, predicted ids = tensor([1045, 1045, 1005, 1049, 2025, 1996, 2069, 2028], device='cuda:0')\n",
      "original text = when you don't know yourself, labels = tensor([2043, 2017, 2123, 1005, 1056, 2113, 4426], device='cuda:0')\n",
      "Predicted text = and you don't know yourself, predicted ids = tensor([1998, 2017, 2123, 1005, 1056, 2113, 4426], device='cuda:0')\n",
      "original text = and they were like northern stars, labels = tensor([1998, 2027, 2020, 2066, 2642, 3340], device='cuda:0')\n",
      "Predicted text = and they were like northern stars, predicted ids = tensor([1998, 2027, 2020, 2066, 2642, 3340], device='cuda:0')\n",
      "original text = we can truly say, labels = tensor([2057, 2064, 5621, 2360], device='cuda:0')\n",
      "Predicted text = we can truly say, predicted ids = tensor([2057, 2064, 5621, 2360], device='cuda:0')\n",
      "original text = we were so young, labels = tensor([2057, 2020, 2061, 2402], device='cuda:0')\n",
      "Predicted text = we were so young, predicted ids = tensor([2057, 2020, 2061, 2402], device='cuda:0')\n",
      "original text = she goes dancin'on down the street, labels = tensor([ 2016,  3632,  4907, 15459,  1005,  2006,  2091,  1996,  2395],\n",
      "       device='cuda:0')\n",
      "Predicted text = i goes dancin'on down the street, predicted ids = tensor([ 1045,  3632,  4907, 15459,  1005,  2006,  2091,  1996,  2395],\n",
      "       device='cuda:0')\n",
      "original text = bballi narabwa, labels = tensor([22861,  8095,  2072, 27544,  2497,  4213], device='cuda:0')\n",
      "Predicted text = tomorrowalli narabwa, predicted ids = tensor([ 4826,  8095,  2072, 27544,  2497,  4213], device='cuda:0')\n",
      "original text = christian's lesson's what he's been sold, labels = tensor([ 3017,  1005,  1055, 10800,  1005,  1055,  2054,  2002,  1005,  1055,\n",
      "         2042,  2853], device='cuda:0')\n",
      "Predicted text = never's lesson's what he's been sold, predicted ids = tensor([ 2196,  1005,  1055, 10800,  1005,  1055,  2054,  2002,  1005,  1055,\n",
      "         2042,  2853], device='cuda:0')\n",
      "original text = what's wrong for me, labels = tensor([2054, 1005, 1055, 3308, 2005, 2033], device='cuda:0')\n",
      "Predicted text = what's wrong for me, predicted ids = tensor([2054, 1005, 1055, 3308, 2005, 2033], device='cuda:0')\n",
      "original text = this beretta of the night, labels = tensor([ 2023,  2022, 13465,  2696,  1997,  1996,  2305], device='cuda:0')\n",
      "Predicted text = this beretta of the night, predicted ids = tensor([ 2023,  2022, 13465,  2696,  1997,  1996,  2305], device='cuda:0')\n",
      "original text = but the heartache lives on inside, labels = tensor([ 2021,  1996,  2540, 15395,  3268,  2006,  2503], device='cuda:0')\n",
      "Predicted text = and the heartache lives on inside, predicted ids = tensor([ 1998,  1996,  2540, 15395,  3268,  2006,  2503], device='cuda:0')\n",
      "original text = don't walk away, labels = tensor([2123, 1005, 1056, 3328, 2185], device='cuda:0')\n",
      "Predicted text = don't walk away, predicted ids = tensor([2123, 1005, 1056, 3328, 2185], device='cuda:0')\n",
      "original text = feeling like i matter too, labels = tensor([3110, 2066, 1045, 3043, 2205], device='cuda:0')\n",
      "Predicted text = feeling like i matter too, predicted ids = tensor([3110, 2066, 1045, 3043, 2205], device='cuda:0')\n",
      "original text = can't take no more, labels = tensor([2064, 1005, 1056, 2202, 2053, 2062], device='cuda:0')\n",
      "Predicted text = can't take no more, predicted ids = tensor([2064, 1005, 1056, 2202, 2053, 2062], device='cuda:0')\n",
      "original text = unbreak my, labels = tensor([ 4895, 23890,  2026], device='cuda:0')\n",
      "Predicted text = ibreak my, predicted ids = tensor([ 1045, 23890,  2026], device='cuda:0')\n",
      "original text = how many times before, labels = tensor([2129, 2116, 2335, 2077], device='cuda:0')\n",
      "Predicted text = why many times before, predicted ids = tensor([2339, 2116, 2335, 2077], device='cuda:0')\n",
      "original text = you know i think i recognize your face, labels = tensor([2017, 2113, 1045, 2228, 1045, 6807, 2115, 2227], device='cuda:0')\n",
      "Predicted text = you know i think i recognize your face, predicted ids = tensor([2017, 2113, 1045, 2228, 1045, 6807, 2115, 2227], device='cuda:0')\n",
      "original text = the way that i want to, labels = tensor([1996, 2126, 2008, 1045, 2215, 2000], device='cuda:0')\n",
      "Predicted text = and way that i want to, predicted ids = tensor([1998, 2126, 2008, 1045, 2215, 2000], device='cuda:0')\n",
      "original text = say you've knocked off for a smoko, labels = tensor([ 2360,  2017,  1005,  2310,  6573,  2125,  2005,  1037, 15488, 16366],\n",
      "       device='cuda:0')\n",
      "Predicted text = say you've knocked off for a smoko, predicted ids = tensor([ 2360,  2017,  1005,  2310,  6573,  2125,  2005,  1037, 15488, 16366],\n",
      "       device='cuda:0')\n",
      "original text = that's why i love her, labels = tensor([2008, 1005, 1055, 2339, 1045, 2293, 2014], device='cuda:0')\n",
      "Predicted text = and's why i love her, predicted ids = tensor([1998, 1005, 1055, 2339, 1045, 2293, 2014], device='cuda:0')\n",
      "original text = into your head, labels = tensor([2046, 2115, 2132], device='cuda:0')\n",
      "Predicted text = so your head, predicted ids = tensor([2061, 2115, 2132], device='cuda:0')\n",
      "original text = in the eye of the tornado, labels = tensor([ 1999,  1996,  3239,  1997,  1996, 11352], device='cuda:0')\n",
      "Predicted text = when the eye of the tornado, predicted ids = tensor([ 2043,  1996,  3239,  1997,  1996, 11352], device='cuda:0')\n",
      "original text = i know i saw you singing, labels = tensor([1045, 2113, 1045, 2387, 2017, 4823], device='cuda:0')\n",
      "Predicted text = i know i saw you singing, predicted ids = tensor([1045, 2113, 1045, 2387, 2017, 4823], device='cuda:0')\n",
      "original text = and my feet step the beats like a drum, labels = tensor([ 1998,  2026,  2519,  3357,  1996, 10299,  2066,  1037,  6943],\n",
      "       device='cuda:0')\n",
      "Predicted text = and my feet step the beats like a drum, predicted ids = tensor([ 1998,  2026,  2519,  3357,  1996, 10299,  2066,  1037,  6943],\n",
      "       device='cuda:0')\n",
      "original text = when i woke up the rain was pouring down, labels = tensor([ 2043,  1045,  8271,  2039,  1996,  4542,  2001, 13053,  2091],\n",
      "       device='cuda:0')\n",
      "Predicted text = and i woke up the rain was pouring down, predicted ids = tensor([ 1998,  1045,  8271,  2039,  1996,  4542,  2001, 13053,  2091],\n",
      "       device='cuda:0')\n",
      "original text = i journey through, labels = tensor([1045, 4990, 2083], device='cuda:0')\n",
      "Predicted text = i journey through, predicted ids = tensor([1045, 4990, 2083], device='cuda:0')\n",
      "original text = thinking on you in the final throes, labels = tensor([ 3241,  2006,  2017,  1999,  1996,  2345, 16215,  3217,  2229],\n",
      "       device='cuda:0')\n",
      "Predicted text = thinking on you in the final throes, predicted ids = tensor([ 3241,  2006,  2017,  1999,  1996,  2345, 16215,  3217,  2229],\n",
      "       device='cuda:0')\n",
      "original text = no miss on her own, labels = tensor([2053, 3335, 2006, 2014, 2219], device='cuda:0')\n",
      "Predicted text = \" miss on her own, predicted ids = tensor([1000, 3335, 2006, 2014, 2219], device='cuda:0')\n",
      "original text = like a week in the desert, labels = tensor([2066, 1037, 2733, 1999, 1996, 5532], device='cuda:0')\n",
      "Predicted text = like a week in the desert, predicted ids = tensor([2066, 1037, 2733, 1999, 1996, 5532], device='cuda:0')\n",
      "original text = the tank is empty let it dry, labels = tensor([1996, 4951, 2003, 4064, 2292, 2009, 4318], device='cuda:0')\n",
      "Predicted text = and tank is empty let it dry, predicted ids = tensor([1998, 4951, 2003, 4064, 2292, 2009, 4318], device='cuda:0')\n",
      "original text = thank god for understan ding, labels = tensor([ 4067,  2643,  2005,  2104, 12693, 22033], device='cuda:0')\n",
      "Predicted text = i god for understan ding, predicted ids = tensor([ 1045,  2643,  2005,  2104, 12693, 22033], device='cuda:0')\n",
      "original text = always remember me, labels = tensor([2467, 3342, 2033], device='cuda:0')\n",
      "Predicted text = always remember me, predicted ids = tensor([2467, 3342, 2033], device='cuda:0')\n",
      "original text = where stories all ring true, labels = tensor([2073, 3441, 2035, 3614, 2995], device='cuda:0')\n",
      "Predicted text = and stories all ring true, predicted ids = tensor([1998, 3441, 2035, 3614, 2995], device='cuda:0')\n",
      "original text = i don't feel, labels = tensor([1045, 2123, 1005, 1056, 2514], device='cuda:0')\n",
      "Predicted text = i don't feel, predicted ids = tensor([1045, 2123, 1005, 1056, 2514], device='cuda:0')\n",
      "original text = gonna dress you up in my love, labels = tensor([6069, 4377, 2017, 2039, 1999, 2026, 2293], device='cuda:0')\n",
      "Predicted text = gonna dress you up in my love, predicted ids = tensor([6069, 4377, 2017, 2039, 1999, 2026, 2293], device='cuda:0')\n",
      "original text = you gotta know it's right, labels = tensor([ 2017, 10657,  2113,  2009,  1005,  1055,  2157], device='cuda:0')\n",
      "Predicted text = you gotta know it's right, predicted ids = tensor([ 2017, 10657,  2113,  2009,  1005,  1055,  2157], device='cuda:0')\n",
      "original text = it's a fool who thinks that love, labels = tensor([2009, 1005, 1055, 1037, 7966, 2040, 6732, 2008, 2293], device='cuda:0')\n",
      "Predicted text = it's a fool who thinks that love, predicted ids = tensor([2009, 1005, 1055, 1037, 7966, 2040, 6732, 2008, 2293], device='cuda:0')\n",
      "original text = i fall into a dark hole and, labels = tensor([1045, 2991, 2046, 1037, 2601, 4920, 1998], device='cuda:0')\n",
      "Predicted text = i fall into a dark hole and, predicted ids = tensor([1045, 2991, 2046, 1037, 2601, 4920, 1998], device='cuda:0')\n",
      "original text = i will never ask if you don't ever tell me, labels = tensor([1045, 2097, 2196, 3198, 2065, 2017, 2123, 1005, 1056, 2412, 2425, 2033],\n",
      "       device='cuda:0')\n",
      "Predicted text = i will never ask if you don't ever tell me, predicted ids = tensor([1045, 2097, 2196, 3198, 2065, 2017, 2123, 1005, 1056, 2412, 2425, 2033],\n",
      "       device='cuda:0')\n",
      "original text = i'll read to you here save your eyes, labels = tensor([1045, 1005, 2222, 3191, 2000, 2017, 2182, 3828, 2115, 2159],\n",
      "       device='cuda:0')\n",
      "Predicted text = i'll read to you here save your eyes, predicted ids = tensor([1045, 1005, 2222, 3191, 2000, 2017, 2182, 3828, 2115, 2159],\n",
      "       device='cuda:0')\n",
      "original text = don't wanna take a fall it's best to break it up, labels = tensor([ 2123,  1005,  1056, 10587,  2202,  1037,  2991,  2009,  1005,  1055,\n",
      "         2190,  2000,  3338,  2009,  2039], device='cuda:0')\n",
      "Predicted text = don't wanna take a fall it's best to break it up, predicted ids = tensor([ 2123,  1005,  1056, 10587,  2202,  1037,  2991,  2009,  1005,  1055,\n",
      "         2190,  2000,  3338,  2009,  2039], device='cuda:0')\n",
      "original text = i wish that i could forget you, labels = tensor([1045, 4299, 2008, 1045, 2071, 5293, 2017], device='cuda:0')\n",
      "Predicted text = i wish that i could forget you, predicted ids = tensor([1045, 4299, 2008, 1045, 2071, 5293, 2017], device='cuda:0')\n",
      "original text = if we live a life in fear, labels = tensor([2065, 2057, 2444, 1037, 2166, 1999, 3571], device='cuda:0')\n",
      "Predicted text = if we live a life in fear, predicted ids = tensor([2065, 2057, 2444, 1037, 2166, 1999, 3571], device='cuda:0')\n",
      "original text = let the moment take you, labels = tensor([2292, 1996, 2617, 2202, 2017], device='cuda:0')\n",
      "Predicted text = let the moment take you, predicted ids = tensor([2292, 1996, 2617, 2202, 2017], device='cuda:0')\n",
      "original text = can you read my mind, labels = tensor([2064, 2017, 3191, 2026, 2568], device='cuda:0')\n",
      "Predicted text = can you read my mind, predicted ids = tensor([2064, 2017, 3191, 2026, 2568], device='cuda:0')\n",
      "original text = icometoyoudefensesdown, labels = tensor([24582,  8462, 29578, 19224, 27235, 12325, 16150, 12384],\n",
      "       device='cuda:0')\n",
      "Predicted text = icometoyoudefensesdown, predicted ids = tensor([24582,  8462, 29578, 19224, 27235, 12325, 16150, 12384],\n",
      "       device='cuda:0')\n",
      "original text = somehow all that's left are, labels = tensor([5064, 2035, 2008, 1005, 1055, 2187, 2024], device='cuda:0')\n",
      "Predicted text = everything all that's left are, predicted ids = tensor([2673, 2035, 2008, 1005, 1055, 2187, 2024], device='cuda:0')\n",
      "original text = mysteryland, labels = tensor([6547, 3122], device='cuda:0')\n",
      "Predicted text = mysteryland, predicted ids = tensor([6547, 3122], device='cuda:0')\n",
      "original text = and now the bells are ringingla la la la la, labels = tensor([ 1998,  2085,  1996, 10118,  2024, 13060,  2721,  2474,  2474,  2474,\n",
      "         2474], device='cuda:0')\n",
      "Predicted text = and now the bells are ringingla la la la la, predicted ids = tensor([ 1998,  2085,  1996, 10118,  2024, 13060,  2721,  2474,  2474,  2474,\n",
      "         2474], device='cuda:0')\n",
      "original text = hey louise, labels = tensor([4931, 8227], device='cuda:0')\n",
      "Predicted text = hey louise, predicted ids = tensor([4931, 8227], device='cuda:0')\n",
      "original text = somewhere i belong, labels = tensor([4873, 1045, 7141], device='cuda:0')\n",
      "Predicted text = like i belong, predicted ids = tensor([2066, 1045, 7141], device='cuda:0')\n",
      "original text = anybody can be a singer, labels = tensor([10334,  2064,  2022,  1037,  3220], device='cuda:0')\n",
      "Predicted text = anybody can be a singer, predicted ids = tensor([10334,  2064,  2022,  1037,  3220], device='cuda:0')\n",
      "original text = don't look back now, labels = tensor([2123, 1005, 1056, 2298, 2067, 2085], device='cuda:0')\n",
      "Predicted text = don't look back now, predicted ids = tensor([2123, 1005, 1056, 2298, 2067, 2085], device='cuda:0')\n",
      "original text = another door to the barrens standing open, labels = tensor([ 2178,  2341,  2000,  1996, 20225,  2015,  3061,  2330],\n",
      "       device='cuda:0')\n",
      "Predicted text = the door to the barrens standing open, predicted ids = tensor([ 1996,  2341,  2000,  1996, 20225,  2015,  3061,  2330],\n",
      "       device='cuda:0')\n",
      "original text = but never quite the breakthrough, labels = tensor([ 2021,  2196,  3243,  1996, 12687], device='cuda:0')\n",
      "Predicted text = and never quite the breakthrough, predicted ids = tensor([ 1998,  2196,  3243,  1996, 12687], device='cuda:0')\n",
      "original text = gonna do my very best, labels = tensor([6069, 2079, 2026, 2200, 2190], device='cuda:0')\n",
      "Predicted text = gonna do my very best, predicted ids = tensor([6069, 2079, 2026, 2200, 2190], device='cuda:0')\n",
      "original text = chilled to the marrow in them bones, labels = tensor([23362,  2000,  1996, 24960,  1999,  2068,  5944], device='cuda:0')\n",
      "Predicted text = chill to the marrow in them bones, predicted ids = tensor([10720,  2000,  1996, 24960,  1999,  2068,  5944], device='cuda:0')\n",
      "original text = we'll never fall apart, labels = tensor([2057, 1005, 2222, 2196, 2991, 4237], device='cuda:0')\n",
      "Predicted text = we'll never fall apart, predicted ids = tensor([2057, 1005, 2222, 2196, 2991, 4237], device='cuda:0')\n",
      "original text = so lay roses around you, labels = tensor([ 2061,  3913, 10529,  2105,  2017], device='cuda:0')\n",
      "Predicted text = so lay roses around you, predicted ids = tensor([ 2061,  3913, 10529,  2105,  2017], device='cuda:0')\n",
      "original text = oh and i don't know, labels = tensor([2821, 1998, 1045, 2123, 1005, 1056, 2113], device='cuda:0')\n",
      "Predicted text = oh and i don't know, predicted ids = tensor([2821, 1998, 1045, 2123, 1005, 1056, 2113], device='cuda:0')\n",
      "original text = fail to grow, labels = tensor([8246, 2000, 4982], device='cuda:0')\n",
      "Predicted text = fail to grow, predicted ids = tensor([8246, 2000, 4982], device='cuda:0')\n",
      "original text = burn me alive inside, labels = tensor([6402, 2033, 4142, 2503], device='cuda:0')\n",
      "Predicted text = burn me alive inside, predicted ids = tensor([6402, 2033, 4142, 2503], device='cuda:0')\n",
      "original text = ' cause i'm sure it wasn't your own fault, labels = tensor([1005, 3426, 1045, 1005, 1049, 2469, 2009, 2347, 1005, 1056, 2115, 2219,\n",
      "        6346], device='cuda:0')\n",
      "Predicted text = ' cause i'm sure it wasn't your own fault, predicted ids = tensor([1005, 3426, 1045, 1005, 1049, 2469, 2009, 2347, 1005, 1056, 2115, 2219,\n",
      "        6346], device='cuda:0')\n",
      "original text = all the people stared as if, labels = tensor([2035, 1996, 2111, 3592, 2004, 2065], device='cuda:0')\n",
      "Predicted text = all the people stared as if, predicted ids = tensor([2035, 1996, 2111, 3592, 2004, 2065], device='cuda:0')\n",
      "original text = we are the champions, labels = tensor([2057, 2024, 1996, 3966], device='cuda:0')\n",
      "Predicted text = we are the champions, predicted ids = tensor([2057, 2024, 1996, 3966], device='cuda:0')\n",
      "original text = after all is said and done, labels = tensor([2044, 2035, 2003, 2056, 1998, 2589], device='cuda:0')\n",
      "Predicted text = and all is said and done, predicted ids = tensor([1998, 2035, 2003, 2056, 1998, 2589], device='cuda:0')\n",
      "original text = with you i'd dance in a storm, labels = tensor([2007, 2017, 1045, 1005, 1040, 3153, 1999, 1037, 4040], device='cuda:0')\n",
      "Predicted text = i you i'd dance in a storm, predicted ids = tensor([1045, 2017, 1045, 1005, 1040, 3153, 1999, 1037, 4040], device='cuda:0')\n",
      "original text = so out of nowhere it will rise, labels = tensor([2061, 2041, 1997, 7880, 2009, 2097, 4125], device='cuda:0')\n",
      "Predicted text = so out of nowhere it will rise, predicted ids = tensor([2061, 2041, 1997, 7880, 2009, 2097, 4125], device='cuda:0')\n",
      "original text = from that very first week, labels = tensor([2013, 2008, 2200, 2034, 2733], device='cuda:0')\n",
      "Predicted text = in that very first week, predicted ids = tensor([1999, 2008, 2200, 2034, 2733], device='cuda:0')\n",
      "original text = our train stopped moving, labels = tensor([2256, 3345, 3030, 3048], device='cuda:0')\n",
      "Predicted text = our train stopped moving, predicted ids = tensor([2256, 3345, 3030, 3048], device='cuda:0')\n",
      "original text = it's for you, labels = tensor([2009, 1005, 1055, 2005, 2017], device='cuda:0')\n",
      "Predicted text = it's for you, predicted ids = tensor([2009, 1005, 1055, 2005, 2017], device='cuda:0')\n",
      "original text = let the reason be love, labels = tensor([2292, 1996, 3114, 2022, 2293], device='cuda:0')\n",
      "Predicted text = let the reason be love, predicted ids = tensor([2292, 1996, 3114, 2022, 2293], device='cuda:0')\n",
      "original text = i'm wasting my time, labels = tensor([ 1045,  1005,  1049, 18313,  2026,  2051], device='cuda:0')\n",
      "Predicted text = i'm wasting my time, predicted ids = tensor([ 1045,  1005,  1049, 18313,  2026,  2051], device='cuda:0')\n",
      "original text = andnow you dare to look me in the eye, labels = tensor([ 1998, 19779,  2017,  8108,  2000,  2298,  2033,  1999,  1996,  3239],\n",
      "       device='cuda:0')\n",
      "Predicted text = andnow you dare to look me in the eye, predicted ids = tensor([ 1998, 19779,  2017,  8108,  2000,  2298,  2033,  1999,  1996,  3239],\n",
      "       device='cuda:0')\n",
      "original text = and i won't let go, labels = tensor([1998, 1045, 2180, 1005, 1056, 2292, 2175], device='cuda:0')\n",
      "Predicted text = and i won't let go, predicted ids = tensor([1998, 1045, 2180, 1005, 1056, 2292, 2175], device='cuda:0')\n",
      "original text = i won't fuck us o ver i'm mis ter no vem ber, labels = tensor([ 1045,  2180,  1005,  1056,  6616,  2149,  1051,  2310,  2099,  1045,\n",
      "         1005,  1049, 28616, 28774,  2053,  2310,  2213,  2022,  2099],\n",
      "       device='cuda:0')\n",
      "Predicted text = i won't fuck us o ver i'm mis ter no vem ber, predicted ids = tensor([ 1045,  2180,  1005,  1056,  6616,  2149,  1051,  2310,  2099,  1045,\n",
      "         1005,  1049, 28616, 28774,  2053,  2310,  2213,  2022,  2099],\n",
      "       device='cuda:0')\n",
      "original text = i'm down on my mind, labels = tensor([1045, 1005, 1049, 2091, 2006, 2026, 2568], device='cuda:0')\n",
      "Predicted text = i'm down on my mind, predicted ids = tensor([1045, 1005, 1049, 2091, 2006, 2026, 2568], device='cuda:0')\n",
      "original text = you will never need to recognize yourself, labels = tensor([2017, 2097, 2196, 2342, 2000, 6807, 4426], device='cuda:0')\n",
      "Predicted text = you will never need to recognize yourself, predicted ids = tensor([2017, 2097, 2196, 2342, 2000, 6807, 4426], device='cuda:0')\n",
      "original text = he's the song in the car, labels = tensor([2002, 1005, 1055, 1996, 2299, 1999, 1996, 2482], device='cuda:0')\n",
      "Predicted text = i's the song in the car, predicted ids = tensor([1045, 1005, 1055, 1996, 2299, 1999, 1996, 2482], device='cuda:0')\n",
      "original text = when i'm only nineteen, labels = tensor([ 2043,  1045,  1005,  1049,  2069, 11977], device='cuda:0')\n",
      "Predicted text = and i'm only nineteen, predicted ids = tensor([ 1998,  1045,  1005,  1049,  2069, 11977], device='cuda:0')\n",
      "original text = she wants to go home but nobody's home, labels = tensor([2016, 4122, 2000, 2175, 2188, 2021, 6343, 1005, 1055, 2188],\n",
      "       device='cuda:0')\n",
      "Predicted text = i wants to go home but nobody's home, predicted ids = tensor([1045, 4122, 2000, 2175, 2188, 2021, 6343, 1005, 1055, 2188],\n",
      "       device='cuda:0')\n",
      "original text = but he was chasing paper, labels = tensor([ 2021,  2002,  2001, 11777,  3259], device='cuda:0')\n",
      "Predicted text = and he was chasing paper, predicted ids = tensor([ 1998,  2002,  2001, 11777,  3259], device='cuda:0')\n",
      "original text = she's fallen from grace, labels = tensor([2016, 1005, 1055, 5357, 2013, 4519], device='cuda:0')\n",
      "Predicted text = i's fallen from grace, predicted ids = tensor([1045, 1005, 1055, 5357, 2013, 4519], device='cuda:0')\n",
      "original text = won't you shine shine shine, labels = tensor([ 2180,  1005,  1056,  2017, 12342, 12342, 12342], device='cuda:0')\n",
      "Predicted text = won't you shine shine shine, predicted ids = tensor([ 2180,  1005,  1056,  2017, 12342, 12342, 12342], device='cuda:0')\n",
      "original text = there's a calm surrender, labels = tensor([2045, 1005, 1055, 1037, 5475, 7806], device='cuda:0')\n",
      "Predicted text = there's a calm surrender, predicted ids = tensor([2045, 1005, 1055, 1037, 5475, 7806], device='cuda:0')\n",
      "original text = that leave our worries behind you, labels = tensor([ 2008,  2681,  2256, 15508,  2369,  2017], device='cuda:0')\n",
      "Predicted text = and leave our worries behind you, predicted ids = tensor([ 1998,  2681,  2256, 15508,  2369,  2017], device='cuda:0')\n",
      "original text = under a sky no longer blue, labels = tensor([2104, 1037, 3712, 2053, 2936, 2630], device='cuda:0')\n",
      "Predicted text = and a sky no longer blue, predicted ids = tensor([1998, 1037, 3712, 2053, 2936, 2630], device='cuda:0')\n",
      "original text = to make myself feel bad, labels = tensor([2000, 2191, 2870, 2514, 2919], device='cuda:0')\n",
      "Predicted text = and make myself feel bad, predicted ids = tensor([1998, 2191, 2870, 2514, 2919], device='cuda:0')\n",
      "original text = take another empty moment, labels = tensor([2202, 2178, 4064, 2617], device='cuda:0')\n",
      "Predicted text = take another empty moment, predicted ids = tensor([2202, 2178, 4064, 2617], device='cuda:0')\n",
      "original text = running just as fast as we can, labels = tensor([2770, 2074, 2004, 3435, 2004, 2057, 2064], device='cuda:0')\n",
      "Predicted text = good just as fast as we can, predicted ids = tensor([2204, 2074, 2004, 3435, 2004, 2057, 2064], device='cuda:0')\n",
      "original text = shattering to the ground you, labels = tensor([21797,  2000,  1996,  2598,  2017], device='cuda:0')\n",
      "Predicted text = and to the ground you, predicted ids = tensor([1998, 2000, 1996, 2598, 2017], device='cuda:0')\n",
      "original text = nicotine and the brady bunch, labels = tensor([19332, 10196,  1998,  1996, 10184,  9129], device='cuda:0')\n",
      "Predicted text = nicotine and the brady bunch, predicted ids = tensor([19332, 10196,  1998,  1996, 10184,  9129], device='cuda:0')\n",
      "original text = i never seen girl you know what i mean, labels = tensor([1045, 2196, 2464, 2611, 2017, 2113, 2054, 1045, 2812], device='cuda:0')\n",
      "Predicted text = i never seen girl you know what i mean, predicted ids = tensor([1045, 2196, 2464, 2611, 2017, 2113, 2054, 1045, 2812], device='cuda:0')\n",
      "original text = can't say what's on my mind, labels = tensor([2064, 1005, 1056, 2360, 2054, 1005, 1055, 2006, 2026, 2568],\n",
      "       device='cuda:0')\n",
      "Predicted text = can't say what's on my mind, predicted ids = tensor([2064, 1005, 1056, 2360, 2054, 1005, 1055, 2006, 2026, 2568],\n",
      "       device='cuda:0')\n",
      "original text = loneliness up ahead emptiness behind, labels = tensor([20334,  2039,  3805, 23397,  2369], device='cuda:0')\n",
      "Predicted text = love up ahead emptiness empty, predicted ids = tensor([ 2293,  2039,  3805, 23397,  4064], device='cuda:0')\n",
      "original text = i'm just the shadow of the man, labels = tensor([1045, 1005, 1049, 2074, 1996, 5192, 1997, 1996, 2158], device='cuda:0')\n",
      "Predicted text = i'm just the shadow of the man, predicted ids = tensor([1045, 1005, 1049, 2074, 1996, 5192, 1997, 1996, 2158], device='cuda:0')\n",
      "original text = we had joy we had fun, labels = tensor([2057, 2018, 6569, 2057, 2018, 4569], device='cuda:0')\n",
      "Predicted text = we had joy we had fun, predicted ids = tensor([2057, 2018, 6569, 2057, 2018, 4569], device='cuda:0')\n",
      "original text = you don't ever put your trust in me, labels = tensor([2017, 2123, 1005, 1056, 2412, 2404, 2115, 3404, 1999, 2033],\n",
      "       device='cuda:0')\n",
      "Predicted text = you don't ever put your trust in me, predicted ids = tensor([2017, 2123, 1005, 1056, 2412, 2404, 2115, 3404, 1999, 2033],\n",
      "       device='cuda:0')\n",
      "original text = and if a double decker bus, labels = tensor([ 1998,  2065,  1037,  3313, 20946,  3902], device='cuda:0')\n",
      "Predicted text = and if a double decker bus, predicted ids = tensor([ 1998,  2065,  1037,  3313, 20946,  3902], device='cuda:0')\n",
      "original text = too real is this feeling of make believe, labels = tensor([2205, 2613, 2003, 2023, 3110, 1997, 2191, 2903], device='cuda:0')\n",
      "Predicted text = all real is this feeling of make believe, predicted ids = tensor([2035, 2613, 2003, 2023, 3110, 1997, 2191, 2903], device='cuda:0')\n",
      "original text = through my rise and fall, labels = tensor([2083, 2026, 4125, 1998, 2991], device='cuda:0')\n",
      "Predicted text = and my rise and fall, predicted ids = tensor([1998, 2026, 4125, 1998, 2991], device='cuda:0')\n",
      "original text = but there were strangers watching, labels = tensor([ 2021,  2045,  2020, 12358,  3666], device='cuda:0')\n",
      "Predicted text = and there were strangers watching, predicted ids = tensor([ 1998,  2045,  2020, 12358,  3666], device='cuda:0')\n",
      "original text = know all about you, labels = tensor([2113, 2035, 2055, 2017], device='cuda:0')\n",
      "Predicted text = can all about you, predicted ids = tensor([2064, 2035, 2055, 2017], device='cuda:0')\n",
      "original text = too much of nothing, labels = tensor([2205, 2172, 1997, 2498], device='cuda:0')\n",
      "Predicted text = all much of nothing, predicted ids = tensor([2035, 2172, 1997, 2498], device='cuda:0')\n",
      "original text = ' cause i'll never be with you, labels = tensor([1005, 3426, 1045, 1005, 2222, 2196, 2022, 2007, 2017], device='cuda:0')\n",
      "Predicted text = ' cause i'll never be with you, predicted ids = tensor([1005, 3426, 1045, 1005, 2222, 2196, 2022, 2007, 2017], device='cuda:0')\n",
      "original text = there is a way, labels = tensor([2045, 2003, 1037, 2126], device='cuda:0')\n",
      "Predicted text = there is a way, predicted ids = tensor([2045, 2003, 1037, 2126], device='cuda:0')\n",
      "original text = he burn he burn, labels = tensor([2002, 6402, 2002, 6402], device='cuda:0')\n",
      "Predicted text = i burn he burn, predicted ids = tensor([1045, 6402, 2002, 6402], device='cuda:0')\n",
      "original text = i'll give it to you, labels = tensor([1045, 1005, 2222, 2507, 2009, 2000, 2017], device='cuda:0')\n",
      "Predicted text = i'll give it to you, predicted ids = tensor([1045, 1005, 2222, 2507, 2009, 2000, 2017], device='cuda:0')\n",
      "original text = i love the sound of breaking glass, labels = tensor([1045, 2293, 1996, 2614, 1997, 4911, 3221], device='cuda:0')\n",
      "Predicted text = i love the sound of breaking glass, predicted ids = tensor([1045, 2293, 1996, 2614, 1997, 4911, 3221], device='cuda:0')\n",
      "original text = across this new divide, labels = tensor([ 2408,  2023,  2047, 11443], device='cuda:0')\n",
      "Predicted text = across this new divide, predicted ids = tensor([ 2408,  2023,  2047, 11443], device='cuda:0')\n",
      "original text = before we learn how to fly, labels = tensor([2077, 2057, 4553, 2129, 2000, 4875], device='cuda:0')\n",
      "Predicted text = maybe we learn how to fly, predicted ids = tensor([2672, 2057, 4553, 2129, 2000, 4875], device='cuda:0')\n",
      "original text = with gold in our hands, labels = tensor([2007, 2751, 1999, 2256, 2398], device='cuda:0')\n",
      "Predicted text = i gold in our hands, predicted ids = tensor([1045, 2751, 1999, 2256, 2398], device='cuda:0')\n",
      "original text = for giving it to me, labels = tensor([2005, 3228, 2009, 2000, 2033], device='cuda:0')\n",
      "Predicted text = and giving it to me, predicted ids = tensor([1998, 3228, 2009, 2000, 2033], device='cuda:0')\n",
      "original text = for power out of greed, labels = tensor([ 2005,  2373,  2041,  1997, 22040], device='cuda:0')\n",
      "Predicted text = and power out of greed, predicted ids = tensor([ 1998,  2373,  2041,  1997, 22040], device='cuda:0')\n",
      "original text = but i mean nothing to you andi don't know why, labels = tensor([2021, 1045, 2812, 2498, 2000, 2017, 1998, 2072, 2123, 1005, 1056, 2113,\n",
      "        2339], device='cuda:0')\n",
      "Predicted text = and i mean nothing to you andi don't know why, predicted ids = tensor([1998, 1045, 2812, 2498, 2000, 2017, 1998, 2072, 2123, 1005, 1056, 2113,\n",
      "        2339], device='cuda:0')\n",
      "original text = and when the hardest part is over we'll be here, labels = tensor([ 1998,  2043,  1996, 18263,  2112,  2003,  2058,  2057,  1005,  2222,\n",
      "         2022,  2182], device='cuda:0')\n",
      "Predicted text = and when the hardest part is over we'll be here, predicted ids = tensor([ 1998,  2043,  1996, 18263,  2112,  2003,  2058,  2057,  1005,  2222,\n",
      "         2022,  2182], device='cuda:0')\n",
      "original text = the picture kept will remind me, labels = tensor([ 1996,  3861,  2921,  2097, 10825,  2033], device='cuda:0')\n",
      "Predicted text = and picture kept will remind me, predicted ids = tensor([ 1998,  3861,  2921,  2097, 10825,  2033], device='cuda:0')\n",
      "original text = i'd like to see them spend the week, labels = tensor([1045, 1005, 1040, 2066, 2000, 2156, 2068, 5247, 1996, 2733],\n",
      "       device='cuda:0')\n",
      "Predicted text = i'd like to see them spend the week, predicted ids = tensor([1045, 1005, 1040, 2066, 2000, 2156, 2068, 5247, 1996, 2733],\n",
      "       device='cuda:0')\n",
      "original text = and even if i could it'd all be grey, labels = tensor([1998, 2130, 2065, 1045, 2071, 2009, 1005, 1040, 2035, 2022, 4462],\n",
      "       device='cuda:0')\n",
      "Predicted text = and even if i could it'd all be grey, predicted ids = tensor([1998, 2130, 2065, 1045, 2071, 2009, 1005, 1040, 2035, 2022, 4462],\n",
      "       device='cuda:0')\n",
      "original text = and let me go home, labels = tensor([1998, 2292, 2033, 2175, 2188], device='cuda:0')\n",
      "Predicted text = and let me go home, predicted ids = tensor([1998, 2292, 2033, 2175, 2188], device='cuda:0')\n",
      "original text = just our hands clasped so tight, labels = tensor([ 2074,  2256,  2398, 16763,  2061,  4389], device='cuda:0')\n",
      "Predicted text = just our hands clasped so tight, predicted ids = tensor([ 2074,  2256,  2398, 16763,  2061,  4389], device='cuda:0')\n",
      "original text = do you feel the same, labels = tensor([2079, 2017, 2514, 1996, 2168], device='cuda:0')\n",
      "Predicted text = do you feel the same, predicted ids = tensor([2079, 2017, 2514, 1996, 2168], device='cuda:0')\n",
      "original text = and every night i'm there, labels = tensor([1998, 2296, 2305, 1045, 1005, 1049, 2045], device='cuda:0')\n",
      "Predicted text = and every night i'm there, predicted ids = tensor([1998, 2296, 2305, 1045, 1005, 1049, 2045], device='cuda:0')\n",
      "original text = now it's up to us babe, labels = tensor([ 2085,  2009,  1005,  1055,  2039,  2000,  2149, 11561],\n",
      "       device='cuda:0')\n",
      "Predicted text = now it's up to us babe, predicted ids = tensor([ 2085,  2009,  1005,  1055,  2039,  2000,  2149, 11561],\n",
      "       device='cuda:0')\n",
      "original text = a storm that blew so pure, labels = tensor([1037, 4040, 2008, 8682, 2061, 5760], device='cuda:0')\n",
      "Predicted text = and storm that blew so pure, predicted ids = tensor([1998, 4040, 2008, 8682, 2061, 5760], device='cuda:0')\n",
      "original text = all i left for him was a note, labels = tensor([2035, 1045, 2187, 2005, 2032, 2001, 1037, 3602], device='cuda:0')\n",
      "Predicted text = all i left for him was a note, predicted ids = tensor([2035, 1045, 2187, 2005, 2032, 2001, 1037, 3602], device='cuda:0')\n",
      "original text = a lovely day, labels = tensor([1037, 8403, 2154], device='cuda:0')\n",
      "Predicted text = and lovely day, predicted ids = tensor([1998, 8403, 2154], device='cuda:0')\n",
      "original text = real love'til you've been burned, labels = tensor([ 2613,  2293,  1005, 18681,  2017,  1005,  2310,  2042,  5296],\n",
      "       device='cuda:0')\n",
      "Predicted text = real love'til you've been burned, predicted ids = tensor([ 2613,  2293,  1005, 18681,  2017,  1005,  2310,  2042,  5296],\n",
      "       device='cuda:0')\n",
      "original text = i'll never know the answer, labels = tensor([1045, 1005, 2222, 2196, 2113, 1996, 3437], device='cuda:0')\n",
      "Predicted text = i'll never know the answer, predicted ids = tensor([1045, 1005, 2222, 2196, 2113, 1996, 3437], device='cuda:0')\n",
      "original text = we've got to keep on giving, labels = tensor([2057, 1005, 2310, 2288, 2000, 2562, 2006, 3228], device='cuda:0')\n",
      "Predicted text = we've got to keep on giving, predicted ids = tensor([2057, 1005, 2310, 2288, 2000, 2562, 2006, 3228], device='cuda:0')\n",
      "original text = i'm feeling my darkest dreams, labels = tensor([ 1045,  1005,  1049,  3110,  2026, 23036,  5544], device='cuda:0')\n",
      "Predicted text = i'm feeling my darkest dreams, predicted ids = tensor([ 1045,  1005,  1049,  3110,  2026, 23036,  5544], device='cuda:0')\n",
      "original text = when you looked into my eyes, labels = tensor([2043, 2017, 2246, 2046, 2026, 2159], device='cuda:0')\n",
      "Predicted text = and you looked into my eyes, predicted ids = tensor([1998, 2017, 2246, 2046, 2026, 2159], device='cuda:0')\n",
      "original text = crank up my electricity, labels = tensor([27987,  2039,  2026,  6451], device='cuda:0')\n",
      "Predicted text = crank up my electricity, predicted ids = tensor([27987,  2039,  2026,  6451], device='cuda:0')\n",
      "original text = all we need is a reason, labels = tensor([2035, 2057, 2342, 2003, 1037, 3114], device='cuda:0')\n",
      "Predicted text = all we need is a reason, predicted ids = tensor([2035, 2057, 2342, 2003, 1037, 3114], device='cuda:0')\n",
      "original text = and now it's just farewell, labels = tensor([ 1998,  2085,  2009,  1005,  1055,  2074, 13407], device='cuda:0')\n",
      "Predicted text = and now it's just farewell, predicted ids = tensor([ 1998,  2085,  2009,  1005,  1055,  2074, 13407], device='cuda:0')\n",
      "original text = like i'm going crazy, labels = tensor([2066, 1045, 1005, 1049, 2183, 4689], device='cuda:0')\n",
      "Predicted text = like i'm going crazy, predicted ids = tensor([2066, 1045, 1005, 1049, 2183, 4689], device='cuda:0')\n",
      "original text = ihope you can't sleep anddream about it, labels = tensor([ 1045, 26441,  2017,  2064,  1005,  1056,  3637,  1998, 16200,  3286,\n",
      "         2055,  2009], device='cuda:0')\n",
      "Predicted text = ihope you can't sleep anddream about it, predicted ids = tensor([ 1045, 26441,  2017,  2064,  1005,  1056,  3637,  1998, 16200,  3286,\n",
      "         2055,  2009], device='cuda:0')\n",
      "original text = i'm thirty three for a moment, labels = tensor([1045, 1005, 1049, 4228, 2093, 2005, 1037, 2617], device='cuda:0')\n",
      "Predicted text = i'm thirty three for a moment, predicted ids = tensor([1045, 1005, 1049, 4228, 2093, 2005, 1037, 2617], device='cuda:0')\n",
      "original text = to renew your faith in god, labels = tensor([ 2000, 20687,  2115,  4752,  1999,  2643], device='cuda:0')\n",
      "Predicted text = and renew your faith in god, predicted ids = tensor([ 1998, 20687,  2115,  4752,  1999,  2643], device='cuda:0')\n",
      "original text = well if i was in your position, labels = tensor([2092, 2065, 1045, 2001, 1999, 2115, 2597], device='cuda:0')\n",
      "Predicted text = and if i was in your position, predicted ids = tensor([1998, 2065, 1045, 2001, 1999, 2115, 2597], device='cuda:0')\n",
      "original text = they'll bring us through it every time, labels = tensor([2027, 1005, 2222, 3288, 2149, 2083, 2009, 2296, 2051], device='cuda:0')\n",
      "Predicted text = they'll bring us through it every time, predicted ids = tensor([2027, 1005, 2222, 3288, 2149, 2083, 2009, 2296, 2051], device='cuda:0')\n",
      "original text = the best that i can, labels = tensor([1996, 2190, 2008, 1045, 2064], device='cuda:0')\n",
      "Predicted text = and best that i can, predicted ids = tensor([1998, 2190, 2008, 1045, 2064], device='cuda:0')\n",
      "original text = with the rest, labels = tensor([2007, 1996, 2717], device='cuda:0')\n",
      "Predicted text = i the rest, predicted ids = tensor([1045, 1996, 2717], device='cuda:0')\n",
      "original text = see beneath your perfect, labels = tensor([2156, 4218, 2115, 3819], device='cuda:0')\n",
      "Predicted text = see beneath your perfect, predicted ids = tensor([2156, 4218, 2115, 3819], device='cuda:0')\n",
      "original text = by two by two, labels = tensor([2011, 2048, 2011, 2048], device='cuda:0')\n",
      "Predicted text = and two by two, predicted ids = tensor([1998, 2048, 2011, 2048], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os. chdir('/home/users/gmenon/workspace/songsLyricsGenerator/src')\n",
    "from training import lyrics_finetune\n",
    "from constants.mir_constants import TrainingArgs, WAV2VEC2_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565f829-bc48-41db-a714-42028b889662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "hparams = argparse.Namespace()\n",
    "hparams.wav2vec2_model = 'facebook/wav2vec2-large-960h-lv60-self'\n",
    "hparams.lm_model = 'bert-base-uncased' #'facebook/bart-large'\n",
    "hparams.vocab_size = 20000\n",
    "hparams.learning_rate = 1e-6\n",
    "hparams.batch_size = 2\n",
    "\n",
    "model,trainer = lyrics_finetune.run(hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943c2e9-59c8-46f5-a681-9c96ec6776f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/BERT2BERT_for_CNN_Dailymail.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d3245-2648-4434-baf5-2249682358e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = trainer.datamodule\n",
    "# data.setup()\n",
    "# import torch\n",
    "# torch.Tensor(data.val_dataset['input_values'][0]).unsqueeze(0)\n",
    "# model.generate(torch.Tensor(data.val_dataset['input_values'][0]).unsqueeze(0).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd01a88-f5e5-467d-b7fe-b019deb2b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.Tensor([6506, 3808,1998, 1996,6506,3808,2058,2058,1012])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2911ae-4a22-4957-b03f-4ba66dfcd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a92ef7-b8db-4cbd-90f0-3e991c895322",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [101, 2054, 2842, 2023, 2071, 1005, 2310, 2042,  102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53c214-9bd2-4bc1-a664-f5efb642ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42a160-2f59-4890-9040-95d0d430c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edeeb59-e4fb-4458-9072-4995164f53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.decode(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c818fd82-a604-428d-8407-291640c1fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.decode(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603d0b8-5ec5-4b92-8d23-ce783df5b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "b  = [6506, 3808, 2003,1998,2042,3808,7316,1999,1012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a8aab-5759-49ab-8769-4d6973e21bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_2D_list = [[5, 10, 15, 20],\n",
    "                   [25, 30, 35, 40],\n",
    "                   [45, 50, 55, 60]]\n",
    "list_to_tensor = torch.tensor(example_2D_list)\n",
    "print(\"Our New 2D Tensor from 2D List is: \", list_to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc4b9c-8c94-4c66-b9e4-344d1a6a0c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b95338-4fc7-46bc-b7fc-3f8fa3ef4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = torch.Tensor([[6506, 3808],\n",
    "        [3808, 3808],\n",
    "        [2003, 1998],\n",
    "        [1998, 1996],\n",
    "        [2042, 6506],\n",
    "        [3808, 3808],\n",
    "        [7316, 2058],\n",
    "        [1999, 2058],\n",
    "        [1012, 1012]]).type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578baf2-b5f9-4889-9c1f-96498a615ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = tensors[:,:1].flatten().tolist()\n",
    "list2 = tensors[:,-1].flatten().tolist()\n",
    "list1, list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216744cf-ab2d-42fb-bbaf-e215c03a8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.decode(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345721b-6fb6-4d85-a7bb-97ac07da7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.decode(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe275d-62f2-4ed3-8483-8c0d612068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.Tensor([[ 101, 2054, 2842, 2023, 2071, 1005, 2310, 2042,  102],\n",
    "        [ 101, 2562, 2115, 2192, 1999, 3067,  102, -100, -100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644480ec-0dd4-493b-b237-92fb3112d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4364896-4d8a-4f68-82a9-53dfff78945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.decode(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe00d13-4a16-4d87-b099-d9523c4b2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.decode(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541180e7-ee15-4c38-9b11-5a19d615e4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3af1ef-24f3-4655-ae66-3d76994c8809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54566220-e690-4eba-a75f-557845db3bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f292ed0a-68b9-4164-9e50-cf3e3a2b6598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9880857-0b09-4be1-be14-5e279a0e9ed1",
   "metadata": {},
   "source": [
    "## TESTING HUGGINGFACE's IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3892980d-3369-4945-82ea-7631c6a86e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechEncoderDecoderModel, AutoProcessor\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-xls-r-300m-en-to-15\")\n",
    "model = SpeechEncoderDecoderModel.from_pretrained(\"facebook/wav2vec2-xls-r-300m-en-to-15\")\n",
    "\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "\n",
    "input_values = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"pt\").input_values\n",
    "# Inference: Translate English speech to German\n",
    "generated = model.generate(input_values)\n",
    "decoded = processor.batch_decode(generated, skip_special_tokens=True)[0]\n",
    "decoded\n",
    "\n",
    "# Training: Train model on English transcription\n",
    "labels = processor(text=ds[0][\"text\"], return_tensors=\"pt\").input_ids\n",
    "\n",
    "loss = model(input_values, labels=labels).loss\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6c4c2-6498-4e6e-bc35-99954667b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoFeatureExtractor, SpeechEncoderDecoderModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "encoder_id = \"facebook/wav2vec2-base-960h\"  # acoustic model encoder\n",
    "decoder_id = \"bert-base-uncased\"  # text decoder\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(encoder_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(decoder_id)\n",
    "# Combine pre-trained encoder and pre-trained decoder to form a Seq2Seq model\n",
    "model = SpeechEncoderDecoderModel.from_encoder_decoder_pretrained(encoder_id, decoder_id)\n",
    "\n",
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# load an audio input and pre-process (normalise mean/std to 0/1)\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "input_values = feature_extractor(ds[0][\"audio\"][\"array\"], return_tensors=\"pt\").input_values\n",
    "\n",
    "# load its corresponding transcription and tokenize to generate labels\n",
    "labels = tokenizer(ds[0][\"text\"], return_tensors=\"pt\").input_ids\n",
    "\n",
    "# the forward function automatically creates the correct decoder_input_ids\n",
    "loss = model(input_values).loss\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3899ce1-5707-4381-9981-ce9c3646f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.cls_token_id,tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09855416-6f50-4a4b-8667-d311a544a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949546b-5e7d-479e-818f-0431b00a1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b88539-fb4f-437a-b7b0-1abc3696f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets.features import Audio\n",
    "from transformers import SpeechEncoderDecoderModel, Wav2Vec2Processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf4512-0a15-4407-ad72-cb7071af0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LANG_ID = \"ru\"\n",
    "MODEL_ID = \"bond005/wav2vec2-mbart50-ru\"\n",
    "SAMPLES = 30\n",
    "\n",
    "num_processes = 4\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = SpeechEncoderDecoderModel.from_pretrained(MODEL_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9964f298-8e2b-4302-8772-c83fa20e8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = load_dataset(\"common_voice\", LANG_ID, split=f\"test[:{SAMPLES}]\")\n",
    "\n",
    "if test_dataset.features['audio'].sampling_rate != 16_000:\n",
    "    test_dataset = test_dataset.cast_column(\n",
    "        'audio',\n",
    "        Audio(sampling_rate=16_000)\n",
    "    )\n",
    "\n",
    "audio_data = [test_dataset[i]['audio']['array'] for i in range(SAMPLES)]\n",
    "\n",
    "processed = processor(audio_data, sampling_rate=16_000,\n",
    "                      return_tensors=\"pt\", padding='longest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f1f7b-a934-4c63-b188-de0bfbd7d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    predicted_ids = model.generate(**processed)\n",
    "\n",
    "predicted_sentences = processor.batch_decode(\n",
    "    predicted_ids,\n",
    "    num_processes=num_processes,\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for i, predicted_sentence in enumerate(predicted_sentences):\n",
    "        print(\"-\" * 100)\n",
    "        print(\"Reference: \", test_dataset[i][\"sentence\"])\n",
    "        print(\"Prediction:\", predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef0a005-9e5a-488b-a9a0-6d57153ad408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2babd045-1df9-42e6-aa6e-afde7e55d8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>consolidated_file_path</th>\n",
       "      <th>Length</th>\n",
       "      <th>transcription</th>\n",
       "      <th>transcription_capitalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01cef35811fd4a3fa63a3ab8bba5430c</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.447392</td>\n",
       "      <td>right about now i'm fifty fifty</td>\n",
       "      <td>RIGHT ABOUT NOW I'M FIFTY FIFTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0c04880a6eaf4e559fd9b20594eb74cd</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>4.137755</td>\n",
       "      <td>let me run my fingers through your hair</td>\n",
       "      <td>LET ME RUN MY FINGERS THROUGH YOUR HAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01a7c7f2e6db4c68abfbc1218dc9ef76</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.923696</td>\n",
       "      <td>but you're yesterday's child to me</td>\n",
       "      <td>BUT YOU'RE YESTERDAY'S CHILD TO ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0c8c027ad9374db6b9e6c12dc873be7b</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.058390</td>\n",
       "      <td>and whisper so softly</td>\n",
       "      <td>AND WHISPER SO SOFTLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08558a8941c04a559a3ea48793ac1a34</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.038073</td>\n",
       "      <td>have a laugh at the rat race</td>\n",
       "      <td>HAVE A LAUGH AT THE RAT RACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07929e956a9745fa96e91730d8540cd1</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.702948</td>\n",
       "      <td>aaaa haaa haaa</td>\n",
       "      <td>AAAA HAAA HAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>002fe3610f1b41b59d28546201635043</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>3.507075</td>\n",
       "      <td>but that's not how it used to be</td>\n",
       "      <td>BUT THAT'S NOT HOW IT USED TO BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0a4e93435d0746d39ea0814667d6fa3a</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>3.020454</td>\n",
       "      <td>and you've seen it all before but the wolf's o...</td>\n",
       "      <td>AND YOU'VE SEEN IT ALL BEFORE BUT THE WOLF'S O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0bde4da0cf2842028bf7d1a712dec1c5</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.734830</td>\n",
       "      <td>and talk is cheap awhen the story is good</td>\n",
       "      <td>AND TALK IS CHEAP AWHEN THE STORY IS GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0851f1ca1594443d897d4a32b4eab788</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.288141</td>\n",
       "      <td>turned you into someone new</td>\n",
       "      <td>TURNED YOU INTO SOMEONE NEW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Folder  \\\n",
       "0  01cef35811fd4a3fa63a3ab8bba5430c   \n",
       "1  0c04880a6eaf4e559fd9b20594eb74cd   \n",
       "2  01a7c7f2e6db4c68abfbc1218dc9ef76   \n",
       "3  0c8c027ad9374db6b9e6c12dc873be7b   \n",
       "4  08558a8941c04a559a3ea48793ac1a34   \n",
       "5  07929e956a9745fa96e91730d8540cd1   \n",
       "6  002fe3610f1b41b59d28546201635043   \n",
       "7  0a4e93435d0746d39ea0814667d6fa3a   \n",
       "8  0bde4da0cf2842028bf7d1a712dec1c5   \n",
       "9  0851f1ca1594443d897d4a32b4eab788   \n",
       "\n",
       "                              consolidated_file_path    Length  \\\n",
       "0  /scratch/users/gmenon/wav_clips/separated/htde...  2.447392   \n",
       "1  /scratch/users/gmenon/wav_clips/separated/htde...  4.137755   \n",
       "2  /scratch/users/gmenon/wav_clips/separated/htde...  2.923696   \n",
       "3  /scratch/users/gmenon/wav_clips/separated/htde...  2.058390   \n",
       "4  /scratch/users/gmenon/wav_clips/separated/htde...  2.038073   \n",
       "5  /scratch/users/gmenon/wav_clips/separated/htde...  2.702948   \n",
       "6  /scratch/users/gmenon/wav_clips/separated/htde...  3.507075   \n",
       "7  /scratch/users/gmenon/wav_clips/separated/htde...  3.020454   \n",
       "8  /scratch/users/gmenon/wav_clips/separated/htde...  2.734830   \n",
       "9  /scratch/users/gmenon/wav_clips/separated/htde...  2.288141   \n",
       "\n",
       "                                       transcription  \\\n",
       "0                    right about now i'm fifty fifty   \n",
       "1            let me run my fingers through your hair   \n",
       "2                 but you're yesterday's child to me   \n",
       "3                              and whisper so softly   \n",
       "4                       have a laugh at the rat race   \n",
       "5                                     aaaa haaa haaa   \n",
       "6                   but that's not how it used to be   \n",
       "7  and you've seen it all before but the wolf's o...   \n",
       "8          and talk is cheap awhen the story is good   \n",
       "9                        turned you into someone new   \n",
       "\n",
       "                           transcription_capitalized  \n",
       "0                    RIGHT ABOUT NOW I'M FIFTY FIFTY  \n",
       "1            LET ME RUN MY FINGERS THROUGH YOUR HAIR  \n",
       "2                 BUT YOU'RE YESTERDAY'S CHILD TO ME  \n",
       "3                              AND WHISPER SO SOFTLY  \n",
       "4                       HAVE A LAUGH AT THE RAT RACE  \n",
       "5                                     AAAA HAAA HAAA  \n",
       "6                   BUT THAT'S NOT HOW IT USED TO BE  \n",
       "7  AND YOU'VE SEEN IT ALL BEFORE BUT THE WOLF'S O...  \n",
       "8          AND TALK IS CHEAP AWHEN THE STORY IS GOOD  \n",
       "9                        TURNED YOU INTO SOMEONE NEW  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(WAV2VEC2_ARGS.TRAIN_FILE_PATH).head(10)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b64793a-efaa-407c-94ea-80ece2282045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>consolidated_file_path</th>\n",
       "      <th>Length</th>\n",
       "      <th>transcription</th>\n",
       "      <th>transcription_capitalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0aa835068aa64515b2158c2f0b6513b7</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>4.754943</td>\n",
       "      <td>so learn from your mistakes</td>\n",
       "      <td>SO LEARN FROM YOUR MISTAKES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>089cd84d662e4c50954cfa46c07cae14</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.759388</td>\n",
       "      <td>i've been connected to the right line</td>\n",
       "      <td>I'VE BEEN CONNECTED TO THE RIGHT LINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127cc2aaff9a44fab21b2a0c4f5c3e5d</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.668254</td>\n",
       "      <td>the truth to be found</td>\n",
       "      <td>THE TRUTH TO BE FOUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18e03c3980014046a3504ef42fe81ae8</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.895079</td>\n",
       "      <td>he said the way myblue eyes shined</td>\n",
       "      <td>HE SAID THE WAY MYBLUE EYES SHINED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07c8b8c0b0424c1e87389392695a551b</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.666939</td>\n",
       "      <td>you leave me once again home alone</td>\n",
       "      <td>YOU LEAVE ME ONCE AGAIN HOME ALONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0cb795c9b6e64a4abab5553c2b2ed3e0</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.742880</td>\n",
       "      <td>while they are in commend</td>\n",
       "      <td>WHILE THEY ARE IN COMMEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0655395364614218be31548245853ca0</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>4.697710</td>\n",
       "      <td>a life all mine</td>\n",
       "      <td>A LIFE ALL MINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>113bb605eb324aeb8db046b4193424a2</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.642948</td>\n",
       "      <td>so i never went back</td>\n",
       "      <td>SO I NEVER WENT BACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00ecd4b71c094b959ae492ec138bb555</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>3.176508</td>\n",
       "      <td>in you i taste god</td>\n",
       "      <td>IN YOU I TASTE GOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0b5fa72c054e44598ec8aefb76ff855e</td>\n",
       "      <td>/scratch/users/gmenon/wav_clips/separated/htde...</td>\n",
       "      <td>2.465011</td>\n",
       "      <td>could stay a while</td>\n",
       "      <td>COULD STAY A WHILE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Folder  \\\n",
       "0  0aa835068aa64515b2158c2f0b6513b7   \n",
       "1  089cd84d662e4c50954cfa46c07cae14   \n",
       "2  127cc2aaff9a44fab21b2a0c4f5c3e5d   \n",
       "3  18e03c3980014046a3504ef42fe81ae8   \n",
       "4  07c8b8c0b0424c1e87389392695a551b   \n",
       "5  0cb795c9b6e64a4abab5553c2b2ed3e0   \n",
       "6  0655395364614218be31548245853ca0   \n",
       "7  113bb605eb324aeb8db046b4193424a2   \n",
       "8  00ecd4b71c094b959ae492ec138bb555   \n",
       "9  0b5fa72c054e44598ec8aefb76ff855e   \n",
       "\n",
       "                              consolidated_file_path    Length  \\\n",
       "0  /scratch/users/gmenon/wav_clips/separated/htde...  4.754943   \n",
       "1  /scratch/users/gmenon/wav_clips/separated/htde...  2.759388   \n",
       "2  /scratch/users/gmenon/wav_clips/separated/htde...  2.668254   \n",
       "3  /scratch/users/gmenon/wav_clips/separated/htde...  2.895079   \n",
       "4  /scratch/users/gmenon/wav_clips/separated/htde...  2.666939   \n",
       "5  /scratch/users/gmenon/wav_clips/separated/htde...  2.742880   \n",
       "6  /scratch/users/gmenon/wav_clips/separated/htde...  4.697710   \n",
       "7  /scratch/users/gmenon/wav_clips/separated/htde...  2.642948   \n",
       "8  /scratch/users/gmenon/wav_clips/separated/htde...  3.176508   \n",
       "9  /scratch/users/gmenon/wav_clips/separated/htde...  2.465011   \n",
       "\n",
       "                           transcription  \\\n",
       "0            so learn from your mistakes   \n",
       "1  i've been connected to the right line   \n",
       "2                  the truth to be found   \n",
       "3     he said the way myblue eyes shined   \n",
       "4     you leave me once again home alone   \n",
       "5              while they are in commend   \n",
       "6                        a life all mine   \n",
       "7                   so i never went back   \n",
       "8                     in you i taste god   \n",
       "9                     could stay a while   \n",
       "\n",
       "               transcription_capitalized  \n",
       "0            SO LEARN FROM YOUR MISTAKES  \n",
       "1  I'VE BEEN CONNECTED TO THE RIGHT LINE  \n",
       "2                  THE TRUTH TO BE FOUND  \n",
       "3     HE SAID THE WAY MYBLUE EYES SHINED  \n",
       "4     YOU LEAVE ME ONCE AGAIN HOME ALONE  \n",
       "5              WHILE THEY ARE IN COMMEND  \n",
       "6                        A LIFE ALL MINE  \n",
       "7                   SO I NEVER WENT BACK  \n",
       "8                     IN YOU I TASTE GOD  \n",
       "9                     COULD STAY A WHILE  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = pd.read_csv(WAV2VEC2_ARGS.TEST_FILE_PATH).head(10)\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5a069d0-7df7-454a-b738-8756510565c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor, BertTokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained('facebook/wav2vec2-large-960h-lv60-self')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f95a8161-b007-4da7-bb81-3a4c103eab4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([101,\n",
       "   156,\n",
       "   2346,\n",
       "   149,\n",
       "   12420,\n",
       "   2069,\n",
       "   2249,\n",
       "   143,\n",
       "   21564,\n",
       "   2107,\n",
       "   19141,\n",
       "   2069,\n",
       "   26574,\n",
       "   9272,\n",
       "   1592,\n",
       "   22441,\n",
       "   1708,\n",
       "   102],\n",
       "  [101, 1177, 3858, 1121, 1240, 12572, 102]),\n",
       " ([101,\n",
       "   146,\n",
       "   112,\n",
       "   159,\n",
       "   2036,\n",
       "   139,\n",
       "   27073,\n",
       "   2249,\n",
       "   18732,\n",
       "   2249,\n",
       "   22680,\n",
       "   16647,\n",
       "   10069,\n",
       "   16972,\n",
       "   7462,\n",
       "   155,\n",
       "   23413,\n",
       "   18784,\n",
       "   149,\n",
       "   11607,\n",
       "   2036,\n",
       "   102],\n",
       "  [101, 178, 112, 1396, 1151, 3387, 1106, 1103, 1268, 1413, 102]),\n",
       " ([101,\n",
       "   7462,\n",
       "   157,\n",
       "   2069,\n",
       "   16830,\n",
       "   3048,\n",
       "   16972,\n",
       "   139,\n",
       "   2036,\n",
       "   143,\n",
       "   2346,\n",
       "   27370,\n",
       "   2137,\n",
       "   102],\n",
       "  [101, 1103, 3062, 1106, 1129, 1276, 102]),\n",
       " ([101,\n",
       "   145,\n",
       "   2036,\n",
       "   13411,\n",
       "   9949,\n",
       "   7462,\n",
       "   22751,\n",
       "   3663,\n",
       "   150,\n",
       "   3663,\n",
       "   13360,\n",
       "   24846,\n",
       "   142,\n",
       "   3663,\n",
       "   9919,\n",
       "   17730,\n",
       "   11607,\n",
       "   10069,\n",
       "   102],\n",
       "  [101, 1119, 1163, 1103, 1236, 1139, 1830, 19224, 1257, 18978, 1181, 102]),\n",
       " ([101,\n",
       "   19141,\n",
       "   149,\n",
       "   12420,\n",
       "   17145,\n",
       "   22157,\n",
       "   21748,\n",
       "   10954,\n",
       "   14731,\n",
       "   1592,\n",
       "   11607,\n",
       "   145,\n",
       "   13041,\n",
       "   2036,\n",
       "   18589,\n",
       "   11414,\n",
       "   2036,\n",
       "   102],\n",
       "  [101, 1128, 1817, 1143, 1517, 1254, 1313, 2041, 102]),\n",
       " ([101,\n",
       "   160,\n",
       "   3048,\n",
       "   17656,\n",
       "   2036,\n",
       "   7462,\n",
       "   3663,\n",
       "   22133,\n",
       "   2036,\n",
       "   15969,\n",
       "   18732,\n",
       "   25290,\n",
       "   11680,\n",
       "   2137,\n",
       "   102],\n",
       "  [101, 1229, 1152, 1132, 1107, 3254, 2354, 1181, 102]),\n",
       " ([101, 138, 149, 15499, 2036, 18589, 2162, 26574, 22680, 102],\n",
       "  [101, 170, 1297, 1155, 2317, 102]),\n",
       " ([101,\n",
       "   156,\n",
       "   2346,\n",
       "   146,\n",
       "   26546,\n",
       "   17145,\n",
       "   2069,\n",
       "   160,\n",
       "   11680,\n",
       "   1942,\n",
       "   12465,\n",
       "   1658,\n",
       "   2428,\n",
       "   102],\n",
       "  [101, 1177, 178, 1309, 1355, 1171, 102]),\n",
       " ([101, 15969, 19141, 146, 157, 10719, 12880, 27157, 2137, 102],\n",
       "  [101, 1107, 1128, 178, 5080, 5540, 102]),\n",
       " ([101,\n",
       "   18732,\n",
       "   2591,\n",
       "   20521,\n",
       "   23676,\n",
       "   1592,\n",
       "   3663,\n",
       "   138,\n",
       "   160,\n",
       "   3048,\n",
       "   17656,\n",
       "   2036,\n",
       "   102],\n",
       "  [101, 1180, 2215, 170, 1229, 102])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a for a in zip(bert_tokenizer(list(validation_df[\"transcription_capitalized\"])).input_ids,bert_tokenizer(list(validation_df[\"transcription\"])).input_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1a216e7-276c-45cc-91f7-401946441a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he said the way myblue eyes shined'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(bert_tokenizer(list(validation_df[\"transcription\"])).input_ids[3],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec7d0394-1291-433f-935c-fbe850890b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'so learn from your mistakes'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(validation_df[\"transcription\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "559d4025-cde5-48d9-ac08-294a5ec63ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "label = torch.Tensor([101, 155, 23413, 18784, 16151, 2346, 16830, 24819, 2924, 146, 112, 150, 143, 15499, 16880, 143, 15499, 16880, 102])\n",
    "\n",
    "label = torch.Tensor([[ 101, 1037, 2166, 2035, 3067,  102, -100],[ 101, 2061, 1045, 2196, 2253, 2067,  102]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317b076f-5be1-4e66-b382-5b23bf56cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor, BertTokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained('facebook/wav2vec2-base-960h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dee7e39-0f87-4918-b1d1-b37c65a653b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] so i never went back [SEP]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14e73de-3744-45e5-a44b-f10890399af7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wav_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwav_tokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(label)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wav_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "wav_tokenizer.decode(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0e4c8-2c5d-4c8c-bad1-54ff6462c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.Tensor([[ 101, 1037, 2166, 2035, 3067,  102, -100],\n",
    "        [ 101, 2061, 1045, 2196, 2253, 2067,  102]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218963a8-63c0-45d4-9679-139ced75b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.decode(label[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689de184-6d7c-4a51-846a-c3cddb5e338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.decode(label[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c37ac-55de-43be-9fd1-0d53040b916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = torch.Tensor([[1996, 1996],\n",
    "        [1999, 1996],\n",
    "        [2061, 1996],\n",
    "        [2061, 1000],\n",
    "        [1000, 1998],\n",
    "        [1000, 2030],\n",
    "        [2061, 2061]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211520c9-f5d0-4712-a337-e279d30858e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.decode(predicted.T[0,:],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c065f3e5-eaa6-4aec-9423-ce4a78b8b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "validation_df = pd.read_csv(WAV2VEC2_ARGS.TEST_FILE_PATH).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e9fc80e-dc3b-4a44-8256-06615ad031a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE TRUTH TO BE FOUND']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(validation_df[validation_df[\"Folder\"] == '127cc2aaff9a44fab21b2a0c4f5c3e5d'][\"transcription_capitalized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f98d289e-a041-4d28-bc86-74c3e7ed3627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101, 1996, 3606, 2000, 2022, 2179, 102]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer(list(validation_df[validation_df[\"Folder\"] == '127cc2aaff9a44fab21b2a0c4f5c3e5d'][\"transcription_capitalized\"])).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d44d271a-c5d7-4e6f-876d-f11e0ff2fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    # batched output is \"un-batched\" to ensure mapping is correct\n",
    "    batch[\"input_values\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    #batch[\"attention_mask\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).attention_mask[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "    batch[\"labels\"] = bert_tokenizer(batch[\"transcription\"]).input_ids\n",
    "    batch[\"label_attention_mask\"] = bert_tokenizer(batch[\"transcription\"]).attention_mask\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07bcd7e1-c776-4cf8-be39-50b0cfb96688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Audio\n",
    "val_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(validation_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(validation_df[\"transcription_capitalized\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6a8104b-8f8b-44eb-ab90-7842b9af0954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6514c59c27fa4320b0d4ac9e1c2322f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_dataset1 = val_dataset.map(prepare_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c485df2f-0cae-4b93-a2ec-32387d553eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_dataset1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae5938ce-fe60-404b-abc9-cee7a9dbfd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = [{\"input_ids\": feature[\"labels\"]} for feature in val_dataset1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cee0e86-af23-4f98-969f-be4e9084af5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 101, 1996, 3606, 2000, 2022, 2179,  102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.pad(\n",
    "            label_features,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eed0fe2-d3a6-46ff-8de0-0c7515c29d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a965d4d2-c262-447f-9402-3339a2396df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ae1f6e7-a6e0-4292-880f-7b7ff49a0aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbd0a975-2e5a-4ecb-900c-90e3a45b50e5",
   "metadata": {},
   "source": [
    "# BACKUP OF WORKING SCRIPT !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2603f-4b14-4914-9c05-65bf05bfecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchmetrics.text import WordErrorRate\n",
    "from typing import Optional\n",
    "from pytorch_lightning import LightningModule, LightningDataModule, Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from constants.mir_constants import TrainingArgs, WAV2VEC2_ARGS\n",
    "from dataclasses import dataclass, asdict, field # type: ignore\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor, BertTokenizer\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM,AutoModelForCTC, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset, Dataset, Audio\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from flash.audio import SpeechRecognition, SpeechRecognitionData\n",
    "from training.wav2vec2_finetune import Wav2Vec2SpeechRecognition, SpeechRecognitionData\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"SLG - wav2vec2 transfer learning\",log_model=True,)\n",
    "\n",
    "print(json.dumps(asdict(WAV2VEC2_ARGS), indent = 4))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "    \"\"\"\n",
    "# {\n",
    "#     'input_values': tensor([[ 0.1252,  0.1147, -0.0070,  ...,  0.0000,  0.0000,  0.0000], [ 0.0015, -0.0029, -0.0065,  ..., -0.0397, -0.0444,  0.0110]]), \n",
    "#     'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],[1, 1, 1,  ..., 1, 1, 1]]), \n",
    "#     'labels': tensor([[  101,  9294,  1185,  1119,   112,  1325,  1294,  2059,   102], [  101,  1105,   178,  1169,  1437,  1128,  1103, 11711,   102]]), \n",
    "#     'label_attention_masks': tensor([[0, 1, 1, 1, 1, 1, 1, 1, 0], [0, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
    "#  }\n",
    "\n",
    "#{\n",
    "#        'input_values': tensor([[-0.1088,  0.7008,  0.0430,  ...,  0.0174, -0.6597, -1.5689],\n",
    "#                               [ 0.0170,  0.0307,  0.0260,  ...,  0.0000,  0.0000,  0.0000]]),\n",
    "#        'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1], [1, 1, 1,  ..., 0, 0, 0]]),\n",
    "#        'labels': tensor([[  101, 15969, 19141,   146,   157, 10719, 12880, 27157,  2137,   102,  -100,  -100,  -100],\n",
    "#                          [  101, 18732,  2591, 20521, 23676,  1592,  3663,   138,   160,  3048, 17656,  2036,   102]]), \n",
    "#        'label_attention_masks': tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
    "# }\n",
    "\n",
    "\n",
    "    feature_extractor: Wav2Vec2FeatureExtractor\n",
    "    bert_tokenizer: BertTokenizer\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        label_attention_features =[{\"input_ids\": feature[\"label_attention_mask\"]} for feature in features]\n",
    "        attention_features =[{\"input_values\": feature[\"attention_mask\"]} for feature in features]\n",
    "        \n",
    "        batch = self.feature_extractor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\")\n",
    "\n",
    "        batch_attention = self.feature_extractor.pad(\n",
    "            attention_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\")\n",
    "    \n",
    "        labels_batch = self.bert_tokenizer.pad(\n",
    "            label_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        label_attention_batch = self.bert_tokenizer.pad(\n",
    "            label_attention_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "            )\n",
    "                \n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels_attention = label_attention_batch[\"input_ids\"].masked_fill(labels_batch.input_ids.eq(101), 0).masked_fill(labels_batch.input_ids.eq(102), 0)\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), 0) #Changed from -100 as this is not Wav2Vec2 but it is BERT. The latter's pad token is 0.\n",
    "        batch[\"labels\"] = labels\n",
    "        batch[\"label_attention_masks\"] = labels_attention\n",
    "        batch[\"attention_mask\"] = batch_attention[\"input_values\"]\n",
    "        #print(batch)\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "class SpeechRecognitionDataModule(LightningDataModule):\n",
    "    def __init__(self, WAV2VEC2_ARGS: WAV2VEC2_ARGS, num_workers,hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.batch_size = WAV2VEC2_ARGS.BATCH_SIZE\n",
    "        self.num_workers = num_workers\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(hparams.wav2vec2_model)\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(hparams.lm_model)\n",
    "        #self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(WAV2VEC2_ARGS.MODEL_BACKBONE)\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16_000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "        #self.feature_extractor = AutoFeatureExtractor.from_pretrained(hparams.wav2vec2_model)\n",
    "        #self.processor = Wav2Vec2Processor(feature_extractor=self.feature_extractor, tokenizer=self.bert_tokenizer)\n",
    "        #self.processor = AutoProcessor(feature_extractor=self.feature_extractor, tokenizer=self.bert_tokenizer)\n",
    "        #self.processor = WhisperProcessor(feature_extractor=self.feature_extractor, tokenizer=self.bert_tokenizer)\n",
    "        self.data_collator = DataCollatorCTCWithPadding(feature_extractor=self.feature_extractor, bert_tokenizer=self.bert_tokenizer, padding=True,)\n",
    "        self.cpu_count = 4\n",
    "        print(f\"CPU Count = {self.cpu_count}\")\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        train_df = pd.read_csv(WAV2VEC2_ARGS.TRAIN_FILE_PATH).head(1000)\n",
    "        validation_df = pd.read_csv(WAV2VEC2_ARGS.TEST_FILE_PATH).head(10)\n",
    "        if stage == 'fit' or stage is None:\n",
    "            print(\"In Stage = Fit\")\n",
    "            train_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(train_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(train_df[\"transcription\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "            self.train_dataset = train_dataset.map(self.prepare_dataset,remove_columns = train_dataset.column_names)\n",
    "            \n",
    "            val_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(validation_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(validation_df[\"transcription\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "            self.val_dataset = val_dataset.map(self.prepare_dataset,remove_columns = val_dataset.column_names)\n",
    "\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            print(\"In Stage = Test\")\n",
    "            test_dataset = Dataset.from_dict(\n",
    "                    {\"audio\": list(validation_df[\"consolidated_file_path\"]),\n",
    "                    \"transcription\": list(validation_df[\"transcription\"])}).cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "            test_dataset = val_dataset.map(self.prepare_dataset,remove_columns = val_dataset.column_names)\n",
    "            self.test_dataset = test_dataset\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        print(\"entering train data loader\")\n",
    "        return DataLoader(\n",
    "            self.train_dataset.with_format(\"torch\"), \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn = self.data_collator\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        print(\"entering val data loader\")\n",
    "        return DataLoader(\n",
    "            self.val_dataset.with_format(\"torch\"), \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn = self.data_collator\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        print(\"entering test data loader\")\n",
    "        return DataLoader(\n",
    "            self.test_dataset.with_format(\"torch\"), \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn = self.data_collator\n",
    "        )\n",
    "\n",
    "    def prepare_dataset(self,batch):\n",
    "        audio = batch[\"audio\"]\n",
    "        # batched output is \"un-batched\" to ensure mapping is correct\n",
    "        batch[\"input_values\"] = self.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "        batch[\"attention_mask\"] = self.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).attention_mask[0]\n",
    "        batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "        batch[\"labels\"] = self.bert_tokenizer(batch[\"transcription\"]).input_ids\n",
    "        batch[\"label_attention_mask\"] = self.bert_tokenizer(batch[\"transcription\"]).attention_mask\n",
    "        #print(batch)\n",
    "        # with self.processor.as_target_processor():\n",
    "        #     batch[\"labels\"] = self.processor(batch[\"transcription\"]).input_ids\n",
    "        #     batch[\"label_attention_mask\"] = self.processor(batch[\"transcription\"]).attention_mask\n",
    "        return batch\n",
    "\n",
    "class Wav2SeqModel(LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.batch_size = hparams.batch_size\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(hparams.lm_model)\n",
    "        speech_recognition_task = Wav2Vec2SpeechRecognition(wav2vec2_args=WAV2VEC2_ARGS)\n",
    "        #self.wav2vec2 = AutoModelForCTC.from_pretrained(hparams.wav2vec2_model,ctc_zero_infinity=False,ctc_loss_reduction=\"sum\")\n",
    "        self.wav2vec2 = SpeechRecognition.load_from_checkpoint(\"/scratch/users/gmenon/model_artefacts/wav2vec2_demucs_en_large-960h-lv60-self_freeze_unfreeze_15epochs_adam.pt\").model\n",
    "        #self.wav2vec2.freeze_feature_encoder()\n",
    "        #self.wav2vec2 = AutoModel.from_pretrained(hparams.wav2vec2_model)\n",
    "        self.wav2vec2.eval()\n",
    "        #print(self.wav2vec2.config)\n",
    "        self.seq2seq = AutoModelForCausalLM.from_pretrained(hparams.lm_model)\n",
    "        self.seq2seq.config.is_decoder = True\n",
    "        self.seq2seq.add_cross_attention = True\n",
    "        self.seq2seq.train()\n",
    "        bert_unwanted = np.zeros((1996,), dtype=int)\n",
    "        bert_wanted = np.ones((len(self.bert_tokenizer.get_vocab())-1996,), dtype=int)\n",
    "        self.weights = torch.Tensor(np.concatenate((bert_unwanted, bert_wanted), axis=0)).cuda()\n",
    "        #print(self.seq2seq.config)\n",
    "\n",
    "    def forward(self, audio, attention_mask, labels, label_attention_mask):\n",
    "        #print(\"entering forward step\")\n",
    "        encoder_outputs = self.wav2vec2(audio.squeeze(),\n",
    "                                        attention_mask=attention_mask,\n",
    "                                        output_hidden_states=True,\n",
    "                                        output_attentions=True)\n",
    "        encoder_hidden_states = encoder_outputs[0]  \n",
    "        #encoder_attention_mask = self.wav2vec2._get_feature_vector_attention_mask(\n",
    "        #        encoder_hidden_states.shape[1], \n",
    "        #        attention_mask\n",
    "        #        )\n",
    "        #print(f\"[PRIOR]decoder_input_ids={labels}\")\n",
    "        #print(f\"encoder_hidden_states = {encoder_hidden_states}\")\n",
    "        #print(f\"[PRIOR]decoder_attention_masks={label_attention_mask}\")\n",
    "        #decoder_input_ids = self.shift_tokens_right(labels, 0, 101)\n",
    "        #decoder_attention_masks = self.shift_tokens_right_mask(label_attention_mask)\n",
    "        #print(f\"Shape of labels ={labels.shape}, label_attention_mask = {label_attention_mask.shape}, decoder_input_ids ={decoder_input_ids.shape}, decoder_attention_mask = {decoder_attention_masks.shape}\")\n",
    "        #print(f\"[AFTER]decoder_input_ids={decoder_input_ids}\")\n",
    "        #print(f\"[AFTER]decoder_attention_masks={decoder_attention_masks}\")\n",
    "        decoder_outputs = self.seq2seq(input_ids=labels,\n",
    "                                       attention_mask = label_attention_mask.squeeze(),\n",
    "                                       encoder_hidden_states=encoder_hidden_states)\n",
    "                                       #,encoder_attention_mask=encoder_attention_mask) \n",
    "        # decoder_outputs = self.seq2seq(input_ids=labels, attention_mask = label_attention_mask, encoder_attention_mask=encoder_attention_mask)\n",
    "        return decoder_outputs\n",
    "\n",
    "    def generate(self, audio):\n",
    "        encoder_outputs = self.wav2vec2(audio[0],output_hidden_states=True,output_attentions=True)\n",
    "        encoder_hidden_states = encoder_outputs[0]\n",
    "        bos_ids = (\n",
    "            torch.ones(\n",
    "                (encoder_hidden_states.size()[0], 1),\n",
    "                dtype=torch.long,\n",
    "                device=self.seq2seq.device,\n",
    "            )\n",
    "            * self.seq2seq.config.pad_token_id\n",
    "        )\n",
    "        return self.seq2seq.generate(\n",
    "            input_ids=bos_ids,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #print(\"entering training step\")\n",
    "        audio = batch[\"input_values\"].unsqueeze(0)\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        label_attention_mask = batch[\"label_attention_masks\"].unsqueeze(0)\n",
    "        #print(f\"audio={audio}, attention_mask = {attention_mask}, label_attention_mask = {label_attention_mask}\")\n",
    "        labels = batch[\"labels\"]\n",
    "        labels = labels.reshape(self.batch_size,-1)\n",
    "        #labels = labels.reshape(-1,self.batch_size) \n",
    "        logits = self(audio,attention_mask,labels,label_attention_mask).logits\n",
    "        logits = logits.reshape(-1, self.batch_size, self.seq2seq.config.vocab_size)\n",
    "        input_lengths = torch.full(size=(self.batch_size,), fill_value=logits.shape[0], dtype=torch.long)\n",
    "        target_lengths = torch.full(size=(self.batch_size,), fill_value=labels.shape[0], dtype=torch.long)\n",
    "        loss = None\n",
    "        ctc_loss =  nn.CTCLoss(blank=0)\n",
    "        loss = ctc_loss(logits,labels,input_lengths,target_lengths)\n",
    "        #print(\"Shape of Logits and Labels\")\n",
    "        #print(logits.shape,labels.shape)\n",
    "        #ce_loss = nn.CrossEntropyLoss(weight=self.weights)\n",
    "        #loss = ce_loss(logits.permute(0,2,1), labels.permute(1,0))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch,batch_idx):\n",
    "        #print(\"entering validation step\")\n",
    "        audio = batch[\"input_values\"].unsqueeze(0)\n",
    "        labels = batch[\"labels\"]\n",
    "        \n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        label_attention_mask = batch[\"label_attention_masks\"].unsqueeze(0)\n",
    "        #print(f\"audio={audio}, attention_mask = {attention_mask}, label_attention_mask = {label_attention_mask}\")\n",
    "        #labels = labels.reshape(-1,self.batch_size) \n",
    "        labels = labels.reshape(self.batch_size,-1)\n",
    "        logits = self(audio,attention_mask,labels,label_attention_mask).logits\n",
    "        logits = logits.reshape(-1, self.batch_size, self.seq2seq.config.vocab_size)\n",
    "        input_lengths = torch.full(size=(self.batch_size,), fill_value=logits.shape[0], dtype=torch.long)\n",
    "        target_lengths = torch.full(size=(self.batch_size,), fill_value=labels.shape[0], dtype=torch.long)\n",
    "        loss=None\n",
    "        ctc_loss =  nn.CTCLoss(blank=0)\n",
    "        loss = ctc_loss(logits,labels,input_lengths,target_lengths)\n",
    "        #print(\"Shape of Logits and Labels\")\n",
    "        #print(logits.shape,labels.shape)\n",
    "        #ce_loss = nn.CrossEntropyLoss(weight=self.weights)\n",
    "        #loss = ce_loss(logits.permute(0,2,1), labels.permute(1,0))\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        #label_decoded = labels.type(torch.int32).tolist()\n",
    "        #print(label_decoded)\n",
    "        #print(f\"labels = {labels}\")\n",
    "        #print(f\"Shape/predicted ids = {predicted_ids.shape},{predicted_ids}\")\n",
    "        #print(f\"original transcript = {batch['transcription']}\")\n",
    "        print(f\"original text = {self.bert_tokenizer.decode(labels[0],skip_special_tokens=False)},{self.bert_tokenizer.decode(labels[1],skip_special_tokens=False)}\")\n",
    "        #predicted_text = predicted_ids.type(torch.int32)\n",
    "        print(f\"Predicted text = {self.bert_tokenizer.decode(predicted_ids.T[0,:],skip_special_tokens=False)},{self.bert_tokenizer.decode(predicted_ids.T[1,:],skip_special_tokens=False)}\")\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        print(\"Entering Optimization Step\")\n",
    "        return torch.optim.AdamW(self.parameters(), lr=hparams.learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n",
    "        \"\"\"\n",
    "        Shift input ids one token to the right.\n",
    "        \"\"\"\n",
    "        shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "        shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
    "        if decoder_start_token_id is None:\n",
    "            raise ValueError(\"Make sure to set the decoder_start_token_id attribute of the model's configuration.\")\n",
    "        shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "    \n",
    "        if pad_token_id is None:\n",
    "            raise ValueError(\"Make sure to set the pad_token_id attribute of the model's configuration.\")\n",
    "        # replace possible -100 values in labels by `pad_token_id`\n",
    "        shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "    \n",
    "        return shifted_input_ids\n",
    "\n",
    "    @staticmethod\n",
    "    def shift_tokens_right_mask(input_ids: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Shift input ids one token to the right.\n",
    "        \"\"\"\n",
    "        shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "        shifted_input_ids[:,:, 1:] = input_ids[:,:, :-1].clone()\n",
    "        shifted_input_ids[:,:, 0] = 0\n",
    "        return shifted_input_ids.squeeze()\n",
    "\n",
    "def run(hparams):\n",
    "    print(hparams)\n",
    "    model = Wav2SeqModel(hparams)\n",
    "    trainer = Trainer(max_epochs=10,devices=1, accelerator=\"gpu\", logger=wandb_logger)\n",
    "    trainer.fit(model,SpeechRecognitionDataModule(WAV2VEC2_ARGS,num_workers=4,hparams=hparams))\n",
    "    return model, trainer\n",
    "\n",
    "\n",
    "hparams = argparse.Namespace()\n",
    "hparams.wav2vec2_model = 'facebook/wav2vec2-large-960h-lv60-self'\n",
    "hparams.lm_model = 'bert-base-uncased' #'facebook/bart-large'\n",
    "hparams.vocab_size = 40000\n",
    "hparams.learning_rate = 1e-3\n",
    "hparams.batch_size = 2\n",
    "\n",
    "model,trainer = run(hparams=hparams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
