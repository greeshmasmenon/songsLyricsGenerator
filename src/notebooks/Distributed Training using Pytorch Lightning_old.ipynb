{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c390f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightning-flash\n",
    "! pip install 'lightning-flash[audio,text]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4a1c186-1b0a-43aa-aa9f-9074512198f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting jiwer\n",
      "  Obtaining dependency information for jiwer from https://files.pythonhosted.org/packages/23/a3/92c29a5e422acd87e3b4f2e6dc0ce877070cc9b2f81d30fe84122032338a/jiwer-3.0.2-py3-none-any.whl.metadata\n",
      "  Downloading jiwer-3.0.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /mnt/irisgpfs/users/gmenon/workspace/songsLyricsGenerator/slg_wav2vec2/lib/python3.8/site-packages (from jiwer) (8.1.6)\n",
      "Collecting rapidfuzz==2.13.7 (from jiwer)\n",
      "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiwer-3.0.2-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-3.0.2 rapidfuzz-2.13.7\n"
     ]
    }
   ],
   "source": [
    "! pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe7b8b50-a502-45d2-b2e3-a492655f365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Downloading https://github.com/kpu/kenlm/archive/master.zip (553 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.5/553.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyctcdecode\n",
      "  Downloading pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.15.0 in /mnt/irisgpfs/users/gmenon/workspace/songsLyricsGenerator/slg_wav2vec2/lib/python3.8/site-packages (from pyctcdecode) (1.23.5)\n",
      "Collecting pygtrie<3.0,>=2.1 (from pyctcdecode)\n",
      "  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
      "Collecting hypothesis<7,>=6.14 (from pyctcdecode)\n",
      "  Obtaining dependency information for hypothesis<7,>=6.14 from https://files.pythonhosted.org/packages/f7/af/c94ff33c5ba640d17e13cdfd17fc90bc245df1f285a6d418f1fc7d9610d8/hypothesis-6.82.0-py3-none-any.whl.metadata\n",
      "  Downloading hypothesis-6.82.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /mnt/irisgpfs/users/gmenon/workspace/songsLyricsGenerator/slg_wav2vec2/lib/python3.8/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (23.1.0)\n",
      "Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis<7,>=6.14->pyctcdecode)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0 in /mnt/irisgpfs/users/gmenon/workspace/songsLyricsGenerator/slg_wav2vec2/lib/python3.8/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (1.1.2)\n",
      "Downloading hypothesis-6.82.0-py3-none-any.whl (414 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.9/414.9 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: kenlm\n",
      "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kenlm: filename=kenlm-0.0.0-cp38-cp38-linux_x86_64.whl size=3214997 sha256=f4db6c3f2007c499b580bccad2fca7ccba83d116fc0952bd48bdfd8076842da6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jv20egqq/wheels/ff/08/4e/a3ddc0e786e0f3c1fcd2e7a82c4324c02fc3ae2638471406d2\n",
      "Successfully built kenlm\n",
      "Installing collected packages: sortedcontainers, pygtrie, kenlm, hypothesis, pyctcdecode\n",
      "Successfully installed hypothesis-6.82.0 kenlm-0.0.0 pyctcdecode-0.5.0 pygtrie-2.5.0 sortedcontainers-2.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install https://github.com/kpu/kenlm/archive/master.zip pyctcdecode"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a77a1125-debf-4e09-9212-738f668fb293",
   "metadata": {},
   "source": [
    "from transformers import Wav2Vec2ProcessorWithLM\n",
    "\n",
    "processor = Wav2Vec2ProcessorWithLM.from_pretrained(\"patrickvonplaten/wav2vec2-base-100h-with-lm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "468edd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flash\n",
    "import torch\n",
    "from flash.audio import SpeechRecognition, SpeechRecognitionData"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41418dc1-57b8-49ce-b550-d3c81b89136f",
   "metadata": {},
   "source": [
    "import flash\n",
    "import torch\n",
    "from flash.audio import SpeechRecognition, SpeechRecognitionData\n",
    "from flash.core.data.utils import download_data\n",
    "\n",
    "# 1. Create the DataModule\n",
    "download_data(\"https://pl-flash-data.s3.amazonaws.com/timit_data.zip\", \"./data\")\n",
    "\n",
    "datamodule = SpeechRecognitionData.from_json(\n",
    "    \"file\",\n",
    "    \"text\",\n",
    "    train_file=\"data/timit/train.json\",\n",
    "    test_file=\"data/timit/test.json\",\n",
    "    batch_size=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778945c6-db8c-4d58-992e-c09df54f865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Build the task\n",
    "model = SpeechRecognition(backbone=\"facebook/wav2vec2-large-960h-lv60-self\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09d20f25-d544-4586-a104-b2e7d302af55",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Create the trainer and finetune the model\n",
    "trainer = flash.Trainer(max_epochs=1, gpus=torch.cuda.device_count())\n",
    "trainer.finetune(model, datamodule=datamodule, strategy=\"unfreeze\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5315feb1-011d-4207-bc49-f1435fe811ac",
   "metadata": {},
   "source": [
    "# 4. Predict on audio files!\n",
    "datamodule = SpeechRecognitionData.from_files(predict_files=[\"data/timit/example.wav\"], batch_size=4)\n",
    "predictions = trainer.predict(model, datamodule=datamodule)\n",
    "print(predictions)\n",
    "\n",
    "# 5. Save the model!\n",
    "trainer.save_checkpoint(\"speech_recognition_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e011a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7229fb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "wav2vec2_trainer = flash.Trainer(accumulate_grad_batches=1,\n",
    "                                              precision=16,\n",
    "                                              max_epochs=1,\n",
    "                                              gpus=1,\n",
    "                                              num_nodes = 1\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "53fdbb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'facebook/wav2vec2-large-robust-ft-libri-960h' provided by Hugging Face/transformers (https://github.com/huggingface/transformers).\n",
      "Using 'facebook/wav2vec2-large-robust-ft-libri-960h' provided by Hugging Face/transformers (https://github.com/huggingface/transformers).\n"
     ]
    }
   ],
   "source": [
    "wav2vec2_model = SpeechRecognition.load_from_checkpoint(\"/home/users/gmenon/workspace/songsLyricsGenerator/src/model_artefacts/wav2vec2_demucs_en_finetuned_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "bded8ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'facebook/wav2vec2-large-960h-lv60-self' provided by Hugging Face/transformers (https://github.com/huggingface/transformers).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#wav2vec2_model = SpeechRecognition.load_from_checkpoint(\"/home/users/gmenon/workspace/songsLyricsGenerator/src/model_artefacts/wav2vec2_demucs_en_finetuned_model.pt\")\n",
    "wav2vec2_model = SpeechRecognition.load_from_checkpoint(\"/home/users/gmenon/workspace/songsLyricsGenerator/src/model_artefacts/wav2vec2_demucs_en_finetuned_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "e8d5a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.read_csv(\"/home/users/gmenon/notebooks/home/users/gmenon/notebooks/validation_song_metadata_en_demucs_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "2f9a2f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>consolidated_file_path</th>\n",
       "      <th>Length</th>\n",
       "      <th>file_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>language</th>\n",
       "      <th>transcription_capitalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9fdeb5c63854498da6defbca63f128be</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>1.509002</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>just a tryin' to survive</td>\n",
       "      <td>en</td>\n",
       "      <td>JUST A TRYIN' TO SURVIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2ad6272e46440cd9239e6186de5e74a</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>3.062948</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>don't go on me</td>\n",
       "      <td>en</td>\n",
       "      <td>DON'T GO ON ME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Folder        File  \\\n",
       "0  9fdeb5c63854498da6defbca63f128be  vocals.wav   \n",
       "1  d2ad6272e46440cd9239e6186de5e74a  vocals.wav   \n",
       "\n",
       "                              consolidated_file_path    Length  \\\n",
       "0  /home/users/gmenon/workspace/songsLyricsGenera...  1.509002   \n",
       "1  /home/users/gmenon/workspace/songsLyricsGenera...  3.062948   \n",
       "\n",
       "                                           file_name  \\\n",
       "0  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "1  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "\n",
       "              transcription language transcription_capitalized  \n",
       "0  just a tryin' to survive       en  JUST A TRYIN' TO SURVIVE  \n",
       "1            don't go on me       en            DON'T GO ON ME  "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "8bf6c2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf898f280c7b43ef99758b4e3c503152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1222b6b91f84eac82eb91012ea8fb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_datamodule = SpeechRecognitionData.from_files(\n",
    "    predict_files=list(test_data[\"consolidated_file_path\"]), \n",
    "    batch_size=1)\n",
    "\n",
    "finetuned_predictions = wav2vec2_trainer.predict(wav2vec2_model, \n",
    "                                                datamodule=test_datamodule)\n",
    "\n",
    "base_pred = wav2vec2_trainer.predict(model, \n",
    "                                                datamodule=test_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "80e41157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>consolidated_file_path</th>\n",
       "      <th>Length</th>\n",
       "      <th>file_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>language</th>\n",
       "      <th>transcription_capitalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9fdeb5c63854498da6defbca63f128be</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>1.509002</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>just a tryin' to survive</td>\n",
       "      <td>en</td>\n",
       "      <td>JUST A TRYIN' TO SURVIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2ad6272e46440cd9239e6186de5e74a</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>3.062948</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>don't go on me</td>\n",
       "      <td>en</td>\n",
       "      <td>DON'T GO ON ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a76d6dfe717b460ea33b7e6e86df183d</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>5.003084</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>i don't know how i feel</td>\n",
       "      <td>en</td>\n",
       "      <td>I DON'T KNOW HOW I FEEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1cede001e02c41bea6a63569465e7b03</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>1.757007</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>i would love to love you lover</td>\n",
       "      <td>en</td>\n",
       "      <td>I WOULD LOVE TO LOVE YOU LOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9a7cc26706da4e0e92c61608c32d9580</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>7.486757</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>i am the greatest man that ever lived</td>\n",
       "      <td>en</td>\n",
       "      <td>I AM THE GREATEST MAN THAT EVER LIVED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Folder        File  \\\n",
       "0  9fdeb5c63854498da6defbca63f128be  vocals.wav   \n",
       "1  d2ad6272e46440cd9239e6186de5e74a  vocals.wav   \n",
       "2  a76d6dfe717b460ea33b7e6e86df183d  vocals.wav   \n",
       "3  1cede001e02c41bea6a63569465e7b03  vocals.wav   \n",
       "4  9a7cc26706da4e0e92c61608c32d9580  vocals.wav   \n",
       "\n",
       "                              consolidated_file_path    Length  \\\n",
       "0  /home/users/gmenon/workspace/songsLyricsGenera...  1.509002   \n",
       "1  /home/users/gmenon/workspace/songsLyricsGenera...  3.062948   \n",
       "2  /home/users/gmenon/workspace/songsLyricsGenera...  5.003084   \n",
       "3  /home/users/gmenon/workspace/songsLyricsGenera...  1.757007   \n",
       "4  /home/users/gmenon/workspace/songsLyricsGenera...  7.486757   \n",
       "\n",
       "                                           file_name  \\\n",
       "0  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "1  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "2  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "3  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "4  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "\n",
       "                           transcription language  \\\n",
       "0               just a tryin' to survive       en   \n",
       "1                         don't go on me       en   \n",
       "2                i don't know how i feel       en   \n",
       "3         i would love to love you lover       en   \n",
       "4  i am the greatest man that ever lived       en   \n",
       "\n",
       "               transcription_capitalized  \n",
       "0               JUST A TRYIN' TO SURVIVE  \n",
       "1                         DON'T GO ON ME  \n",
       "2                I DON'T KNOW HOW I FEEL  \n",
       "3         I WOULD LOVE TO LOVE YOU LOVER  \n",
       "4  I AM THE GREATEST MAN THAT EVER LIVED  "
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "756c5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred_transformed = []\n",
    "for predictions in base_pred:\n",
    "    base_pred_transformed.append(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "a01107b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_pred_transformed = []\n",
    "for predictions in finetuned_predictions:\n",
    "    finetuned_pred_transformed.append(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "231beae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"base_pred\"] = base_pred_transformed\n",
    "test_data[\"finetuned_predictions\"] = finetuned_pred_transformed"
   ]
  },
  {
   "cell_type": "raw",
   "id": "246633da-12e6-4ed7-b95b-014a91e876c4",
   "metadata": {},
   "source": [
    "from jiwer import wer\n",
    "\n",
    "reference = [\"hello world\", \"i like monthy python\"]\n",
    "hypothesis = [\"hello duck\", \"i like python\"]\n",
    "\n",
    "error = wer(reference, hypothesis)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "1c03427e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7814730100640439"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jiwer import wer\n",
    "\n",
    "reference = list(test_data[\"transcription_capitalized\"])\n",
    "hypothesis = base_pred_transformed\n",
    "\n",
    "error = wer(reference, hypothesis)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "13020a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7814730100640439"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jiwer import wer\n",
    "\n",
    "reference = list(test_data[\"transcription_capitalized\"])\n",
    "hypothesis = finetuned_pred_transformed\n",
    "\n",
    "error = wer(reference, hypothesis)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d93dc-0d58-477e-90ee-77903ab36f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "42f6c7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>consolidated_file_path</th>\n",
       "      <th>Length</th>\n",
       "      <th>file_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>language</th>\n",
       "      <th>transcription_capitalized</th>\n",
       "      <th>base_pred</th>\n",
       "      <th>finetuned_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3388279af3904205916cdc0ae818c398</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>2.022449</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>i'm the one who takes you there</td>\n",
       "      <td>en</td>\n",
       "      <td>I'M THE ONE WHO TAKES YOU THERE</td>\n",
       "      <td>I'M NO GOING TO TAKE YOU THERE</td>\n",
       "      <td>I'M NO GOING TO TAKE YOU THERE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>23ff388c931d4fe5af9e87eea597defd</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>1.607506</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>cuz you're the baddest little thing</td>\n",
       "      <td>en</td>\n",
       "      <td>CUZ YOU'RE THE BADDEST LITTLE THING</td>\n",
       "      <td>I'S AL THE BAES SIN THING</td>\n",
       "      <td>I'S AL THE BAES SIN THING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>d89513df28a946c193d564b7b9c4007d</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>have no fear of death</td>\n",
       "      <td>en</td>\n",
       "      <td>HAVE NO FEAR OF DEATH</td>\n",
       "      <td>O YO LI O</td>\n",
       "      <td>O YO LI O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>a88718deaae24732886fdc197dc845a8</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>4.588254</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>unending answer to all your fears</td>\n",
       "      <td>en</td>\n",
       "      <td>UNENDING ANSWER TO ALL YOUR FEARS</td>\n",
       "      <td>I'M LENTING ANSER TO ALL YOUR PERS</td>\n",
       "      <td>I'M LENTING ANSER TO ALL YOUR PERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>711e8893e10e498f9086c0d7c6c1947d</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>2.175011</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>you're gonna be just fine</td>\n",
       "      <td>en</td>\n",
       "      <td>YOU'RE GONNA BE JUST FINE</td>\n",
       "      <td>WE GON TO MAKE TIS FAT</td>\n",
       "      <td>WE GON TO MAKE TIS FAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0feb990352bf494f95ae7e3417cf8559</td>\n",
       "      <td>vocals.wav</td>\n",
       "      <td>/home/users/gmenon/workspace/songsLyricsGenera...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>/home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...</td>\n",
       "      <td>has darkness taken over me</td>\n",
       "      <td>en</td>\n",
       "      <td>HAS DARKNESS TAKEN OVER ME</td>\n",
       "      <td>AND NO THE SAV E OI</td>\n",
       "      <td>AND NO THE SAV E OI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Folder        File  \\\n",
       "50  3388279af3904205916cdc0ae818c398  vocals.wav   \n",
       "51  23ff388c931d4fe5af9e87eea597defd  vocals.wav   \n",
       "52  d89513df28a946c193d564b7b9c4007d  vocals.wav   \n",
       "53  a88718deaae24732886fdc197dc845a8  vocals.wav   \n",
       "54  711e8893e10e498f9086c0d7c6c1947d  vocals.wav   \n",
       "55  0feb990352bf494f95ae7e3417cf8559  vocals.wav   \n",
       "\n",
       "                               consolidated_file_path    Length  \\\n",
       "50  /home/users/gmenon/workspace/songsLyricsGenera...  2.022449   \n",
       "51  /home/users/gmenon/workspace/songsLyricsGenera...  1.607506   \n",
       "52  /home/users/gmenon/workspace/songsLyricsGenera...  2.100000   \n",
       "53  /home/users/gmenon/workspace/songsLyricsGenera...  4.588254   \n",
       "54  /home/users/gmenon/workspace/songsLyricsGenera...  2.175011   \n",
       "55  /home/users/gmenon/workspace/songsLyricsGenera...  4.000000   \n",
       "\n",
       "                                            file_name  \\\n",
       "50  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "51  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "52  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "53  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "54  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "55  /home/users/gmenon/dali/DALI_v1.0/audio/wav_cl...   \n",
       "\n",
       "                          transcription language  \\\n",
       "50      i'm the one who takes you there       en   \n",
       "51  cuz you're the baddest little thing       en   \n",
       "52                have no fear of death       en   \n",
       "53    unending answer to all your fears       en   \n",
       "54            you're gonna be just fine       en   \n",
       "55           has darkness taken over me       en   \n",
       "\n",
       "              transcription_capitalized                           base_pred  \\\n",
       "50      I'M THE ONE WHO TAKES YOU THERE      I'M NO GOING TO TAKE YOU THERE   \n",
       "51  CUZ YOU'RE THE BADDEST LITTLE THING           I'S AL THE BAES SIN THING   \n",
       "52                HAVE NO FEAR OF DEATH                           O YO LI O   \n",
       "53    UNENDING ANSWER TO ALL YOUR FEARS  I'M LENTING ANSER TO ALL YOUR PERS   \n",
       "54            YOU'RE GONNA BE JUST FINE              WE GON TO MAKE TIS FAT   \n",
       "55           HAS DARKNESS TAKEN OVER ME                 AND NO THE SAV E OI   \n",
       "\n",
       "                 finetuned_predictions  \n",
       "50      I'M NO GOING TO TAKE YOU THERE  \n",
       "51           I'S AL THE BAES SIN THING  \n",
       "52                           O YO LI O  \n",
       "53  I'M LENTING ANSER TO ALL YOUR PERS  \n",
       "54              WE GON TO MAKE TIS FAT  \n",
       "55                 AND NO THE SAV E OI  "
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.loc[50:55,:]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f931d127-a2a1-47a2-ac9b-fc990a8b5abd",
   "metadata": {},
   "source": [
    "model = SpeechRecognition.load_from_checkpoint(\"/home/users/gmenon/workspace/songsLyricsGenerator/src/model_artefacts/wav2vec2_demucs_en_finetuned_model.pt\")\n",
    "\n",
    "trainer = flash.Trainer()\n",
    "\n",
    "test_datamodule = SpeechRecognitionData.from_files(\n",
    "    predict_files=list(test_data.loc[48:50,:][\"consolidated_file_path\"]),\n",
    "    batch_size=1)\n",
    "\n",
    "wav2vec2_predictions = trainer.predict(model, datamodule=test_datamodule)\n",
    "wav2vec2_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "598bc414-baf9-4a68-b9dc-052a96b8a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load pretrained model\n",
    "# from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "# asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "# asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "b23132d6-731b-4724-b95c-f282c95c4af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import Wav2Vec2ProcessorWithLM\n",
    "\n",
    "# processor = Wav2Vec2ProcessorWithLM.from_pretrained(\"patrickvonplaten/wav2vec2-base-100h-with-lm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "566af702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyctcdecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1bb180-d763-4856-a30b-8b5863a11363",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\"<pad>\": 0, \"<s>\": 1, \"</s>\": 2, \"<unk>\": 3, \"|\": 4, \"E\": 5, \"T\": 6, \"A\": 7, \"O\": 8, \"N\": 9, \"I\": 10, \"H\": 11, \"S\": 12, \"R\": 13, \"D\": 14, \"L\": 15, \"U\": 16, \"M\": 17, \"W\": 18, \"C\": 19, \"F\": 20, \"G\": 21, \"Y\": 22, \"P\": 23, \"B\": 24, \"V\": 25, \"K\": 26, \"'\": 27, \"X\": 28, \"J\": 29, \"Q\": 30, \"Z\": 31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4bdbbf1-b5a7-488a-84da-ccddaa2d9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0833f79f-268e-4420-8fc3-882233723222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "waveform, sample_rate = torchaudio.load('/home/users/gmenon/workspace/songsLyricsGenerator/data/DALI_v1.0/audio/wav_clips/separated/htdemucs/a88718deaae24732886fdc197dc845a8/vocals.wav')\n",
    "waveform = torchaudio.functional.resample(waveform, sample_rate, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "978d8872-01ba-4f91-8916-b2da3baeaa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 73413])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform.squeeze().shape\n",
    "#model = SpeechRecognition.load_from_checkpoint(\"/home/users/gmenon/workspace/songsLyricsGenerator/src/model_artefacts/wav2vec2_demucs_en_finetuned_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b38c6f88-d0a6-4e63-9d8e-b66b50bd45ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00172427,  0.00930336,  0.00756506, ..., -0.11694409,\n",
       "       -0.07854679, -0.01719929], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "waveform = librosa.to_mono(np.array(waveform))\n",
    "waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "130768ce-a5bb-4aca-afcf-4888d188772d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73413,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd8dfee-fa8b-4a6d-955e-22c619ee49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchaudio.models.decoder import ctc_decoder, download_pretrained_files\n",
    "# files = download_pretrained_files(\"librispeech-4-gram\")\n",
    "# decoder = ctc_decoder(\n",
    "#    lexicon=files.lexicon,\n",
    "#    tokens=files.tokens,\n",
    "#    lm=files.lm,\n",
    "#    nbest=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e558412b-a13f-4fe4-aec6-52662a120fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 'facebook/wav2vec2-large-960h-lv60-self' provided by Hugging Face/transformers (https://github.com/huggingface/transformers).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# load model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "hf_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "model = SpeechRecognition.load_from_checkpoint(\"/home/users/gmenon/workspace/songsLyricsGenerator/src/model_artefacts/wav2vec2_demucs_en_finetuned_model.pt\")\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3eec26-9c8f-416c-86d6-0d2ed95db2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995fe9ac-c761-4380-8089-8095c6380f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa798ae9-755d-4e45-a9bb-e4d136fed2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fefd4d46-b5cf-45a9-a571-428ad1de46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"audio\"][0][\"array\"].shape, waveform.T.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7622c0c9-8650-4a9e-b92f-bb8c2eb28686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = processor(dataset[\"audio\"][0][\"array\"], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "# inputs[\"input_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1637075-9fc4-4e59-bf8c-ec211ee1a317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 73413])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = processor(waveform.T.squeeze(), sampling_rate=16_000, return_tensors=\"pt\")\n",
    "inputs[\"input_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f351521b-716d-41de-9a6b-73767e89e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = {k: v.to(\"cuda\") for k,v in inputs.items()}\n",
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa3a3940-61ee-47c3-91f4-b81298f06f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73413,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efde32b4-4528-4d4d-93ee-46ff0db503d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 73413])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = processor(waveform, sampling_rate=16_000, return_tensors=\"pt\")\n",
    "inputs[\"input_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49eb1107-eac2-4411-861a-a4dcaf9e5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "  logits = model.model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24b020ea-dfaa-4fbf-8a64-0fff00fba156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 229, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "021777f7-692b-4a41-88aa-a135f89a3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyctcdecode import build_ctcdecoder\n",
    "vocab = {\"<pad>\": 0, \"<s>\": 1, \"</s>\": 2, \"<unk>\": 3, \"|\": 4, \"E\": 5, \"T\": 6, \"A\": 7, \"O\": 8, \"N\": 9, \"I\": 10, \"H\": 11, \"S\": 12, \"R\": 13, \"D\": 14, \"L\": 15, \"U\": 16, \"M\": 17, \"W\": 18, \"C\": 19, \"F\": 20, \"G\": 21, \"Y\": 22, \"P\": 23, \"B\": 24, \"V\": 25, \"K\": 26, \"'\": 27, \"X\": 28, \"J\": 29, \"Q\": 30, \"Z\": 31}\n",
    "vocab_list = list(vocab.keys())\n",
    "# decoder = build_ctcdecoder(vocab_list)\n",
    "# decoder.decode(logits.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3dd4c01-136d-4a66-990d-f8060bc7ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _greedy_decode(logits,labels):\n",
    "    \"\"\"Decode argmax of logits and squash in CTC fashion.\"\"\"\n",
    "    label_dict = {n: c for n, c in enumerate(labels)}\n",
    "    prev_c = None\n",
    "    out = []\n",
    "    for x in logits.argmax(axis=1):\n",
    "        for n in x:\n",
    "            c = label_dict.get(n.item(), \"\")  # if not in labels, then assume it's ctc blank char\n",
    "            if c != prev_c:\n",
    "                out.append(c)\n",
    "            prev_c = c\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad9616f5-ce15-49ad-8e31-d38b6997ec41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KNUUD'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_greedy_decode(logits,vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "075cefa2-1427-424c-bab2-51caa1b51b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PretrainedFiles(lexicon='/home/users/gmenon/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lexicon.txt', tokens='/home/users/gmenon/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/tokens.txt', lm='/home/users/gmenon/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lm.bin')\n"
     ]
    }
   ],
   "source": [
    "from torchaudio.models.decoder import download_pretrained_files\n",
    "\n",
    "files = download_pretrained_files(\"librispeech-4-gram\")\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcef8cb6-c232-4caa-ba88-eb3a17968cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  9.9043, -22.8711, -22.5385, -22.3990,  -7.7792,  -0.8127,   1.0707,\n",
       "          0.9914,  -0.8369,  -0.6631,   2.3691,  -1.1760,   1.9395,  -3.5349,\n",
       "         -0.7451,  -1.7523,  -1.9744,  -2.6891,  -0.5868,  -2.0085,  -2.5887,\n",
       "         -3.4665,  -0.8007,  -1.5650,  -1.4590,  -3.6714,  -1.9487,  -2.5568,\n",
       "         -4.8734,  -3.8054,  -6.8474,  -2.7006])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.squeeze()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "122042ef-928b-4270-90cc-34ac7b31963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'M LENTING ANSER TO ALL YOUR PERS\n"
     ]
    }
   ],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "\n",
    "decoder = build_ctcdecoder(vocab_list)\n",
    "print(decoder.decode(logits[0].cpu().detach().numpy()))\n",
    "#print(decoder.decode_beams(logits[0].cpu().detach().numpy()))[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2880bf4b-cee1-4ff7-b3e6-92069b986009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pwd (/mnt/irisgpfs/users/gmenon/workspace/songsLyricsGenerator/src/notebooks)\n",
    "\n",
    "# !pip install https://github.com/kpu/kenlm/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cd8c8ec-7c57-48c1-9044-08ac89e3acf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /home/users/gmenon/workspace/songsLyricsGenerator/src/kenlm/4gram_big.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import kenlm\n",
    "kenlm_model = kenlm.Model('/home/users/gmenon/workspace/songsLyricsGenerator/src/kenlm/4gram_big.arpa')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cd10802-0d7a-421a-b290-ec7107febdb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert <class 'kenlm.Model'> to string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m decoder \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_ctcdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkenlm_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m decoder\u001b[38;5;241m.\u001b[39mdecode(logits)\n",
      "File \u001b[0;32m/mnt/irisgpfs/users/gmenon/workspace/songsLyricsGenerator/slg_wav2vec2/lib/python3.8/site-packages/pyctcdecode/decoder.py:907\u001b[0m, in \u001b[0;36mbuild_ctcdecoder\u001b[0;34m(labels, kenlm_model_path, unigrams, alpha, beta, unk_score_offset, lm_score_boundary)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_ctcdecoder\u001b[39m(\n\u001b[1;32m    885\u001b[0m     labels: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    886\u001b[0m     kenlm_model_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m     lm_score_boundary: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_SCORE_LM_BOUNDARY,\n\u001b[1;32m    892\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeamSearchDecoderCTC:\n\u001b[1;32m    893\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a BeamSearchDecoderCTC instance with main functionality.\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \n\u001b[1;32m    895\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;124;03m        instance of BeamSearchDecoderCTC\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m     kenlm_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m kenlm_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mkenlm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkenlm_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kenlm_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m kenlm_model_path\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.arpa\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    909\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing arpa instead of binary LM file, decoder instantiation might be slow.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32mkenlm.pyx:137\u001b[0m, in \u001b[0;36mkenlm.Model.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mkenlm.pyx:9\u001b[0m, in \u001b[0;36mkenlm.as_str\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert <class 'kenlm.Model'> to string"
     ]
    }
   ],
   "source": [
    "decoder = build_ctcdecoder(\n",
    "    asr_model.decoder.vocabulary,\n",
    "    kenlm_model,\n",
    "    unigram_list,\n",
    ")\n",
    "decoder.decode(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b81488-6321-44f2-b94d-30337fc8d03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ctcdecode' already exists and is not an empty directory.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Processing /mnt/irisgpfs/users/gmenon/workspace/songsLyricsGenerator/src/notebooks/ctcdecode\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ctcdecode\n",
      "  Building wheel for ctcdecode (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ctcdecode: filename=ctcdecode-1.0.3-cp38-cp38-linux_x86_64.whl size=19313592 sha256=400a09d0d9f8029080bfafd416a31944a79dc6a39f001c2b7dc6ae6c618da92a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gr_knuf_/wheels/51/ba/8e/ad9755178fe9d27230218c9fd8c6dd3934ef9606f61e3b6598\n",
      "Successfully built ctcdecode\n",
      "Installing collected packages: ctcdecode\n",
      "Successfully installed ctcdecode-1.0.3\n"
     ]
    }
   ],
   "source": [
    "# ! git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "# ! cd ctcdecode && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "f3a208d3-1533-49a5-8a99-cd5f8f52510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-21.547266006469727\n"
     ]
    }
   ],
   "source": [
    "# print(model.score(\"i'm lenting answe to all your pers\", bos = True, eos = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff253f79-3a27-48b3-96db-892731fca1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function CTCBeamDecoder.__del__ at 0x7fff24b6eb80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/irisgpfs/users/gmenon/workspace/songsLyricsGenerator/slg_wav2vec2/lib/python3.8/site-packages/ctcdecode/__init__.py\", line 139, in __del__\n",
      "    if self._scorer is not None:\n",
      "AttributeError: 'CTCBeamDecoder' object has no attribute '_scorer'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'lm_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mctcdecode\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m beam_decoder \u001b[38;5;241m=\u001b[39m \u001b[43mCTCBeamDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mlm_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/users/gmenon/workspace/songsLyricsGenerator/src/kenlm/4gram_big.arpa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcutoff_top_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcutoff_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mbeam_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mblank_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'lm_path'"
     ]
    }
   ],
   "source": [
    "import ctcdecode\n",
    "\n",
    "beam_decoder = CTCBeamDecoder(vocab_list, \n",
    "                                    lm_path='/home/users/gmenon/workspace/songsLyricsGenerator/src/kenlm/4gram_big.arpa',\n",
    "                                     alpha=0.5,\n",
    "                                     beta=1,\n",
    "                                     cutoff_top_n=40,\n",
    "                                     cutoff_prob=1.0,\n",
    "                                     beam_width=100, \n",
    "                                     num_processes=16,\n",
    "                                     blank_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b0ac59d-1e7e-45da-b1e3-d721892aae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctcdecode import CTCBeamDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4545ec2e-debf-45ae-8e7a-e48de670760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "decoder = CTCBeamDecoder(\n",
    "    labels,\n",
    "    model_path=None,\n",
    "    alpha=0,\n",
    "    beta=0,\n",
    "    cutoff_top_n=40,\n",
    "    cutoff_prob=1.0,\n",
    "    beam_width=100,\n",
    "    num_processes=4,\n",
    "    blank_id=0,\n",
    "    log_probs_input=False\n",
    ")\n",
    "beam_results, beam_scores, timesteps, out_lens = decoder.decode(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c03cbc2-1070-4230-9f24-3bae741668a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 229])\n",
      "hello\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 229 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m n:\n\u001b[0;32m----> 6\u001b[0m     c \u001b[38;5;241m=\u001b[39m label_dict\u001b[38;5;241m.\u001b[39mget(\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(c)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 229 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "label_dict = {n: c for n, c in enumerate(vocab_list)}\n",
    "print(beam_results.shape)\n",
    "for n in beam_results.squeeze():\n",
    "    print(\"hello\")\n",
    "    for x in n:\n",
    "        c = label_dict.get(n.item(), \"\")\n",
    "        print(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "748dad54-67ed-4318-8060-69b796d83c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<s>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '|',\n",
       " 'E',\n",
       " 'T',\n",
       " 'A',\n",
       " 'O',\n",
       " 'N',\n",
       " 'I',\n",
       " 'H',\n",
       " 'S',\n",
       " 'R',\n",
       " 'D',\n",
       " 'L',\n",
       " 'U',\n",
       " 'M',\n",
       " 'W',\n",
       " 'C',\n",
       " 'F',\n",
       " 'G',\n",
       " 'Y',\n",
       " 'P',\n",
       " 'B',\n",
       " 'V',\n",
       " 'K',\n",
       " \"'\",\n",
       " 'X',\n",
       " 'J',\n",
       " 'Q',\n",
       " 'Z']"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4594a3b-b820-45b6-a14e-70807cdaa01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = CTCBeamDecoder(\n",
    "    labels,\n",
    "    model_path=None,\n",
    "    alpha=0,\n",
    "    beta=0,\n",
    "    cutoff_top_n=40,\n",
    "    cutoff_prob=1.0,\n",
    "    beam_width=100,\n",
    "    num_processes=4,\n",
    "    blank_id=0,\n",
    "    log_probs_input=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb2fca-7f84-492c-89ba-1357b4239ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_result = beam_search_decoder(logits)\n",
    "beam_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692be30-2581-4652-9bc7-fde14c5572b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_transcript = \" \".join(beam_search_result[0][0].words).strip()\n",
    "beam_search_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb22cb3-7005-489f-bed4-2b7be56bb62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = beam_search_result[0][0].timesteps\n",
    "predicted_tokens = beam_search_decoder.idxs_to_tokens(beam_search_result[0][0].tokens)\n",
    "\n",
    "print(predicted_tokens, len(predicted_tokens))\n",
    "print(timesteps, timesteps.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "fe23483c-2fd0-4bcb-a2a8-bdeaa3a40f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyctcdecode import build_ctcdecoder\n",
    "# vocab = {\"<pad>\": 0, \"<s>\": 1, \"</s>\": 2, \"<unk>\": 3, \"|\": 4, \"E\": 5, \"T\": 6, \"A\": 7, \"O\": 8, \"N\": 9, \"I\": 10, \"H\": 11, \"S\": 12, \"R\": 13, \"D\": 14, \"L\": 15, \"U\": 16, \"M\": 17, \"W\": 18, \"C\": 19, \"F\": 20, \"G\": 21, \"Y\": 22, \"P\": 23, \"B\": 24, \"V\": 25, \"K\": 26, \"'\": 27, \"X\": 28, \"J\": 29, \"Q\": 30, \"Z\": 31}\n",
    "# vocab_list = list(vocab.keys())\n",
    "# decoder = build_ctcdecoder(vocab_list)\n",
    "# decoder.decode(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "191c9c69-7238-4973-9e60-dd7de4b60b6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actual_transcript' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[477], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m beam_search_wer \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39medit_distance(\u001b[43mactual_transcript\u001b[49m, beam_search_result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mwords) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m      2\u001b[0m     actual_transcript\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscript: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeam_search_transcript\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbeam_search_wer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'actual_transcript' is not defined"
     ]
    }
   ],
   "source": [
    "beam_search_wer = torchaudio.functional.edit_distance(actual_transcript, beam_search_result[0][0].words) / len(\n",
    "    actual_transcript\n",
    ")\n",
    "\n",
    "print(f\"Transcript: {beam_search_transcript}\")\n",
    "print(f\"WER: {beam_search_wer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5043444-8aba-4108-a14e-151370187f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dedeae-78b6-427a-9920-d9843daf8541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4caee43-71a0-42ff-a0d4-9e108ae97404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
