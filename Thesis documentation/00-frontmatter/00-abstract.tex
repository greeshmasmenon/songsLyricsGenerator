\chapter*{\centering Abstract}
\addcontentsline{toc}{chapter}{Abstract}


    Music lovers across the world enjoy listening to music and singing along with them. Inspite of artists publishing over 100 million songs in top audio streaming services, there are only 8 million songs with associated lyrics. In this work, we propose that pre-trained models that are trained in the speech domain can be used with minimal data in the songs domain to improve current benchmarks in the Songs to Lyrics Transcription (SLT) task. To do this, we explore domain adaptation using transfer learning, music source separation and language modeling in the lyrics domain using Wav2Vec2.0 and Whisper models, the current state of the art in the Speech domain.Through our experiments and analysis we show that we are able to improve the Word Error Rate (WER) benchmark by up to 60\% when transcribing songs to their lyrics.
