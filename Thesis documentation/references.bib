@article{salimpoor2011anatomically,
  title={Anatomically distinct dopamine release during anticipation and experience of peak emotion to music},
  author={Salimpoor, Valorie N and Benovoy, Mitchel and Larcher, Kevin and Dagher, Alain and Zatorre, Robert J},
  journal={Nature neuroscience},
  volume={14},
  number={2},
  pages={257--262},
  year={2011},
  publisher={Nature Publishing Group}
}


@misc{Spotify_2023, 
title= {About Spotify - Company Info},
url={https://newsroom.spotify.com/company-info},
journal={Spotify},
year={2023},
month={07}
} 

@misc{musixmatch_2023, 
title= {About Musixmatch - The world's leading music data company},
url={https://about.musixmatch.com/press},
journal={Musixmatch},
year={2023},
month={08}
} 


@article{gao2022automatic,
  title={Automatic lyrics transcription of polyphonic music with lyrics-chord multi-task learning},
  author={Gao, Xiaoxue and Gupta, Chitralekha and Li, Haizhou},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={2280--2294},
  year={2022},
  publisher={IEEE}
}


@book{jurafsky2000speech,
  title={Speech \& language processing},
  author={Jurafsky, Dan},
  year={2000},
  publisher={Pearson Education India}
}

@article{forsberg2003speech,
  title={Why is speech recognition difficult},
  author={Forsberg, Markus},
  journal={Chalmers University of Technology},
  year={2003}
}


@article{karpagavalli2016review,
  title={A review on automatic speech recognition architecture and approaches},
  author={Karpagavalli, S and Chandra, Edy},
  journal={International Journal of Signal Processing, Image Processing and Pattern Recognition},
  volume={9},
  number={4},
  pages={393--404},
  year={2016}
}



@article{gales2008application,
  title={The application of hidden Markov models in speech recognition},
  author={Gales, Mark and Young, Steve and others},
  journal={Foundations and Trends{\textregistered} in Signal Processing},
  volume={1},
  number={3},
  pages={195--304},
  year={2008},
  publisher={Now Publishers, Inc.}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}


@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}


@article{meseguer2020creating,
  title={Creating DALI, a large dataset of synchronized audio, lyrics, and notes},
  author={Meseguer-Brocal, Gabriel and Cohen-Hadria, Alice and Peeters, Geoffroy},
  journal={Transactions of the International Society for Music Information Retrieval},
  volume={3},
  number={1},
  year={2020},
  publisher={Ubiquity Press}
}

@inproceedings{mcfee2015librosa,
  title={librosa: Audio and music signal analysis in python},
  author={McFee, Brian and Raffel, Colin and Liang, Dawen and Ellis, Daniel P and McVicar, Matt and Battenberg, Eric and Nieto, Oriol},
  booktitle={Proceedings of the 14th python in science conference},
  volume={8},
  pages={18--25},
  year={2015}
}


@book{huang2001spoken,
  title={Spoken language processing: A guide to theory, algorithm, and system development},
  author={Huang, Xuedong and Acero, Alex and Hon, Hsiao-Wuen and Reddy, Raj},
  year={2001},
  publisher={Prentice hall PTR}
}

@InProceedings{VBCG_HPCS14,
   author =       {S. Varrette and P. Bouvry and H. Cartiaux and F. Georgatos},
   title =        {Management of an Academic HPC Cluster: The UL Experience},
   booktitle =    {Proc. of the 2014 Intl. Conf. on High Performance Computing \& Simulation (HPCS 2014)},
   year =         {2014},
   pages =        {959--967},
   month =        {7},
   address =      {Bologna, Italy},
   publisher =    {IEEE},
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Wolf, Thomas  and
      Debut, Lysandre  and
      Sanh, Victor  and
      Chaumond, Julien  and
      Delangue, Clement  and
      Moi, Anthony  and
      Cistac, Pierric  and
      Rault, Tim  and
      Louf, Remi  and
      Funtowicz, Morgan  and
      Davison, Joe  and
      Shleifer, Sam  and
      von Platen, Patrick  and
      Ma, Clara  and
      Jernite, Yacine  and
      Plu, Julien  and
      Xu, Canwen  and
      Le Scao, Teven  and
      Gugger, Sylvain  and
      Drame, Mariama  and
      Lhoest, Quentin  and
      Rush, Alexander",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-demos.6",
    doi = "10.18653/v1/2020.emnlp-demos.6",
    pages = "38--45",
    abstract = "Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.",
}


@software{Falcon_PyTorch_Lightning_2019,
author = {Falcon, William and {The PyTorch Lightning team}},
doi = {10.5281/zenodo.3828935},
license = {Apache-2.0},
month = mar,
title = {{PyTorch Lightning}},
url = {https://github.com/Lightning-AI/lightning},
version = {1.4},
year = {2019}
}

@inproceedings{Paszke_PyTorch_An_Imperative_2019,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and d'Alch√©-Buc, F. and Fox, E. and Garnett, R.},
pages = {8024--8035},
publisher = {Curran Associates, Inc.},
title = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
year = {2019}
}



@inproceedings{zechner2000minimizing,
  title={Minimizing word error rate in textual summaries of spoken language},
  author={Zechner, Klaus and Waibel, Alex},
  booktitle={1st Meeting of the North American Chapter of the Association for Computational Linguistics},
  year={2000}
}


@techreport{mccowan2004use,
  title={On the use of information retrieval measures for speech recognition evaluation},
  author={McCowan, Iain A and Moore, Darren and Dines, John and Gatica-Perez, Daniel and Flynn, Mike and Wellner, Pierre and Bourlard, Herv{\'e}},
  year={2004},
  institution={IDIAP}
}


@inproceedings{rouard2023hybrid,
  title={Hybrid transformers for music source separation},
  author={Rouard, Simon and Massa, Francisco and D{\'e}fossez, Alexandre},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{yoo2003slurm,
  title={Slurm: Simple linux utility for resource management},
  author={Yoo, Andy B and Jette, Morris A and Grondona, Mark},
  booktitle={Workshop on job scheduling strategies for parallel processing},
  pages={44--60},
  year={2003},
  organization={Springer}
}


@inproceedings{gu2022mm,
  title={Mm-alt: A multimodal automatic lyric transcription system},
  author={Gu, Xiangming and Ou, Longshen and Ong, Danielle and Wang, Ye},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={3328--3337},
  year={2022}
}

@inproceedings{fujihara2012lyrics,
  title={Lyrics-to-audio alignment and its application},
  author={Fujihara, Hiromasa and Goto, Masataka},
  booktitle={Dagstuhl Follow-Ups},
  volume={3},
  year={2012},
  organization={Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik}
}

@inproceedings{mesaros2013singing,
  title={Singing voice identification and lyrics transcription for music information retrieval invited paper},
  author={Mesaros, Annamaria},
  booktitle={2013 7th Conference on Speech Technology and Human-Computer Dialogue (SpeD)},
  pages={1--10},
  year={2013},
  organization={IEEE}
}


@article{spleeter2020,
  doi = {10.21105/joss.02154},
  url = {https://doi.org/10.21105/joss.02154},
  year = {2020},
  publisher = {The Open Journal},
  volume = {5},
  number = {50},
  pages = {2154},
  author = {Romain Hennequin and Anis Khlif and Felix Voituret and Manuel Moussallam},
  title = {Spleeter: a fast and efficient music source separation tool with pre-trained models},
  journal = {Journal of Open Source Software},
  note = {Deezer Research}
}

@inproceedings{rouard2022hybrid,
  title={Hybrid Transformers for Music Source Separation},
  author={Rouard, Simon and Massa, Francisco and D{\'e}fossez, Alexandre},
  booktitle={ICASSP 23},
  year={2023}
}

@inproceedings{xu2021self,
  title={Self-training and pre-training are complementary for speech recognition},
  author={Xu, Qiantong and Baevski, Alexei and Likhomanenko, Tatiana and Tomasello, Paden and Conneau, Alexis and Collobert, Ronan and Synnaeve, Gabriel and Auli, Michael},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3030--3034},
  year={2021},
  organization={IEEE}
}

@inproceedings{ou2022transfer,
  title={Transfer learning of wav2vec 2.0 for automatic lyric transcription},
  author={Ou, Longshen and Gu, Xiangming and Wang, Ye},
  booktitle={Proc. ISMIR},
  year={2022}
}

@inproceedings{morris2004and,
  title={From WER and RIL to MER and WIL: improved evaluation measures for connected speech recognition},
  author={Morris, Andrew Cameron and Maier, Viktoria and Green, Phil},
  booktitle={Eighth International Conference on Spoken Language Processing},
  year={2004}
}


@book{opensourceseparation:book,
	Author = {Ethan Manilow and Prem Seetharman and Justin Salamon},
	Month = 10,
	Publisher = {https://source-separation.github.io/tutorial},
	Title = {Open Source Tools \& Data for Music Source Separation},
	Year = 2020,
	Url = {https://source-separation.github.io/tutorial}
}

@article{buragohain2022deep,
  title={A deep transfer learning based approach to detect COVID-19 waste},
  author={Buragohain, Ayushman and Mali, Bhabesh and Saha, Santanu and Singh, Pranav Kumar},
  journal={Internet Technology Letters},
  volume={5},
  number={3},
  pages={e327},
  year={2022},
  publisher={Wiley Online Library}
}


@article{hosna2022transfer,
  title={Transfer learning: a friendly introduction},
  author={Hosna, Asmaul and Merry, Ethel and Gyalmo, Jigmey and Alom, Zulfikar and Aung, Zeyar and Azim, Mohammad Abdul},
  journal={Journal of Big Data},
  volume={9},
  number={1},
  pages={102},
  year={2022},
  publisher={Springer}
}


@book{zhang2023dive,
    title={Dive into Deep Learning},
    author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
    publisher={Cambridge University Press},
    note={\url{https://D2L.ai}},
    year={2023}
}

@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{wang2021large,
  title={Large-scale self-and semi-supervised learning for speech translation},
  author={Wang, Changhan and Wu, Anne and Pino, Juan and Baevski, Alexei and Auli, Michael and Conneau, Alexis},
  journal={arXiv preprint arXiv:2104.06678},
  year={2021}
}


@misc{dalireleases,
	author = {},
	title = {{D}{A}{L}{I}/versions at master ¬∑ gabolsgabs/{D}{A}{L}{I} --- github.com},
	howpublished = {\url{https://github.com/gabolsgabs/DALI/tree/master/versions}},
	year = {},
	note = {[Accessed 29-08-2023]},
}

@misc{robert2018pydub,
  title={Pydub},
  author={Robert, James and Webbie, Marc and others},
  year={2018},
  publisher={GitHub},
  url={http://pydub.com/}
}


@book{martineau2021elements,
  title={Elements of Music},
  author={Martineau, Jason},
  year={2021},
  publisher={eBook Partnership}
}


@inproceedings{heafield-etal-2013-scalable,
  title = {Scalable Modified {K}neser-{N}ey Language Model Estimation},
  author = {Heafield, Kenneth and Pouzyrevsky, Ivan and Clark, Jonathan H. and Koehn, Philipp},
  booktitle = {Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  month = aug,
  year = {2013},
  address = {Sofia, Bulgaria},
  publisher = {Association for Computational Linguistics},
  url = {https://www.aclweb.org/anthology/P13-2121},
  pages = {690--696},
  month_numeric = {8}
}


@misc{KenshoTechnologies, 
    title={Kensho-Technologies/pyctcdecode: A fast and lightweight python-based CTC Beam Search decoder for speech recognition.},
    url={https://github.com/kensho-technologies/pyctcdecode}, 
    journal={GitHub},
    author={Kensho-Technologies}    
} 


@misc{githubWhisperwhisperdecodingpyMain,
	author = {},
	title = {whisper/whisper/decoding.py at main ¬∑ openai/whisper --- github.com},
	howpublished = {\url{https://github.com/openai/whisper/blob/main/whisper/decoding.py}},
	year = {},
	note = {[Accessed 29-08-2023]},
}


@article{mosbach2020stability,
  title={On the stability of fine-tuning bert: Misconceptions, explanations, and strong baselines},
  author={Mosbach, Marius and Andriushchenko, Maksym and Klakow, Dietrich},
  journal={arXiv preprint arXiv:2006.04884},
  year={2020}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}


@inproceedings{song2016detecting,
  title={Detecting driver phone calls in a moving vehicle based on voice features},
  author={Song, Tianyi and Cheng, Xiuzhen and Li, Hongjuan and Yu, Jiguo and Wang, Shengling and Bie, Rongfang},
  booktitle={IEEE INFOCOM 2016-The 35th Annual IEEE International Conference on Computer Communications},
  pages={1--9},
  year={2016},
  organization={IEEE}
}